{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":99552,"databundleVersionId":13762876,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\ndata_path = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\nprint(os.listdir(data_path))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-09-15T18:05:56.755396Z","iopub.execute_input":"2025-09-15T18:05:56.755580Z","iopub.status.idle":"2025-09-15T18:05:56.765088Z","shell.execute_reply.started":"2025-09-15T18:05:56.755562Z","shell.execute_reply":"2025-09-15T18:05:56.764463Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"['train_localizers.csv', 'segmentations', 'series', 'train.csv', 'kaggle_evaluation']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"!pip -q install python-gdcm","metadata":{"execution":{"iopub.status.busy":"2025-09-03T17:35:19.594664Z","iopub.execute_input":"2025-09-03T17:35:19.594962Z","iopub.status.idle":"2025-09-03T17:35:22.970468Z","shell.execute_reply.started":"2025-09-03T17:35:19.594939Z","shell.execute_reply":"2025-09-03T17:35:22.969358Z"}}},{"cell_type":"code","source":"import os, importlib.util, pydicom\n# Importing the handler registers it\nimport pydicom.pixel_data_handlers.gdcm_handler as gdcm_handler\n\nprint(\"GDCM handler available:\", gdcm_handler.is_available())\n\n# Optional: prove it decodes a random slice quickly\nroot = \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\"\nsome_uid = next(d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d)))\ndcm_path = os.path.join(root, some_uid, os.listdir(os.path.join(root, some_uid))[0])\n\nds = pydicom.dcmread(dcm_path)\narr = ds.pixel_array  # should succeed quickly if GDCM is active\nprint(\"Decoded OK. shape:\", arr.shape, \"dtype:\", arr.dtype)","metadata":{"execution":{"iopub.status.busy":"2025-09-08T19:17:29.517780Z","iopub.execute_input":"2025-09-08T19:17:29.518399Z","iopub.status.idle":"2025-09-08T19:17:30.263201Z","shell.execute_reply.started":"2025-09-08T19:17:29.518371Z","shell.execute_reply":"2025-09-08T19:17:30.262525Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"GDCM handler available: False\nDecoded OK. shape: (448, 392) dtype: int16\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\nlabels = pd.read_csv(os.path.join(data_path, \"train.csv\"))\nprint(labels.head())\n","metadata":{"execution":{"iopub.status.busy":"2025-09-08T19:17:32.170443Z","iopub.execute_input":"2025-09-08T19:17:32.171150Z","iopub.status.idle":"2025-09-08T19:17:34.275677Z","shell.execute_reply.started":"2025-09-08T19:17:32.171119Z","shell.execute_reply":"2025-09-08T19:17:34.274890Z"},"trusted":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"                                   SeriesInstanceUID  PatientAge PatientSex  \\\n0  1.2.826.0.1.3680043.8.498.10004044428023505108...          64     Female   \n1  1.2.826.0.1.3680043.8.498.10004684224894397679...          76     Female   \n2  1.2.826.0.1.3680043.8.498.10005158603912009425...          58       Male   \n3  1.2.826.0.1.3680043.8.498.10009383108068795488...          71       Male   \n4  1.2.826.0.1.3680043.8.498.10012790035410518400...          48     Female   \n\n  Modality  Left Infraclinoid Internal Carotid Artery  \\\n0      MRA                                          0   \n1      MRA                                          0   \n2      CTA                                          0   \n3      MRA                                          0   \n4      MRA                                          0   \n\n   Right Infraclinoid Internal Carotid Artery  \\\n0                                           0   \n1                                           0   \n2                                           0   \n3                                           0   \n4                                           0   \n\n   Left Supraclinoid Internal Carotid Artery  \\\n0                                          0   \n1                                          0   \n2                                          0   \n3                                          0   \n4                                          0   \n\n   Right Supraclinoid Internal Carotid Artery  Left Middle Cerebral Artery  \\\n0                                           0                            0   \n1                                           0                            0   \n2                                           0                            0   \n3                                           0                            0   \n4                                           0                            0   \n\n   Right Middle Cerebral Artery  Anterior Communicating Artery  \\\n0                             0                              0   \n1                             0                              0   \n2                             0                              0   \n3                             0                              0   \n4                             0                              0   \n\n   Left Anterior Cerebral Artery  Right Anterior Cerebral Artery  \\\n0                              0                               0   \n1                              0                               0   \n2                              0                               0   \n3                              0                               0   \n4                              0                               0   \n\n   Left Posterior Communicating Artery  Right Posterior Communicating Artery  \\\n0                                    0                                     0   \n1                                    0                                     0   \n2                                    0                                     0   \n3                                    0                                     0   \n4                                    0                                     0   \n\n   Basilar Tip  Other Posterior Circulation  Aneurysm Present  \n0            0                            0                 0  \n1            0                            0                 0  \n2            0                            1                 1  \n3            0                            0                 0  \n4            0                            0                 0  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os, glob, numpy as np, pandas as pd\nimport pydicom\nfrom pydicom.filereader import dcmread\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nDATA_DIR = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\nSERIES_DIR = os.path.join(DATA_DIR, \"series\")\nlabels = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\nprint(labels.shape, labels.columns.tolist()[:8], '...')\n","metadata":{"execution":{"iopub.status.busy":"2025-09-08T19:17:37.470870Z","iopub.execute_input":"2025-09-08T19:17:37.471484Z","iopub.status.idle":"2025-09-08T19:17:41.841402Z","shell.execute_reply.started":"2025-09-08T19:17:37.471455Z","shell.execute_reply":"2025-09-08T19:17:41.840551Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"(4348, 18) ['SeriesInstanceUID', 'PatientAge', 'PatientSex', 'Modality', 'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery', 'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery'] ...\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os, glob, numpy as np, pandas as pd\nimport pydicom\nfrom pydicom.filereader import dcmread\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\nDATA_DIR = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\nSERIES_DIR = os.path.join(DATA_DIR, \"series\")\nlabels = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\nprint(labels.shape, labels.columns.tolist()[:8], '...')\n","metadata":{"execution":{"iopub.status.busy":"2025-09-08T19:17:41.842861Z","iopub.execute_input":"2025-09-08T19:17:41.843540Z","iopub.status.idle":"2025-09-08T19:17:41.864166Z","shell.execute_reply.started":"2025-09-08T19:17:41.843517Z","shell.execute_reply":"2025-09-08T19:17:41.863567Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"(4348, 18) ['SeriesInstanceUID', 'PatientAge', 'PatientSex', 'Modality', 'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery', 'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery'] ...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# **TEST 1** ","metadata":{}},{"cell_type":"markdown","source":"**MIP** didnt work as expecte mostly i the coronal and the segittal planes goona fix theat and goona explore ways to improve on the code and on making th outpus shorter","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nRSNA Intracranial Aneurysm Detection - Tri-planar MIP Baseline\nComplete implementation in a single file for Kaggle notebook execution.\n\nCRITICAL IMPROVEMENTS:\n- TRUE on-the-fly MIP reduction (no RAM buildup)\n- Completion order processing for better responsiveness\n- Normalize once after reduction (not per slice)\n- Conservative defaults for stability\n- Proper DataLoader gating\n- CuDNN benchmark option\n- All decoder optimizations\n\"\"\"\n\nimport os\nimport sys\nimport argparse\nimport random\nimport warnings\nimport time\nimport hashlib\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional, Union\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport multiprocessing as mp\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\n# Fix import path for apply_voi_lut\ntry:\n    from pydicom.pixel_data_handlers import apply_voi_lut\nexcept ImportError:\n    try:\n        from pydicom.pixel_data_handlers.util import apply_voi_lut\n    except ImportError:\n        # Fallback for older pydicom versions\n        def apply_voi_lut(pixel_array, ds):\n            return pixel_array\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings('ignore')\n\n# Initialize DICOM decoders at startup for optimal performance\ndef initialize_dicom_decoders():\n    \"\"\"Initialize pylibjpeg decoders at startup.\"\"\"\n    try:\n        import pylibjpeg\n        import pylibjpeg_libjpeg\n        import pylibjpeg_openjpeg\n        import pylibjpeg_rle\n        # Enable external codecs\n        pydicom.config.decode_external_data = True\n        return True\n    except ImportError:\n        print(\"‚ö†Ô∏è  Some DICOM decoders missing. Install with:\")\n        print(\"   pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg pylibjpeg-rle\")\n        return False\n\n# Initialize decoders on import\nDECODERS_AVAILABLE = initialize_dicom_decoders()\n\n# =============================================================================\n# CONFIGURATION\n# =============================================================================\n\nclass Config:\n    \"\"\"Configuration class for the RSNA IA detection model.\"\"\"\n    \n    # Data paths (Kaggle default)\n    DATA_DIR = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\n    SERIES_DIR = f\"{DATA_DIR}/series\"\n    TRAIN_CSV = f\"{DATA_DIR}/train.csv\"\n    \n    # Model parameters\n    IMG_SIZE = 384\n    BATCH_SIZE = 4\n    EPOCHS = 3\n    LR = 2e-4\n    NUM_WORKERS = 0  # Start with 0, can bump to 2 later\n    DEFAULT_WORKERS = 2  # Conservative default for stability\n    SEED = 42\n    \n    # Performance optimization settings\n    CACHE_DIR = \"/kaggle/working/mip_cache\"  # Cache preprocessed MIPs\n    USE_CACHE = True  # Enable MIP caching\n    MAX_WORKERS = min(4, mp.cpu_count())  # Max workers for parallel processing\n    PREFETCH_FACTOR = 2  # DataLoader prefetch factor\n    \n    # DICOM decoder settings\n    FORCE_PYLIBJPEG = True  # Force pylibjpeg for better performance\n    \n    # Cache version for breaking changes\n    CACHE_VERSION = \"v2.1\"  # Increment when changing processing logic\n    \n    # Memory threshold for switching to streaming mode\n    LARGE_SERIES_THRESHOLD = 200  # Switch to streaming for series > 200 slices\n    \n    # Target columns (13 anatomical locations + Aneurysm Present)\n    TARGET_COLS = [\n        \"Left Infraclinoid Internal Carotid Artery\",\n        \"Right Infraclinoid Internal Carotid Artery\",\n        \"Left Supraclinoid Internal Carotid Artery\",\n        \"Right Supraclinoid Internal Carotid Artery\",\n        \"Left Middle Cerebral Artery\",\n        \"Right Middle Cerebral Artery\",\n        \"Anterior Communicating Artery\",\n        \"Left Anterior Cerebral Artery\",\n        \"Right Anterior Cerebral Artery\",\n        \"Left Posterior Communicating Artery\",\n        \"Right Posterior Communicating Artery\",\n        \"Basilar Tip\",\n        \"Other Posterior Circulation\",\n        \"Aneurysm Present\",\n    ]\n\ndef make_seed(seed: int, benchmark_mode: bool = False) -> None:\n    \"\"\"\n    Set random seeds for reproducibility.\n    \n    Args:\n        seed: Random seed value\n        benchmark_mode: If True, enable cuDNN benchmark for speed over reproducibility\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    if benchmark_mode:\n        # Speed over reproducibility\n        torch.backends.cudnn.deterministic = False\n        torch.backends.cudnn.benchmark = True\n        print(\"‚ö° CuDNN benchmark mode enabled (speed over reproducibility)\")\n    else:\n        # Reproducibility over speed\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\ndef device() -> str:\n    \"\"\"Get the device to use for training/inference.\"\"\"\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# =============================================================================\n# DICOM I/O AND MIP GENERATION (OPTIMIZED)\n# =============================================================================\n\ndef get_mip_cache_path(series_path: str, out_size: int, modality_hint: str = None) -> str:\n    \"\"\"\n    Generate cache file path for a series MIP with robust cache key.\n    \n    Args:\n        series_path: Path to series folder\n        out_size: Output image size\n        modality_hint: Modality hint for cache key\n        \n    Returns:\n        Cache file path\n    \"\"\"\n    # Create a robust cache key including all relevant parameters\n    series_uid = os.path.basename(series_path)\n    modality = modality_hint or \"unknown\"\n    \n    # Include cache version, modality, and image size in key\n    cache_key = f\"{Config.CACHE_VERSION}_{series_uid}_{modality}_{out_size}\"\n    cache_hash = hashlib.md5(cache_key.encode()).hexdigest()[:16]\n    \n    cache_dir = Config.CACHE_DIR\n    os.makedirs(cache_dir, exist_ok=True)\n    \n    # Use .npy instead of .pkl for better performance and safety\n    return os.path.join(cache_dir, f\"mip_{cache_hash}.npy\")\n\ndef save_mip_to_cache(mips: np.ndarray, cache_path: str) -> None:\n    \"\"\"Save MIPs to cache file using uint8 format for 4x smaller files.\"\"\"\n    try:\n        # Convert float32 [0,1] to uint8 [0,255] for 4x smaller cache files\n        mips_uint8 = (mips * 255).astype(np.uint8)\n        np.save(cache_path, mips_uint8, allow_pickle=False)\n    except Exception as e:\n        print(f\"Warning: Failed to save MIP cache: {e}\")\n\ndef load_mip_from_cache(cache_path: str) -> Optional[np.ndarray]:\n    \"\"\"Load MIPs from cache file and convert uint8 back to float32 [0,1].\"\"\"\n    try:\n        if os.path.exists(cache_path):\n            # Load uint8 [0,255] and convert back to float32 [0,1]\n            mips_uint8 = np.load(cache_path, allow_pickle=False)\n            mips_float = mips_uint8.astype(np.float32) / 255.0\n            return mips_float\n    except Exception as e:\n        print(f\"Warning: Failed to load MIP cache: {e}\")\n    return None\n\ndef process_dicom_slice_optimized(file_path: str) -> Optional[np.ndarray]:\n    \"\"\"\n    Optimized DICOM slice processing for parallel execution.\n    \"\"\"\n    try:\n        ds = pydicom.dcmread(file_path)\n        img = read_pixel(ds)\n        \n        # Handle photometric interpretation\n        if hasattr(ds, 'PhotometricInterpretation'):\n            photometric = ds.PhotometricInterpretation\n            if photometric == 'MONOCHROME1':\n                img = np.max(img) - img\n            elif photometric == 'RGB':\n                if len(img.shape) == 3 and img.shape[-1] == 3:\n                    img = np.mean(img, axis=-1)\n        return img\n    except Exception:\n        return None\n\ndef iter_dicom_files(series_path: str) -> List[str]:\n    \"\"\"Return sorted DICOM files in the series folder.\"\"\"\n    series_path = Path(series_path)\n    dcm_files = list(series_path.glob(\"*.dcm\"))\n    if not dcm_files:\n        dcm_files = [f for f in series_path.iterdir() if f.is_file() and not f.suffix]\n    if not dcm_files:\n        return []\n    file_info = []\n    for file_path in dcm_files:\n        try:\n            ds = pydicom.dcmread(str(file_path), stop_before_pixels=True)\n            instance_num = getattr(ds, 'InstanceNumber', 0)\n            file_info.append((instance_num, str(file_path)))\n        except:\n            file_info.append((0, str(file_path)))\n    file_info.sort(key=lambda x: (x[0], x[1]))\n    return [f[1] for f in file_info]\n\ndef read_pixel(ds) -> np.ndarray:\n    \"\"\"Robustly decode DICOM pixel data to numpy array.\"\"\"\n    try:\n        pixel_array = ds.pixel_array\n        if hasattr(ds, 'VOILUTSequence') or hasattr(ds, 'WindowCenter'):\n            pixel_array = apply_voi_lut(pixel_array, ds)\n        if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n            pixel_array = pixel_array.astype(np.float32)\n            pixel_array = pixel_array * ds.RescaleSlope + ds.RescaleIntercept\n        return pixel_array\n    except Exception as e:\n        raise RuntimeError(f\"Failed to decode pixel data: {e}\")\n\ndef window_ct(img: np.ndarray, level: int = 200, width: int = 500) -> np.ndarray:\n    \"\"\"Apply CT windowing to image -> [0,1].\"\"\"\n    img = img.astype(np.float32)\n    min_val = level - width // 2\n    max_val = level + width // 2\n    img = np.clip(img, min_val, max_val)\n    img = (img - min_val) / (max_val - min_val)\n    return np.clip(img, 0, 1)\n\ndef normalize_mr(img: np.ndarray) -> np.ndarray:\n    \"\"\"Percentile clip (1-99) then min-max -> [0,1].\"\"\"\n    img = img.astype(np.float32)\n    p1, p99 = np.percentile(img, [1, 99])\n    img = np.clip(img, p1, p99)\n    if p99 > p1:\n        img = (img - p1) / (p99 - p1)\n    return np.clip(img, 0, 1)\n\n# ===================== FIXED: ALWAYS 2D CORONAL/SAGITTAL =====================\n\ndef make_triplanar_mips_parallel(series_path: str, modality_hint: Optional[str] = None, \n                                 out_size: int = 384, use_cache: bool = True) -> np.ndarray:\n    \"\"\"\n    Create tri-planar MIPs using TRUE on-the-fly parallel processing.\n    Ensures coronal/sagittal are always 2D even for single-slice series.\n    \"\"\"\n    # Cache\n    cache_path = get_mip_cache_path(series_path, out_size, modality_hint)\n    if use_cache and Config.USE_CACHE:\n        cached_mips = load_mip_from_cache(cache_path)\n        if cached_mips is not None:\n            return cached_mips\n    \n    dicom_files = iter_dicom_files(series_path)\n    if not dicom_files:\n        raise RuntimeError(f\"No DICOM files found in {series_path}\")\n    total_slices = len(dicom_files)\n    \n    # Fallback to streaming for very large series\n    if total_slices > Config.LARGE_SERIES_THRESHOLD:\n        print(f\"   üìä Large series detected ({total_slices} slices) - using streaming mode...\")\n        return make_triplanar_mips_stream(series_path, modality_hint, out_size)\n    \n    if total_slices > 50:\n        print(f\"   üìä Processing {total_slices} DICOM slices (parallel on-the-fly mode)...\")\n    \n    axial_mip = None\n    coronal_mips = []   # list of (W,)\n    sagittal_mips = []  # list of (H,)\n    successful_count = 0\n    failed_decodes = 0\n    \n    max_workers = min(Config.MAX_WORKERS, total_slices)\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        future_to_file = {executor.submit(process_dicom_slice_optimized, f): f for f in dicom_files}\n        completed_count = 0\n        for future in as_completed(future_to_file):\n            completed_count += 1\n            try:\n                img = future.result()\n                if img is not None:\n                    if img.ndim == 3:\n                        if img.shape[2] == 3:  # RGB\n                            img = np.mean(img, axis=2)\n                        else:  # multi-channel\n                            img = img.max(axis=2)\n                    if axial_mip is None:\n                        axial_mip = img.copy()\n                    else:\n                        axial_mip = np.maximum(axial_mip, img)\n                    coronal_mips.append(img.max(axis=0))   # (W,)\n                    sagittal_mips.append(img.max(axis=1))  # (H,)\n                    successful_count += 1\n                else:\n                    failed_decodes += 1\n                if total_slices > 100 and completed_count % 50 == 0:\n                    print(f\"      üìà Processed {completed_count}/{total_slices} slices ({successful_count} successful, {failed_decodes} failed)\")\n            except Exception:\n                failed_decodes += 1\n                continue\n    \n    if successful_count == 0:\n        raise RuntimeError(f\"No decodable slices in {series_path} (failed={failed_decodes})\")\n    if failed_decodes > 0:\n        print(f\"   ‚ö†Ô∏è  Warning: {failed_decodes}/{total_slices} slices failed to decode in {os.path.basename(series_path)}\")\n    if total_slices > 50:\n        print(f\"   ‚úÖ Parallel MIP generation complete: {successful_count} successful, {failed_decodes} failed\")\n    \n    # Normalize axial once\n    if modality_hint and modality_hint.upper() in ['CT', 'CTA']:\n        axial_mip = window_ct(axial_mip)\n    else:\n        axial_mip = normalize_mr(axial_mip)\n    H, W = axial_mip.shape  # base dimensions\n    \n    # CORONAL: build 2D (H, W) from a 1D row (W,)\n    if coronal_mips:\n        coronal_vec = coronal_mips[0] if len(coronal_mips) == 1 else np.max(np.stack(coronal_mips, axis=0), axis=0)\n        if coronal_vec.ndim != 1:\n            coronal_vec = coronal_vec.flatten()\n        # resize vector to length W if needed\n        if coronal_vec.shape[0] != W:\n            coronal_vec = cv2.resize(coronal_vec[np.newaxis, :], (W, 1), interpolation=cv2.INTER_AREA).squeeze()\n        coronal_mip = np.tile(coronal_vec[np.newaxis, :], (H, 1)).astype(np.float32)\n        coronal_mip = window_ct(coronal_mip) if (modality_hint and modality_hint.upper() in ['CT','CTA']) else normalize_mr(coronal_mip)\n        assert coronal_mip.ndim == 2, f\"Coronal MIP should be 2D, got {coronal_mip.shape}\"\n    else:\n        coronal_mip = np.zeros((H, W), dtype=np.float32)\n    \n    # SAGITTAL: build 2D (H, W) from a 1D col (H,)\n    if sagittal_mips:\n        sagittal_vec = sagittal_mips[0] if len(sagittal_mips) == 1 else np.max(np.stack(sagittal_mips, axis=0), axis=0)\n        if sagittal_vec.ndim != 1:\n            sagittal_vec = sagittal_vec.flatten()\n        if sagittal_vec.shape[0] != H:\n            sagittal_vec = cv2.resize(sagittal_vec[:, np.newaxis], (1, H), interpolation=cv2.INTER_AREA).squeeze()\n        sagittal_mip = np.tile(sagittal_vec[:, np.newaxis], (1, W)).astype(np.float32)\n        sagittal_mip = window_ct(sagittal_mip) if (modality_hint and modality_hint.upper() in ['CT','CTA']) else normalize_mr(sagittal_mip)\n        assert sagittal_mip.ndim == 2, f\"Sagittal MIP should be 2D, got {sagittal_mip.shape}\"\n    else:\n        sagittal_mip = np.zeros((H, W), dtype=np.float32)\n    \n    # Resize to output size\n    axial_mip    = cv2.resize(axial_mip,    (out_size, out_size), interpolation=cv2.INTER_AREA)\n    coronal_mip  = cv2.resize(coronal_mip,  (out_size, out_size), interpolation=cv2.INTER_AREA)\n    sagittal_mip = cv2.resize(sagittal_mip, (out_size, out_size), interpolation=cv2.INTER_AREA)\n    \n    if total_slices > 50:\n        print(f\"   üìê MIP shapes before stacking:\")\n        print(f\"      ‚Ä¢ Axial: {axial_mip.shape}\")\n        print(f\"      ‚Ä¢ Coronal: {coronal_mip.shape}\")\n        print(f\"      ‚Ä¢ Sagittal: {sagittal_mip.shape}\")\n    \n    target_shape = (out_size, out_size)\n    assert axial_mip.shape == target_shape\n    assert coronal_mip.shape == target_shape\n    assert sagittal_mip.shape == target_shape\n    \n    triplanar_mips = np.stack([axial_mip, coronal_mip, sagittal_mip], axis=0).astype(np.float32)\n    if use_cache and Config.USE_CACHE:\n        save_mip_to_cache(triplanar_mips, cache_path)\n    return triplanar_mips\n\ndef make_triplanar_mips_stream(series_path: str, modality_hint: Optional[str] = None, \n                               out_size: int = 384) -> np.ndarray:\n    \"\"\"\n    Create tri-planar MIPs by streaming slices (memory efficient).\n    Ensures coronal/sagittal are always 2D even for single-slice series.\n    \"\"\"\n    dicom_files = iter_dicom_files(series_path)\n    if not dicom_files:\n        raise RuntimeError(f\"No DICOM files found in {series_path}\")\n    total_slices = len(dicom_files)\n    \n    if total_slices > 50:\n        print(f\"   üìä Processing {total_slices} DICOM slices (streaming mode - low memory)...\")\n    \n    axial_mip = None\n    coronal_rows = []   # (W,)\n    sagittal_cols = []  # (H,)\n    failed_decodes = 0\n    successful_decodes = 0\n    \n    for i, file_path in enumerate(dicom_files):\n        try:\n            ds = pydicom.dcmread(file_path)\n            img = read_pixel(ds)\n            \n            if hasattr(ds, 'PhotometricInterpretation'):\n                photometric = ds.PhotometricInterpretation\n                if photometric == 'MONOCHROME1':\n                    img = np.max(img) - img\n                elif photometric == 'RGB' and len(img.shape) == 3 and img.shape[-1] == 3:\n                    img = np.mean(img, axis=-1)\n            if img.ndim == 3:\n                if img.shape[2] == 3:\n                    img = np.mean(img, axis=2)\n                else:\n                    img = img.max(axis=2)\n            \n            if axial_mip is None:\n                axial_mip = img.copy()\n            else:\n                axial_mip = np.maximum(axial_mip, img)\n            \n            coronal_rows.append(img.max(axis=0))   # (W,)\n            sagittal_cols.append(img.max(axis=1))  # (H,)\n            successful_decodes += 1\n            \n            if total_slices > 100 and (i + 1) % 50 == 0:\n                print(f\"      üìà Processed {i+1}/{total_slices} slices ({successful_decodes} successful, {failed_decodes} failed)\")\n        except Exception:\n            failed_decodes += 1\n            continue\n    \n    if successful_decodes == 0:\n        raise RuntimeError(f\"No decodable slices in {series_path} (failed={failed_decodes})\")\n    if failed_decodes > 0:\n        print(f\"   ‚ö†Ô∏è  Warning: {failed_decodes}/{total_slices} slices failed to decode in {os.path.basename(series_path)}\")\n    if total_slices > 50:\n        print(f\"   ‚úÖ Streaming MIP generation complete: {successful_decodes} successful, {failed_decodes} failed\")\n    \n    # Normalize axial once\n    if modality_hint and modality_hint.upper() in ['CT', 'CTA']:\n        axial_mip = window_ct(axial_mip)\n    else:\n        axial_mip = normalize_mr(axial_mip)\n    H, W = axial_mip.shape\n    \n    # CORONAL: 2D from 1D row\n    if coronal_rows:\n        coronal_vec = coronal_rows[0] if len(coronal_rows) == 1 else np.max(np.stack(coronal_rows, axis=0), axis=0)\n        if coronal_vec.ndim != 1:\n            coronal_vec = coronal_vec.flatten()\n        if coronal_vec.shape[0] != W:\n            coronal_vec = cv2.resize(coronal_vec[np.newaxis, :], (W, 1), interpolation=cv2.INTER_AREA).squeeze()\n        coronal_mip = np.tile(coronal_vec[np.newaxis, :], (H, 1)).astype(np.float32)\n        coronal_mip = window_ct(coronal_mip) if (modality_hint and modality_hint.upper() in ['CT','CTA']) else normalize_mr(coronal_mip)\n        assert coronal_mip.ndim == 2\n    else:\n        coronal_mip = np.zeros((H, W), dtype=np.float32)\n    \n    # SAGITTAL: 2D from 1D col\n    if sagittal_cols:\n        sagittal_vec = sagittal_cols[0] if len(sagittal_cols) == 1 else np.max(np.stack(sagittal_cols, axis=0), axis=0)\n        if sagittal_vec.ndim != 1:\n            sagittal_vec = sagittal_vec.flatten()\n        if sagittal_vec.shape[0] != H:\n            sagittal_vec = cv2.resize(sagittal_vec[:, np.newaxis], (1, H), interpolation=cv2.INTER_AREA).squeeze()\n        sagittal_mip = np.tile(sagittal_vec[:, np.newaxis], (1, W)).astype(np.float32)\n        sagittal_mip = window_ct(sagittal_mip) if (modality_hint and modality_hint.upper() in ['CT','CTA']) else normalize_mr(sagittal_mip)\n        assert sagittal_mip.ndim == 2\n    else:\n        sagittal_mip = np.zeros((H, W), dtype=np.float32)\n    \n    # Resize all to output size\n    axial_mip    = cv2.resize(axial_mip,    (out_size, out_size), interpolation=cv2.INTER_AREA)\n    coronal_mip  = cv2.resize(coronal_mip,  (out_size, out_size), interpolation=cv2.INTER_AREA)\n    sagittal_mip = cv2.resize(sagittal_mip, (out_size, out_size), interpolation=cv2.INTER_AREA)\n    \n    if total_slices > 50:\n        print(f\"   üìê MIP shapes before stacking:\")\n        print(f\"      ‚Ä¢ Axial: {axial_mip.shape}\")\n        print(f\"      ‚Ä¢ Coronal: {coronal_mip.shape}\")\n        print(f\"      ‚Ä¢ Sagittal: {sagittal_mip.shape}\")\n    \n    target_shape = (out_size, out_size)\n    assert axial_mip.shape == target_shape\n    assert coronal_mip.shape == target_shape\n    assert sagittal_mip.shape == target_shape\n    \n    triplanar_mips = np.stack([axial_mip, coronal_mip, sagittal_mip], axis=0)\n    return triplanar_mips.astype(np.float32)\n\n# =============================================================================\n# DATASET CLASS\n# =============================================================================\n\nclass MIPDataset(Dataset):\n    \"\"\"Dataset class for tri-planar MIP images.\"\"\"\n    \n    def __init__(self, df: pd.DataFrame, series_dir: str, out_size: int):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.out_size = out_size\n        \n        missing_cols = [col for col in Config.TARGET_COLS if col not in df.columns]\n        if missing_cols:\n            raise ValueError(f\"Missing target columns: {missing_cols}\")\n    \n    def __len__(self) -> int:\n        return len(self.df)\n    \n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, str]:\n        row = self.df.iloc[idx]\n        series_uid = row['SeriesInstanceUID']\n        \n        series_path = os.path.join(self.series_dir, series_uid)\n        if not os.path.exists(series_path):\n            raise FileNotFoundError(f\"Series folder not found: {series_path}\")\n        \n        modality_hint = row.get('Modality', None)\n        mips = make_triplanar_mips_parallel(series_path, modality_hint, self.out_size)\n        x = torch.from_numpy(mips).float()\n        y = torch.tensor([row[col] for col in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, series_uid\n\ndef stratified_split(df: pd.DataFrame, global_col: str = \"Aneurysm Present\", \n                    seed: int = 42, n_splits: int = 5) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    if global_col not in df.columns:\n        raise ValueError(f\"Global column {global_col} not found in DataFrame\")\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    for train_idx, val_idx in skf.split(df, df[global_col]):\n        train_df = df.iloc[train_idx].copy()\n        val_df = df.iloc[val_idx].copy()\n        break\n    return train_df, val_df\n\n# =============================================================================\n# MODEL DEFINITION\n# =============================================================================\n\ndef build_efficientnet_b0(n_out: int = 14) -> nn.Module:\n    try:\n        model = torchvision.models.efficientnet_b0(\n            weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        )\n    except AttributeError:\n        model = torchvision.models.efficientnet_b0(pretrained=True)\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, n_out)\n    return model\n\n# =============================================================================\n# METRICS\n# =============================================================================\n\ndef compute_auc_per_column(y_true: np.ndarray, y_prob: np.ndarray, \n                          cols: List[str]) -> Tuple[Dict[str, float], float]:\n    column_aucs = {}\n    valid_aucs = []\n    for i, col in enumerate(cols):\n        try:\n            unique_classes = np.unique(y_true[:, i])\n            if len(unique_classes) < 2:\n                column_aucs[col] = np.nan\n                continue\n            auc = roc_auc_score(y_true[:, i], y_prob[:, i])\n            column_aucs[col] = auc\n            valid_aucs.append(auc)\n        except Exception as e:\n            column_aucs[col] = np.nan\n            print(f\"Warning: Could not compute AUC for {col}: {e}\")\n    macro_auc = np.mean(valid_aucs) if valid_aucs else np.nan\n    return column_aucs, macro_auc\n\n# =============================================================================\n# UTILITIES\n# =============================================================================\n\ndef set_seed(seed: int, benchmark_mode: bool = False) -> None:\n    make_seed(seed, benchmark_mode)\n\ndef count_params(model: nn.Module) -> int:\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef safe_series_path(series_dir: str, uid: str) -> str:\n    series_path = os.path.join(series_dir, uid)\n    if not os.path.exists(series_path):\n        raise FileNotFoundError(f\"Series path does not exist: {series_path}\")\n    return series_path\n\n# =============================================================================\n# TRAINING SCRIPT\n# =============================================================================\n\ndef train_model(args):\n    \"\"\"Main training function.\"\"\"\n    start_time = time.time()\n    print(\"=\" * 60)\n    print(\"üöÄ STARTING RSNA IA DETECTION TRAINING\")\n    print(\"=\" * 60)\n    \n    # Set seed and device\n    print(\"üìã Setting up training environment...\")\n    benchmark_mode = getattr(args, 'benchmark_mode', False)\n    set_seed(args.seed, benchmark_mode)\n    device_str = device()\n    print(f\"‚úÖ Device: {device_str}\")\n    print(f\"‚úÖ Random seed: {args.seed}\")\n    if not DECODERS_AVAILABLE:\n        print(\"‚ö†Ô∏è  Some DICOM decoders are missing - processing may be slower\")\n    \n    # Load training data\n    print(f\"\\nüìÅ Loading training data from {args.data_dir}\")\n    train_csv = os.path.join(args.data_dir, \"train.csv\")\n    if not os.path.exists(train_csv):\n        raise FileNotFoundError(f\"‚ùå Training CSV not found: {train_csv}\")\n    \n    print(\"üìä Reading CSV file...\")\n    df = pd.read_csv(train_csv)\n    print(f\"‚úÖ Loaded {len(df):,} training samples\")\n    \n    # Verify target columns exist\n    print(\"\\nüîç Verifying target columns...\")\n    missing_cols = [col for col in Config.TARGET_COLS if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"‚ùå Missing target columns in CSV: {missing_cols}\")\n    print(f\"‚úÖ All {len(Config.TARGET_COLS)} target columns found\")\n    \n    # Show data distribution\n    print(\"\\nüìà Data distribution:\")\n    aneurysm_present = df[\"Aneurysm Present\"].sum()\n    print(f\"   ‚Ä¢ Aneurysm Present: {aneurysm_present:,} ({aneurysm_present/len(df)*100:.1f}%)\")\n    print(f\"   ‚Ä¢ No Aneurysm: {len(df)-aneurysm_present:,} ({(len(df)-aneurysm_present)/len(df)*100:.1f}%)\")\n    \n    # Create train/val split\n    print(\"\\n‚úÇÔ∏è  Creating train/validation split...\")\n    train_df, val_df = stratified_split(df, seed=args.seed)\n    print(f\"‚úÖ Train: {len(train_df):,} samples\")\n    print(f\"‚úÖ Val: {len(val_df):,} samples\")\n    \n    # Create datasets\n    print(f\"\\nüîÑ Creating datasets with image size {args.img_size}x{args.img_size}...\")\n    series_dir = os.path.join(args.data_dir, \"series\")\n    print(f\"üìÇ Series directory: {series_dir}\")\n    \n    print(\"   ‚Ä¢ Building training dataset...\")\n    train_dataset = MIPDataset(train_df, series_dir, args.img_size)\n    print(\"   ‚Ä¢ Building validation dataset...\")\n    val_dataset = MIPDataset(val_df, series_dir, args.img_size)\n    print(\"‚úÖ Datasets created successfully\")\n    \n    # Create optimized data loaders\n    print(f\"\\nüì¶ Creating optimized data loaders (batch_size={args.batch_size}, workers={args.num_workers})...\")\n    \n    loader_kwargs = {\n        'batch_size': args.batch_size,\n        'shuffle': True,\n        'num_workers': args.num_workers,\n        'drop_last': True\n    }\n    if device_str == \"cuda\":\n        loader_kwargs['pin_memory'] = True\n    if args.num_workers > 0:\n        loader_kwargs['persistent_workers'] = True\n        loader_kwargs['prefetch_factor'] = Config.PREFETCH_FACTOR\n    train_loader = DataLoader(train_dataset, **loader_kwargs)\n    \n    val_loader_kwargs = {\n        'batch_size': args.batch_size,\n        'shuffle': False,\n        'num_workers': args.num_workers,\n        'drop_last': False\n    }\n    if device_str == \"cuda\":\n        val_loader_kwargs['pin_memory'] = True\n    if args.num_workers > 0:\n        val_loader_kwargs['persistent_workers'] = True\n        val_loader_kwargs['prefetch_factor'] = Config.PREFETCH_FACTOR\n    val_loader = DataLoader(val_dataset, **val_loader_kwargs)\n    \n    print(f\"‚úÖ Train batches: {len(train_loader)}\")\n    print(f\"‚úÖ Val batches: {len(val_loader)}\")\n    \n    # Build model\n    print(\"\\nüèóÔ∏è  Building model...\")\n    model = build_efficientnet_b0(n_out=len(Config.TARGET_COLS))\n    model = model.to(device_str)\n    param_count = count_params(model)\n    print(f\"‚úÖ EfficientNet-B0 loaded with {param_count:,} parameters\")\n    print(f\"‚úÖ Model moved to {device_str}\")\n    \n    # Positive weights\n    print(\"\\n‚öñÔ∏è  Computing positive weights for imbalanced classes...\")\n    pos_weights = []\n    for i, col in enumerate(Config.TARGET_COLS):\n        pos_count = train_df[col].sum()\n        neg_count = len(train_df) - pos_count\n        if pos_count > 0:\n            pos_weight = min(max(neg_count / pos_count, 1.0), 50.0)\n        else:\n            pos_weight = 1.0\n        pos_weights.append(pos_weight)\n        if i < 5:\n            print(f\"   ‚Ä¢ {col}: {pos_weight:.2f}\")\n        elif i == 5:\n            print(f\"   ‚Ä¢ ... and {len(Config.TARGET_COLS)-5} more columns\")\n    pos_weights = torch.tensor(pos_weights, device=device_str)\n    print(f\"‚úÖ Positive weights computed and applied\")\n    \n    # Training components\n    print(\"\\nüîß Setting up training components...\")\n    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n    print(f\"‚úÖ Loss: BCEWithLogitsLoss with positive weighting\")\n    print(f\"‚úÖ Optimizer: AdamW (lr={args.lr}, weight_decay=1e-4)\")\n    print(f\"‚úÖ Scheduler: CosineAnnealingLR (T_max={args.epochs})\")\n    \n    # Training loop\n    best_auc = 0.0\n    best_checkpoint = None\n    epoch_times = []\n    \n    print(f\"\\nüéØ Starting training for {args.epochs} epochs...\")\n    print(\"=\" * 60)\n    \n    for epoch in range(args.epochs):\n        epoch_start = time.time()\n        print(f\"\\nüìÖ EPOCH {epoch + 1}/{args.epochs}\")\n        print(\"-\" * 40)\n        \n        # Training\n        print(\"üèÉ Training phase...\")\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        \n        train_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False, ncols=100)\n        for batch_idx, (x, y, _) in enumerate(train_bar):\n            x, y = x.to(device_str), y.to(device_str)\n            optimizer.zero_grad()\n            outputs = model(x)\n            loss = criterion(outputs, y)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            preds = (torch.sigmoid(outputs) > 0.5).float()\n            train_correct += (preds == y).sum().item()\n            train_total += y.numel()\n            \n            avg_loss = train_loss / (batch_idx + 1)\n            avg_acc = train_correct / train_total if train_total > 0 else 0\n            train_bar.set_postfix({'Loss': f'{avg_loss:.4f}', 'Acc': f'{avg_acc:.3f}', 'LR': f'{scheduler.get_last_lr()[0]:.2e}'})\n        \n        train_loss /= len(train_loader)\n        train_acc = train_correct / train_total if train_total > 0 else 0\n        \n        # Validation\n        print(\"üß™ Validation phase...\")\n        model.eval()\n        val_loss = 0.0\n        all_preds = []\n        all_targets = []\n        \n        val_bar = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\", leave=False, ncols=100)\n        with torch.no_grad():\n            for x, y, _ in val_bar:\n                x, y = x.to(device_str), y.to(device_str)\n                outputs = model(x)\n                loss = criterion(outputs, y)\n                val_loss += loss.item()\n                probs = torch.sigmoid(outputs)\n                all_preds.append(probs.cpu().numpy())\n                all_targets.append(y.cpu().numpy())\n                val_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n        \n        val_loss /= len(val_loader)\n        print(\"üìä Computing metrics...\")\n        all_preds = np.vstack(all_preds)\n        all_targets = np.vstack(all_targets)\n        column_aucs, macro_auc = compute_auc_per_column(all_targets, all_preds, Config.TARGET_COLS)\n        \n        # Epoch results\n        epoch_time = time.time() - epoch_start\n        epoch_times.append(epoch_time)\n        avg_epoch_time = np.mean(epoch_times)\n        remaining_epochs = args.epochs - (epoch + 1)\n        eta = remaining_epochs * avg_epoch_time\n        \n        print(f\"\\nüìà EPOCH {epoch + 1} RESULTS:\")\n        print(f\"   ‚è±Ô∏è  Time: {epoch_time:.1f}s (Avg: {avg_epoch_time:.1f}s)\")\n        print(f\"   üéØ Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.3f}\")\n        print(f\"   üß™ Val Loss: {val_loss:.4f}\")\n        print(f\"   üèÜ Macro AUC: {macro_auc:.4f}\")\n        print(f\"   ‚è≥ ETA: {eta/60:.1f} minutes\")\n        \n        print(f\"\\nüîë Key Column AUCs:\")\n        key_cols = [\"Aneurysm Present\", \"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\", \"Basilar Tip\"]\n        for col in key_cols:\n            if col in column_aucs and not np.isnan(column_aucs[col]):\n                print(f\"   ‚Ä¢ {col}: {column_aucs[col]:.4f}\")\n        \n        # Save best\n        if macro_auc > best_auc:\n            best_auc = macro_auc\n            checkpoint = {\n                'epoch': epoch + 1,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'auc_macro': macro_auc,\n                'target_cols': Config.TARGET_COLS,\n                'config': {\n                    'img_size': args.img_size,\n                    'batch_size': args.batch_size,\n                    'lr': args.lr,\n                    'seed': args.seed\n                }\n            }\n            checkpoint_path = args.out\n            torch.save(checkpoint, checkpoint_path)\n            best_checkpoint = checkpoint_path\n            print(f\"\\nüíæ üÜï NEW BEST CHECKPOINT SAVED!\")\n            print(f\"   üìÅ Path: {checkpoint_path}\")\n            print(f\"   üèÜ Previous Best ‚Üí New Best: {macro_auc:.4f}\")\n        else:\n            print(f\"\\nüíæ Checkpoint not saved (current: {macro_auc:.4f} ‚â§ best: {best_auc:.4f})\")\n        \n        scheduler.step()\n        print(\"-\" * 40)\n    \n    total_time = time.time() - start_time\n    print(\"\\n\" + \"=\" * 60)\n    print(\"üéâ TRAINING COMPLETED!\")\n    print(\"=\" * 60)\n    print(f\"‚è±Ô∏è  Total Time: {total_time/60:.1f} minutes\")\n    print(f\"üèÜ Best Macro AUC: {best_auc:.4f}\")\n    print(f\"üíæ Best Checkpoint: {best_checkpoint}\")\n    print(f\"üìä Final Results:\")\n    print(f\"   ‚Ä¢ Train samples: {len(train_df):,}\")\n    print(f\"   ‚Ä¢ Val samples: {len(val_df):,}\")\n    print(f\"   ‚Ä¢ Model parameters: {param_count:,}\")\n    print(f\"   ‚Ä¢ Image size: {args.img_size}x{args.img_size}\")\n    print(f\"   ‚Ä¢ Batch size: {args.batch_size}\")\n    print(f\"   ‚Ä¢ Learning rate: {args.lr}\")\n    print(\"=\" * 60)\n    \n    return best_checkpoint\n\n# =============================================================================\n# JUPYTER-FRIENDLY FUNCTIONS\n# =============================================================================\n\ndef train_model_jupyter(data_dir=None, img_size=None, batch_size=None, epochs=None, \n                        lr=None, num_workers=None, seed=None, out=None, use_cache=None,\n                        benchmark_mode=False):\n    \"\"\"Jupyter-friendly training function.\"\"\"\n    if use_cache is not None:\n        Config.USE_CACHE = use_cache\n    \n    class Args:\n        def __init__(self):\n            self.data_dir = data_dir or Config.DATA_DIR\n            self.img_size = img_size or Config.IMG_SIZE\n            self.batch_size = batch_size or Config.BATCH_SIZE\n            self.epochs = epochs or Config.EPOCHS\n            self.lr = lr or Config.LR\n            self.num_workers = num_workers if num_workers is not None else Config.DEFAULT_WORKERS\n            self.seed = seed or Config.SEED\n            self.out = out or '/kaggle/working/best.pt'\n            self.benchmark_mode = benchmark_mode\n    args = Args()\n    return train_model(args)\n\ndef run_inference_jupyter(ckpt, data_dir=None, uids_csv=None, out_csv=None):\n    \"\"\"Jupyter-friendly inference function.\"\"\"\n    class Args:\n        def __init__(self):\n            self.ckpt = ckpt\n            self.data_dir = data_dir or Config.DATA_DIR\n            self.uids_csv = uids_csv\n            self.out_csv = out_csv or '/kaggle/working/preds.csv'\n    args = Args()\n    return run_inference(args)\n\ndef check_dicom_decoders():\n    \"\"\"Check if proper DICOM decoders are installed for optimal performance.\"\"\"\n    print(\"üîç DICOM DECODER CHECK\")\n    print(\"=\" * 40)\n    try:\n        import pydicom\n        print(f\"‚úÖ Pydicom version: {pydicom.__version__}\")\n    except ImportError:\n        print(\"‚ùå Pydicom not installed\")\n        return False\n    \n    decoders_installed = True\n    try:\n        import pylibjpeg\n        print(\"‚úÖ pylibjpeg: Installed\")\n    except ImportError:\n        print(\"‚ùå pylibjpeg: NOT installed (will use slow Python fallback)\")\n        decoders_installed = False\n    try:\n        import pylibjpeg_libjpeg\n        print(\"‚úÖ pylibjpeg-libjpeg: Installed\")\n    except ImportError:\n        print(\"‚ùå pylibjpeg-libjpeg: NOT installed (JPEG decoding may be slow)\")\n        decoders_installed = False\n    try:\n        import pylibjpeg_openjpeg\n        print(\"‚úÖ pylibjpeg-openjpeg: Installed\")\n    except ImportError:\n        print(\"‚ùå pylibjpeg-openjpeg: NOT installed (JPEG2000 decoding may be slow)\")\n        decoders_installed = False\n    try:\n        import pylibjpeg_rle\n        print(\"‚úÖ pylibjpeg-rle: Installed\")\n    except ImportError:\n        print(\"‚ùå pylibjpeg-rle: NOT installed (RLE decoding may be slow)\")\n        decoders_installed = False\n    \n    if decoders_installed:\n        print(\"\\nüéâ All DICOM decoders installed! Optimal performance expected.\")\n    else:\n        print(\"\\n‚ö†Ô∏è  Some DICOM decoders missing. Install with:\")\n        print(\"   pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg pylibjpeg-rle\")\n        print(\"   This will significantly improve DICOM processing speed.\")\n    print(\"=\" * 40)\n    return decoders_installed\n\ndef quick_test():\n    \"\"\"Quick test function to verify the code works in Jupyter.\"\"\"\n    print(\"üß™ QUICK TEST MODE\")\n    print(\"=\" * 40)\n    try:\n        print(\"‚úÖ Testing imports...\")\n        import numpy as np  # noqa\n        import pandas as pd  # noqa\n        import torch  # noqa\n        import torchvision  # noqa\n        import cv2  # noqa\n        import pydicom  # noqa\n        print(\"   ‚Ä¢ All required packages imported successfully\")\n        print(\"‚úÖ Testing device detection...\")\n        device_str = device()\n        print(f\"   ‚Ä¢ Device: {device_str}\")\n        print(\"‚úÖ Testing model building...\")\n        model = build_efficientnet_b0(n_out=14)\n        param_count = count_params(model)\n        print(f\"   ‚Ä¢ Model built with {param_count:,} parameters\")\n        print(\"‚úÖ Testing configuration...\")\n        print(f\"   ‚Ä¢ Target columns: {len(Config.TARGET_COLS)}\")\n        print(f\"   ‚Ä¢ Image size: {Config.IMG_SIZE}\")\n        print(f\"   ‚Ä¢ Batch size: {Config.BATCH_SIZE}\")\n        print(f\"   ‚Ä¢ Default workers: {Config.DEFAULT_WORKERS}\")\n        print(\"‚úÖ Testing data directory...\")\n        data_dir = Config.DATA_DIR\n        if os.path.exists(data_dir):\n            print(f\"   ‚Ä¢ Data directory exists: {data_dir}\")\n            train_csv = os.path.join(data_dir, \"train.csv\")\n            if os.path.exists(train_csv):\n                print(f\"   ‚Ä¢ Training CSV found: {train_csv}\")\n                try:\n                    df = pd.read_csv(train_csv, nrows=5)\n                    print(f\"   ‚Ä¢ CSV readable: {len(df)} sample rows loaded\")\n                except Exception as e:\n                    print(f\"   ‚Ä¢ CSV read error: {e}\")\n            else:\n                print(f\"   ‚Ä¢ Training CSV not found: {train_csv}\")\n        else:\n            print(f\"   ‚Ä¢ Data directory not found: {data_dir}\")\n            print(\"   ‚Ä¢ This is expected if you haven't attached the Kaggle dataset yet\")\n        print(\"\\nüéâ ALL TESTS PASSED! The code is ready to use.\")\n    except Exception as e:\n        print(f\"\\n‚ùå Test failed: {e}\")\n        print(\"Please check your installation and try again.\")\n\ndef clear_mip_cache():\n    \"\"\"Clear the MIP cache directory.\"\"\"\n    print(\"üßπ CLEARING MIP CACHE\")\n    print(\"=\" * 40)\n    cache_dir = Config.CACHE_DIR\n    if os.path.exists(cache_dir):\n        import shutil\n        try:\n            shutil.rmtree(cache_dir)\n            print(f\"‚úÖ Cache directory cleared: {cache_dir}\")\n        except Exception as e:\n            print(f\"‚ùå Failed to clear cache: {e}\")\n    else:\n        print(f\"‚ÑπÔ∏è  Cache directory doesn't exist: {cache_dir}\")\n    print(\"=\" * 40)\n\ndef clear_old_cache_versions():\n    \"\"\"Clear cache files from old versions to prevent silent bugs.\"\"\"\n    print(\"üîÑ CLEARING OLD CACHE VERSIONS\")\n    print(\"=\" * 40)\n    cache_dir = Config.CACHE_DIR\n    if not os.path.exists(cache_dir):\n        print(\"‚ÑπÔ∏è  Cache directory doesn't exist\")\n        return\n    cleared_count = 0\n    for filename in os.listdir(cache_dir):\n        if filename.endswith('.npy'):\n            file_path = os.path.join(cache_dir, filename)\n            try:\n                test_load = np.load(file_path, allow_pickle=False)\n                if test_load.dtype != np.uint8:\n                    os.remove(file_path)\n                    cleared_count += 1\n                    print(f\"   ‚Ä¢ Removed old format file: {filename}\")\n            except Exception:\n                os.remove(file_path)\n                cleared_count += 1\n                print(f\"   ‚Ä¢ Removed corrupted/old file: {filename}\")\n    if cleared_count == 0:\n        print(\"‚úÖ No old cache files found\")\n    else:\n        print(f\"‚úÖ Cleared {cleared_count} old cache files\")\n    print(\"=\" * 40)\n\ndef get_cache_info():\n    \"\"\"Get information about the MIP cache.\"\"\"\n    print(\"üìä MIP CACHE INFO\")\n    print(\"=\" * 40)\n    cache_dir = Config.CACHE_DIR\n    print(f\"Cache directory: {cache_dir}\")\n    print(f\"Cache enabled: {Config.USE_CACHE}\")\n    print(f\"Cache version: {Config.CACHE_VERSION}\")\n    if os.path.exists(cache_dir):\n        cache_files = [f for f in os.listdir(cache_dir) if f.endswith('.npy')]\n        total_size = 0\n        for f in cache_files:\n            file_path = os.path.join(cache_dir, f)\n            total_size += os.path.getsize(file_path)\n        print(f\"‚úÖ Cache files: {len(cache_files)}\")\n        print(f\"‚úÖ Total size: {total_size / (1024*1024):.1f} MB\")\n        print(f\"‚úÖ Avg size per file: {total_size / (1024*1024) / len(cache_files):.2f} MB\" if cache_files else \"N/A\")\n        if cache_files:\n            print(\"\\nRecent cache files:\")\n            cache_files.sort(key=lambda x: os.path.getmtime(os.path.join(cache_dir, x)), reverse=True)\n            for f in cache_files[:5]:\n                file_path = os.path.join(cache_dir, f)\n                mtime = time.ctime(os.path.getmtime(file_path))\n                size_mb = os.path.getsize(file_path) / (1024*1024)\n                print(f\"   ‚Ä¢ {f}: {size_mb:.1f} MB ({mtime})\")\n    else:\n        print(\"‚ÑπÔ∏è  Cache directory doesn't exist yet\")\n    print(\"=\" * 40)\n\ndef check_data_directory():\n    \"\"\"Check if the Kaggle data directory exists and show its contents.\"\"\"\n    print(\"üìÅ DATA DIRECTORY CHECK\")\n    print(\"=\" * 40)\n    data_dir = Config.DATA_DIR\n    print(f\"Expected data directory: {data_dir}\")\n    if os.path.exists(data_dir):\n        print(\"‚úÖ Data directory exists!\")\n        train_csv = os.path.join(data_dir, \"train.csv\")\n        if os.path.exists(train_csv):\n            print(\"‚úÖ Training CSV found!\")\n            try:\n                df = pd.read_csv(train_csv, nrows=5)\n                print(f\"   ‚Ä¢ Sample data shape: {df.shape}\")\n                print(f\"   ‚Ä¢ Columns: {list(df.columns)}\")\n                print(f\"   ‚Ä¢ Sample SeriesInstanceUID: {df['SeriesInstanceUID'].iloc[0]}\")\n            except Exception as e:\n                print(f\"   ‚Ä¢ Error reading CSV: {e}\")\n        else:\n            print(\"‚ùå Training CSV not found\")\n        series_dir = os.path.join(data_dir, \"series\")\n        if os.path.exists(series_dir):\n            print(\"‚úÖ Series directory found!\")\n            try:\n                series_folders = [f for f in os.listdir(series_dir) if os.path.isdir(os.path.join(series_dir, f))]\n                print(f\"   ‚Ä¢ Number of series folders: {len(series_folders)}\")\n                if series_folders:\n                    sample_series = series_folders[0]\n                    sample_path = os.path.join(series_dir, sample_series)\n                    sample_files = [f for f in os.listdir(sample_path) if os.path.isfile(os.path.join(sample_path, f))]\n                    print(f\"   ‚Ä¢ Sample series '{sample_series}' has {len(sample_files)} files\")\n            except Exception as e:\n                print(f\"   ‚Ä¢ Error checking series directory: {e}\")\n        else:\n            print(\"‚ùå Series directory not found\")\n    else:\n        print(\"‚ùå Data directory not found!\")\n        print(\"\\nüí° To fix this:\")\n        print(\"   1. Make sure you've attached the RSNA dataset to your Kaggle notebook\")\n        print(\"   2. Check the dataset path in the notebook\")\n        print(\"   3. Verify the dataset contains 'train.csv' and 'series/' subdirectory\")\n        print(f\"   4. Expected path: {data_dir}\")\n    print(\"=\" * 40)\n\n# =============================================================================\n# INFERENCE SCRIPT\n# =============================================================================\n\ndef run_inference(args):\n    \"\"\"Main inference function.\"\"\"\n    start_time = time.time()\n    print(\"=\" * 60)\n    print(\"üîç STARTING RSNA IA DETECTION INFERENCE\")\n    print(\"=\" * 60)\n    \n    # Load checkpoint\n    print(\"üìÅ Loading checkpoint...\")\n    checkpoint = torch.load(args.ckpt, map_location='cpu')\n    target_cols = checkpoint['target_cols']\n    config = checkpoint.get('config', {})\n    \n    auc_val = checkpoint.get('auc_macro', None)\n    auc_str = f\"{auc_val:.4f}\" if isinstance(auc_val, (int, float, np.floating)) else \"N/A\"\n    print(f\"‚úÖ Checkpoint loaded from epoch {checkpoint['epoch']}\")\n    print(f\"‚úÖ Target columns: {len(target_cols)}\")\n    print(f\"‚úÖ Checkpoint AUC: {auc_str}\")\n    \n    if config:\n        print(f\"\\n‚öôÔ∏è  Model Configuration:\")\n        for key, value in config.items():\n            print(f\"   ‚Ä¢ {key}: {value}\")\n    \n    # Build model\n    print(f\"\\nüèóÔ∏è  Building model...\")\n    model = build_efficientnet_b0(n_out=len(target_cols))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    \n    device_str = device()\n    model = model.to(device_str)\n    model.eval()\n    print(f\"‚úÖ Model loaded and moved to {device_str}\")\n    print(f\"‚úÖ Model parameters: {count_params(model):,}\")\n    \n    # Load data\n    print(f\"\\nüìä Loading data...\")\n    if args.uids_csv:\n        print(f\"üìã Loading UIDs from: {args.uids_csv}\")\n        uids_df = pd.read_csv(args.uids_csv)\n        uids = uids_df['SeriesInstanceUID'].tolist()\n        print(f\"‚úÖ Loaded {len(uids):,} UIDs from CSV\")\n    else:\n        train_csv = os.path.join(args.data_dir, \"train.csv\")\n        print(f\"üìã Using sample from training data: {train_csv}\")\n        df = pd.read_csv(train_csv)\n        uids = df['SeriesInstanceUID'].head(10).tolist()\n        print(f\"‚úÖ Using sample of {len(uids):,} UIDs from training data\")\n    \n    results = []\n    series_dir = os.path.join(args.data_dir, \"series\")\n    print(f\"üìÇ Series directory: {series_dir}\")\n    \n    print(f\"\\nüöÄ Running inference on {len(uids):,} series...\")\n    print(\"=\" * 60)\n    \n    successful = 0\n    failed = 0\n    processing_times = []\n    \n    for i, uid in enumerate(tqdm(uids, desc=\"Inference\", ncols=100)):\n        uid_start = time.time()\n        try:\n            series_path = safe_series_path(series_dir, uid)\n            mips = make_triplanar_mips_parallel(series_path, out_size=config.get('img_size', 384))\n            x = torch.from_numpy(mips).float().unsqueeze(0).to(device_str)\n            with torch.no_grad():\n                outputs = model(x)\n                probs = torch.sigmoid(outputs).cpu().numpy()[0]\n            result = {'SeriesInstanceUID': uid}\n            for j, col in enumerate(target_cols):\n                result[col] = probs[j]\n            results.append(result)\n            successful += 1\n            if (i + 1) % 10 == 0 or len(uids) <= 20:\n                elapsed = time.time() - start_time\n                avg_time = elapsed / (i + 1)\n                eta = avg_time * (len(uids) - i - 1)\n                print(f\"\\nüìä Progress Update ({i+1}/{len(uids)}):\")\n                print(f\"   ‚Ä¢ Successful: {successful}\")\n                print(f\"   ‚Ä¢ Failed: {failed}\")\n                print(f\"   ‚Ä¢ Elapsed: {elapsed/60:.1f} minutes\")\n                print(f\"   ‚Ä¢ ETA: {eta/60:.1f} minutes\")\n                if i < 3:\n                    aneurysm_prob = probs[-1]\n                    print(f\"   ‚Ä¢ Sample {uid[:8]}...: Aneurysm Present = {aneurysm_prob:.4f}\")\n        except Exception as e:\n            print(f\"\\n‚ùå Error processing {uid}: {e}\")\n            result = {'SeriesInstanceUID': uid}\n            for col in target_cols:\n                result[col] = np.nan\n            results.append(result)\n            failed += 1\n        uid_time = time.time() - uid_start\n        processing_times.append(uid_time)\n    \n    total_time = time.time() - start_time\n    avg_processing_time = np.mean(processing_times) if processing_times else 0\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"üìä INFERENCE COMPLETED!\")\n    print(\"=\" * 60)\n    print(f\"‚è±Ô∏è  Total Time: {total_time/60:.1f} minutes\")\n    print(f\"‚úÖ Successful: {successful:,}\")\n    print(f\"‚ùå Failed: {failed:,}\")\n    print(f\"üìà Success Rate: {successful/(successful+failed)*100:.1f}%\")\n    print(f\"‚ö° Avg Processing Time: {avg_processing_time:.2f}s per series\")\n    \n    print(f\"\\nüíæ Saving results...\")\n    results_df = pd.DataFrame(results)\n    results_df.to_csv(args.out_csv, index=False)\n    print(f\"‚úÖ Results saved to: {args.out_csv}\")\n    print(f\"üìä Output shape: {results_df.shape}\")\n    \n    if len(results_df) > 0:\n        print(f\"\\nüîç Sample Results:\")\n        sample_cols = [\"SeriesInstanceUID\"] + target_cols[-3:]\n        sample_df = results_df[sample_cols].head(3)\n        for _, row in sample_df.iterrows():\n            uid_short = row['SeriesInstanceUID'][:8] + \"...\"\n            aneurysm_prob = row.get('Aneurysm Present', 'N/A')\n            print(f\"   ‚Ä¢ {uid_short}: Aneurysm Present = {aneurysm_prob}\")\n    print(\"=\" * 60)\n    return results_df\n\n# =============================================================================\n# MAIN EXECUTION\n# =============================================================================\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    print(\"üß† RSNA Intracranial Aneurysm Detection\")\n    print(\"   Tri-planar MIP Baseline Implementation\")\n    print(\"   \" + \"=\" * 50)\n    \n    # Check if we're running in Jupyter/IPython\n    try:\n        get_ipython()\n        # We're in Jupyter - show usage instructions\n        print(\"\\nüìö JUPYTER NOTEBOOK MODE DETECTED!\")\n        print(\"=\" * 50)\n        print(\"To use this script in Jupyter, call the functions directly:\")\n        print()\n        print(\"üéØ For Training:\")\n        print(\"   train_model_jupyter()  # Basic training\")\n        print(\"   train_model_jupyter(num_workers=2, batch_size=8)  # Optimized\")\n        print(\"   train_model_jupyter(benchmark_mode=True)  # Max speed\")\n        print()\n        print(\"üîç For Inference:\")\n        print(\"   run_inference_jupyter(ckpt='/kaggle/working/best.pt')\")\n        print()\n        print(\"üìã For Testing & Cache Management:\")\n        print(\"   check_dicom_decoders()      # Check DICOM decoder performance\")\n        print(\"   quick_test()                # Test all components\")\n        print(\"   get_cache_info()            # Check MIP cache status\")\n        print(\"   clear_mip_cache()           # Clear all cached MIPs\")\n        print(\"   clear_old_cache_versions()  # Clear old version cache files\")\n        print(\"   check_data_directory()      # Verify dataset\")\n        print()\n        print(\"‚ö° PERFORMANCE OPTIMIZATIONS:\")\n        print(f\"   ‚Ä¢ TRUE on-the-fly MIP reduction (no RAM buildup)\")\n        print(f\"   ‚Ä¢ Completion-order parallel processing\")\n        print(f\"   ‚Ä¢ Normalize once after reduction\")\n        print(f\"   ‚Ä¢ Conservative defaults (workers={Config.DEFAULT_WORKERS})\")\n        print(f\"   ‚Ä¢ Smart fallback for large series (>{Config.LARGE_SERIES_THRESHOLD} slices)\")\n        print(f\"   ‚Ä¢ Fast uint8 caching ({'ON' if Config.USE_CACHE else 'OFF'})\")\n        print(f\"   ‚Ä¢ Cache version: {Config.CACHE_VERSION}\")\n        print(\"=\" * 50)\n        return\n    except NameError:\n        # Not in Jupyter; proceed with argparse\n        pass\n    \n    parser = argparse.ArgumentParser(description=\"RSNA IA Detection Training/Inference\")\n    subparsers = parser.add_subparsers(dest='command', help='Command to run')\n    \n    # Training parser\n    train_parser = subparsers.add_parser('train', help='Train the model')\n    train_parser.add_argument('--data_dir', type=str, default=Config.DATA_DIR, help='Data directory path')\n    train_parser.add_argument('--img_size', type=int, default=Config.IMG_SIZE, help='Image size')\n    train_parser.add_argument('--batch_size', type=int, default=Config.BATCH_SIZE, help='Batch size')\n    train_parser.add_argument('--epochs', type=int, default=Config.EPOCHS, help='Number of epochs')\n    train_parser.add_argument('--lr', type=float, default=Config.LR, help='Learning rate')\n    train_parser.add_argument('--num_workers', type=int, default=Config.NUM_WORKERS, help='Number of data loader workers')\n    train_parser.add_argument('--seed', type=int, default=Config.SEED, help='Random seed')\n    train_parser.add_argument('--out', type=str, default='/kaggle/working/best.pt', help='Output checkpoint path')\n    train_parser.add_argument('--benchmark_mode', action='store_true', help='Enable cuDNN benchmark for speed over reproducibility')\n    \n    # Inference parser\n    infer_parser = subparsers.add_parser('infer', help='Run inference')\n    infer_parser.add_argument('--ckpt', type=str, required=True, help='Checkpoint path')\n    infer_parser.add_argument('--data_dir', type=str, default=Config.DATA_DIR, help='Data directory path')\n    infer_parser.add_argument('--uids_csv', type=str, default=None, help='CSV with UIDs to process (optional)')\n    infer_parser.add_argument('--out_csv', type=str, default='/kaggle/working/preds.csv', help='Output CSV path')\n    \n    args = parser.parse_args()\n    if args.command == 'train':\n        print(f\"\\nüéØ Starting TRAINING mode...\")\n        print(f\"   ‚Ä¢ Data directory: {args.data_dir}\")\n        print(f\"   ‚Ä¢ Image size: {args.img_size}x{args.img_size}\")\n        print(f\"   ‚Ä¢ Batch size: {args.batch_size}\")\n        print(f\"   ‚Ä¢ Epochs: {args.epochs}\")\n        print(f\"   ‚Ä¢ Learning rate: {args.lr}\")\n        print(f\"   ‚Ä¢ Workers: {args.num_workers}\")\n        print(f\"   ‚Ä¢ Output: {args.out}\")\n        if getattr(args, 'benchmark_mode', False):\n            print(f\"   ‚Ä¢ CuDNN benchmark: ENABLED\")\n        print(\"   \" + \"-\" * 50)\n        train_model(args)\n    elif args.command == 'infer':\n        print(f\"\\nüîç Starting INFERENCE mode...\")\n        print(f\"   ‚Ä¢ Checkpoint: {args.ckpt}\")\n        print(f\"   ‚Ä¢ Data directory: {args.data_dir}\")\n        print(f\"   ‚Ä¢ Output CSV: {args.out_csv}\")\n        if args.uids_csv:\n            print(f\"   ‚Ä¢ UIDs CSV: {args.uids_csv}\")\n        else:\n            print(f\"   ‚Ä¢ UIDs: Using sample from training data\")\n        print(\"   \" + \"-\" * 50)\n        run_inference(args)\n    else:\n        print(\"\\n‚ùì No command specified. Use --help for options.\")\n        parser.print_help()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-08-28T13:19:07.011154Z","iopub.execute_input":"2025-08-28T13:19:07.011430Z","iopub.status.idle":"2025-08-28T13:19:16.389814Z","shell.execute_reply.started":"2025-08-28T13:19:07.011411Z","shell.execute_reply":"2025-08-28T13:19:16.389111Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"train_model_jupyter(num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2025-08-28T13:19:35.193298Z","iopub.execute_input":"2025-08-28T13:19:35.193776Z"},"_kg_hide-output":true,"jupyter":{"outputs_hidden":true},"collapsed":true}},{"cell_type":"markdown","source":"# **TEST 2** ","metadata":{}},{"cell_type":"markdown","source":"Fixing the **MIP**  and also lessening the jargons to see where we reach","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nRSNA Intracranial Aneurysm Detection - Tri-planar MIP (Stable, runs on Kaggle)\n\nWhat changed to fix your error:\n- Replaced the \"compressed header guess\" with a real quick test decode:\n  we try ds.pixel_array on the first slice; if it works, we keep the series.\n- If filtering keeps 0 items, we FALL BACK to an unfiltered subset so training\n  still runs and completes.\n- Dataset __getitem__ has a last-resort fallback (returns zeros) to avoid crashes.\n\nUsage after loading this cell:\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=288, batch_size=2, epochs=1, num_workers=0, benchmark_mode=True\n)\n\"\"\"\n\nimport os, time, random, warnings, hashlib\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nwarnings.filterwarnings(\"ignore\")\n\n# =============================================================================\n# CONFIG\n# =============================================================================\nclass Config:\n    DATA_DIR   = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\n    SERIES_DIR = f\"{DATA_DIR}/series\"\n    TRAIN_CSV  = f\"{DATA_DIR}/train.csv\"\n\n    IMG_SIZE   = 288\n    BATCH_SIZE = 2\n    EPOCHS     = 1\n    LR         = 2e-4\n    NUM_WORKERS= 0\n    SEED       = 42\n    USE_AMP    = True\n\n    LOG_EVERY_N = 50\n    USE_CACHE = True\n    CACHE_DIR = \"/kaggle/working/mip_cache\"\n    CACHE_VERSION = \"v4.2\"\n\n    # Always use streaming (low RAM)\n    LARGE_SERIES_THRESHOLD = 1\n    MAX_WORKERS = 1\n\n    # Keep a subset so one epoch completes quickly. Set both to None to use ALL.\n    SMOKE_TRAIN_LIMIT = 600\n    SMOKE_VAL_LIMIT   = 200\n\n    TARGET_COLS = [\n        \"Left Infraclinoid Internal Carotid Artery\",\n        \"Right Infraclinoid Internal Carotid Artery\",\n        \"Left Supraclinoid Internal Carotid Artery\",\n        \"Right Supraclinoid Internal Carotid Artery\",\n        \"Left Middle Cerebral Artery\",\n        \"Right Middle Cerebral Artery\",\n        \"Anterior Communicating Artery\",\n        \"Left Anterior Cerebral Artery\",\n        \"Right Anterior Cerebral Artery\",\n        \"Left Posterior Communicating Artery\",\n        \"Right Posterior Communicating Artery\",\n        \"Basilar Tip\",\n        \"Other Posterior Circulation\",\n        \"Aneurysm Present\",\n    ]\n\ndef set_seed(seed=42, benchmark_mode=False):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = not benchmark_mode\n    torch.backends.cudnn.benchmark     = benchmark_mode\n\ndef device() -> str:\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# =============================================================================\n# DICOM I/O & MIP (streaming)\n# =============================================================================\ndef iter_dicom_files(series_path: str) -> List[str]:\n    sp = Path(series_path)\n    dcm_files = list(sp.glob(\"*.dcm\"))\n    if not dcm_files:\n        dcm_files = [f for f in sp.iterdir() if f.is_file() and not f.suffix]\n    if not dcm_files:\n        return []\n    infos = []\n    for f in dcm_files:\n        try:\n            ds = pydicom.dcmread(str(f), stop_before_pixels=True, force=True)\n            ins = getattr(ds, \"InstanceNumber\", 0)\n        except Exception:\n            ins = 0\n        infos.append((ins, str(f)))\n    infos.sort(key=lambda x: (x[0], x[1]))\n    return [p for _, p in infos]\n\ndef _ensure_gray2d(img: np.ndarray) -> np.ndarray:\n    if img.ndim == 3:\n        if img.shape[-1] == 3:\n            img = np.mean(img, axis=-1)\n        else:\n            img = img.max(axis=-1)\n    return img.astype(np.float32)\n\ndef window_ct(img: np.ndarray, level=200, width=500) -> np.ndarray:\n    img = img.astype(np.float32)\n    lo, hi = level - width/2.0, level + width/2.0\n    img = np.clip(img, lo, hi)\n    img = (img - lo) / max(1e-6, (hi - lo))\n    return np.clip(img, 0, 1)\n\ndef normalize_mr(img: np.ndarray) -> np.ndarray:\n    img = img.astype(np.float32)\n    p1, p99 = np.percentile(img, [1, 99])\n    img = np.clip(img, p1, p99)\n    if p99 > p1:\n        img = (img - p1) / (p99 - p1)\n    return np.clip(img, 0, 1)\n\ndef _cache_path(series_path: str, out_size: int, modality_hint: Optional[str]) -> str:\n    os.makedirs(Config.CACHE_DIR, exist_ok=True)\n    key = f\"{Config.CACHE_VERSION}_{os.path.basename(series_path)}_{modality_hint or 'unk'}_{out_size}\"\n    h = hashlib.md5(key.encode()).hexdigest()[:16]\n    return os.path.join(Config.CACHE_DIR, f\"mip_{h}.npy\")\n\ndef _load_cache(path: str) -> Optional[np.ndarray]:\n    try:\n        if not Config.USE_CACHE or not os.path.exists(path):\n            return None\n        arr = np.load(path, allow_pickle=False)\n        return arr.astype(np.float32) / 255.0\n    except Exception:\n        return None\n\ndef _save_cache(arr: np.ndarray, path: str):\n    if not Config.USE_CACHE: return\n    try:\n        np.save(path, (arr * 255).astype(np.uint8), allow_pickle=False)\n    except Exception:\n        pass\n\ndef make_triplanar_mips_stream(series_path: str, modality_hint: Optional[str], out_size: int) -> np.ndarray:\n    cache = _cache_path(series_path, out_size, modality_hint)\n    cached = _load_cache(cache)\n    if cached is not None:\n        return cached\n\n    files = iter_dicom_files(series_path)\n    if not files:\n        raise RuntimeError(\"No DICOMs in series\")\n\n    axial = None\n    cor_rows = None  # (Z, W)\n    sag_cols = None  # (Z, H)\n\n    z = 0\n    H = W = None\n    for f in files:\n        try:\n            ds = pydicom.dcmread(f, force=True)\n            arr = ds.pixel_array  # let pydicom decide; if it fails we skip this slice\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            img = _ensure_gray2d(arr)\n\n            if axial is None:\n                H, W = img.shape\n                axial = img.copy()\n                cor_rows = np.zeros((len(files), W), dtype=np.float32)\n                sag_cols = np.zeros((len(files), H), dtype=np.float32)\n            else:\n                np.maximum(axial, img, out=axial)\n\n            cor_rows[z, :] = img.max(axis=0)\n            sag_cols[z, :] = img.max(axis=1)\n            z += 1\n        except Exception:\n            # skip a bad/unsupported slice\n            continue\n\n    if axial is None:\n        raise RuntimeError(\"No decodable slices in series\")\n\n    if modality_hint and str(modality_hint).upper() in [\"CT\", \"CTA\"]:\n        axial = window_ct(axial);    cor_rows = window_ct(cor_rows); sag_cols = window_ct(sag_cols)\n    else:\n        axial = normalize_mr(axial); cor_rows = normalize_mr(cor_rows); sag_cols = normalize_mr(sag_cols)\n\n    axial    = cv2.resize(axial,    (out_size, out_size), interpolation=cv2.INTER_AREA)\n    coronal  = cv2.resize(cor_rows, (out_size, out_size), interpolation=cv2.INTER_AREA)\n    sagittal = cv2.resize(sag_cols, (out_size, out_size), interpolation=cv2.INTER_AREA)\n\n    mips = np.stack([axial, coronal, sagittal], axis=0).astype(np.float32)\n    _save_cache(mips, cache)\n    return mips\n\n# =============================================================================\n# DATASET & FILTERING\n# =============================================================================\ndef stratified_split(df: pd.DataFrame, global_col=\"Aneurysm Present\", seed=42, n_splits=5):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    tr_idx, va_idx = next(skf.split(df, df[global_col]))\n    return df.iloc[tr_idx].copy(), df.iloc[va_idx].copy()\n\ndef safe_series_path(series_dir: str, uid: str) -> str:\n    p = os.path.join(series_dir, str(uid))\n    if not os.path.exists(p):\n        raise FileNotFoundError(p)\n    return p\n\ndef _quick_series_decode_ok(series_path: str) -> bool:\n    \"\"\"Robust, version-agnostic decodability test: actually try to decode ONE slice.\"\"\"\n    try:\n        files = iter_dicom_files(series_path)\n        if not files:\n            return False\n        ds = pydicom.dcmread(files[0], force=True)\n        _ = ds.pixel_array  # raises if unsupported\n        return True\n    except Exception:\n        return False\n\ndef filter_decodable_df(df: pd.DataFrame, series_dir: str) -> pd.DataFrame:\n    uids = df[\"SeriesInstanceUID\"].astype(str).tolist()\n    keep_mask = []\n    for uid in uids:\n        sp = os.path.join(series_dir, uid)\n        keep_mask.append(_quick_series_decode_ok(sp))\n    kept = df[keep_mask].reset_index(drop=True)\n    print(f\"Decodable series (quick test): {len(kept)}/{len(df)} kept\")\n    return kept\n\nclass MIPDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, series_dir: str, out_size: int):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.out_size = out_size\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss:\n            raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n        modality_hint = row.get(\"Modality\", None)\n\n        try:\n            mips = make_triplanar_mips_stream(sp, modality_hint, self.out_size)\n        except Exception:\n            # Last-resort fallback to keep training running\n            mips = np.zeros((3, self.out_size, self.out_size), dtype=np.float32)\n\n        x = torch.from_numpy(mips).float()\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\n# =============================================================================\n# MODEL / METRICS\n# =============================================================================\ndef build_efficientnet_b0(n_out=14) -> nn.Module:\n    try:\n        model = torchvision.models.efficientnet_b0(\n            weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        )\n    except Exception:\n        model = torchvision.models.efficientnet_b0(pretrained=True)\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, n_out)\n    return model\n\ndef compute_auc_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_aucs, vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_aucs[c] = np.nan\n                continue\n            auc = roc_auc_score(y_true[:, i], y_prob[:, i])\n            col_aucs[c] = auc; vals.append(auc)\n        except Exception:\n            col_aucs[c] = np.nan\n    macro = float(np.mean(vals)) if vals else np.nan\n    return col_aucs, macro\n\ndef count_params(m: nn.Module) -> int:\n    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n\n# =============================================================================\n# TRAIN\n# =============================================================================\ndef train_model(args):\n    print(\"== RSNA IA Detection: TRAIN ==\")\n    set_seed(args.seed, getattr(args, \"benchmark_mode\", False))\n    dev = device()\n    print(f\"Device: {dev} | AMP: {Config.USE_AMP}\")\n\n    csv_path = os.path.join(args.data_dir, \"train.csv\")\n    if not os.path.exists(csv_path):\n        raise FileNotFoundError(csv_path)\n    df = pd.read_csv(csv_path)\n    print(f\"Total rows in CSV: {len(df):,}\")\n\n    train_df, val_df = stratified_split(df, seed=args.seed)\n\n    if Config.SMOKE_TRAIN_LIMIT is not None:\n        train_df = train_df.head(Config.SMOKE_TRAIN_LIMIT).copy()\n    if Config.SMOKE_VAL_LIMIT is not None:\n        val_df = val_df.head(Config.SMOKE_VAL_LIMIT).copy()\n\n    series_dir = os.path.join(args.data_dir, \"series\")\n    print(\"Scanning decodability (quick test on first slice of each series)...\")\n    train_keep = filter_decodable_df(train_df, series_dir)\n    val_keep   = filter_decodable_df(val_df,   series_dir)\n\n    # Fallback if we somehow kept nothing: use small unfiltered subset\n    if len(train_keep) == 0:\n        print(\"‚ö†Ô∏è  Decodability filter kept 0 for train ‚Äî falling back to unfiltered subset.\")\n        train_keep = train_df.head(64).copy()\n    if len(val_keep) == 0:\n        print(\"‚ö†Ô∏è  Decodability filter kept 0 for val ‚Äî falling back to unfiltered subset.\")\n        val_keep = val_df.head(32).copy()\n\n    print(f\"Train: {len(train_keep):,} | Val: {len(val_keep):,}\")\n\n    train_ds = MIPDataset(train_keep, series_dir, args.img_size)\n    val_ds   = MIPDataset(val_keep,   series_dir, args.img_size)\n\n    tkw = dict(batch_size=args.batch_size, shuffle=True,  num_workers=args.num_workers, drop_last=True)\n    vkw = dict(batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, drop_last=False)\n    if dev == \"cuda\":\n        tkw[\"pin_memory\"] = True; vkw[\"pin_memory\"] = True\n    train_loader = DataLoader(train_ds, **tkw)\n    val_loader   = DataLoader(val_ds, **vkw)\n\n    model = build_efficientnet_b0(len(Config.TARGET_COLS)).to(dev)\n    print(f\"Model params: {count_params(model):,}\")\n\n    posw = []\n    for c in Config.TARGET_COLS:\n        pos = train_keep[c].sum()\n        neg = len(train_keep) - pos\n        w = min(max((neg / max(1.0, pos)), 1.0), 50.0) if pos > 0 else 1.0\n        posw.append(w)\n    posw = torch.tensor(posw, device=dev)\n\n    criterion = nn.BCEWithLogitsLoss(pos_weight=posw)\n    opt = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n    sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=args.epochs)\n\n    use_amp = (dev == \"cuda\") and Config.USE_AMP\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    best_auc = -1.0\n    best_ckpt = args.out\n\n    for epoch in range(args.epochs):\n        model.train()\n        run_loss = 0.0; correct = 0; total = 0\n        t0 = time.time()\n        for b, (x, y, _) in enumerate(train_loader, 1):\n            x, y = x.to(dev), y.to(dev)\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                out = model(x)\n                loss = criterion(out, y)\n            scaler.scale(loss).backward()\n            scaler.step(opt); scaler.update()\n\n            run_loss += loss.item()\n            preds = (torch.sigmoid(out) > 0.5).float()\n            correct += (preds == y).sum().item(); total += y.numel()\n\n            if b % Config.LOG_EVERY_N == 0 or b == 1:\n                print(f\"[E{epoch+1} {b}/{len(train_loader)}] \"\n                      f\"loss={run_loss/b:.4f} acc={correct/max(1,total):.3f} \"\n                      f\"lr={sch.get_last_lr()[0]:.2e}\")\n\n        train_loss = run_loss / max(1, len(train_loader))\n        train_acc  = correct / max(1, total)\n\n        # Val\n        model.eval()\n        val_loss = 0.0\n        preds_all, targs_all = [], []\n        with torch.no_grad():\n            for x, y, _ in val_loader:\n                x, y = x.to(dev), y.to(dev)\n                with torch.cuda.amp.autocast(enabled=use_amp):\n                    out = model(x); loss = criterion(out, y)\n                val_loss += loss.item()\n                preds_all.append(torch.sigmoid(out).cpu().numpy())\n                targs_all.append(y.cpu().numpy())\n\n        val_loss /= max(1, len(val_loader))\n        P = np.vstack(preds_all) if preds_all else np.zeros((0, len(Config.TARGET_COLS)))\n        T = np.vstack(targs_all) if targs_all else np.zeros((0, len(Config.TARGET_COLS)))\n        _, macro_auc = compute_auc_per_column(T, P, Config.TARGET_COLS)\n\n        dt = time.time() - t0\n        print(f\"Epoch {epoch+1}/{args.epochs} | {dt:.1f}s  \"\n              f\"train_loss={train_loss:.4f} train_acc={train_acc:.3f}  \"\n              f\"val_loss={val_loss:.4f} macro_auc={macro_auc:.4f}\")\n\n        if macro_auc > best_auc:\n            best_auc = macro_auc\n            torch.save({\n                \"epoch\": epoch+1,\n                \"model_state_dict\": model.state_dict(),\n                \"optimizer_state_dict\": opt.state_dict(),\n                \"scheduler_state_dict\": sch.state_dict(),\n                \"auc_macro\": macro_auc,\n                \"target_cols\": Config.TARGET_COLS,\n                \"config\": {\n                    \"img_size\": args.img_size,\n                    \"batch_size\": args.batch_size,\n                    \"lr\": args.lr,\n                    \"seed\": args.seed,\n                }\n            }, best_ckpt)\n            print(f\"Saved new best: {best_ckpt} (macro_auc={macro_auc:.4f})\")\n\n        sch.step()\n\n    print(f\"Training complete. Best macro AUC: {best_auc:.4f} | ckpt={best_ckpt}\")\n    return best_ckpt\n\n# =============================================================================\n# JUPYTER HELPER\n# =============================================================================\ndef train_model_jupyter(data_dir=None, img_size=None, batch_size=None, epochs=None,\n                        lr=None, num_workers=None, seed=None, out=None, benchmark_mode=False):\n    class A: pass\n    a = A()\n    a.data_dir = data_dir or Config.DATA_DIR\n    a.img_size = img_size or Config.IMG_SIZE\n    a.batch_size = batch_size or Config.BATCH_SIZE\n    a.epochs = epochs or Config.EPOCHS\n    a.lr = lr or Config.LR\n    a.num_workers = num_workers if num_workers is not None else Config.NUM_WORKERS\n    a.seed = seed or Config.SEED\n    a.out = out or \"/kaggle/working/best.pt\"\n    a.benchmark_mode = benchmark_mode\n    return train_model(a)\n\nprint(\"Loaded stable script. Now run train_model_jupyter(...) below.\")","metadata":{"execution":{"iopub.status.busy":"2025-09-03T18:39:04.617372Z","iopub.execute_input":"2025-09-03T18:39:04.618098Z","iopub.status.idle":"2025-09-03T18:39:04.661311Z","shell.execute_reply.started":"2025-09-03T18:39:04.618072Z","shell.execute_reply":"2025-09-03T18:39:04.660551Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=288,\n    batch_size=2,\n    epochs=1,\n    num_workers=0,\n    benchmark_mode=True\n)","metadata":{"execution":{"iopub.status.busy":"2025-09-03T18:39:11.895669Z","iopub.execute_input":"2025-09-03T18:39:11.895917Z","iopub.status.idle":"2025-09-03T20:08:55.047776Z","shell.execute_reply.started":"2025-09-03T18:39:11.895901Z","shell.execute_reply":"2025-09-03T20:08:55.046987Z"},"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **TEST 3**","metadata":{}},{"cell_type":"markdown","source":"using a diffrent image processing for CT scans and also using a much more bigger cifusion matrixes","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nRSNA Intracranial Aneurysm Detection - Stable Baseline (Kaggle-ready)\n\nWhat's in here:\n- MRI/MRA  : tri-planar MIPs (axial/coronal/sagittal) ‚Üí 3 channels\n- CT/CTA   : multi-window axial MIP (3 windows) ‚Üí 3 channels\n- Robust DICOM decode (RescaleSlope/Intercept, VOI LUT), quiet & cached\n- BCEWithLogits + pos_weight\n- Fixed seed, no-leakage split\n- Val metrics: per-label AUROC, PR-AUC; per-label confusion at tuned thresholds\n- Threshold tuning on val (best F1 per label)\n- Saves: /kaggle/working/val_preds.csv and checkpoint with thresholds\n\nUsage after loading:\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=288, batch_size=2, epochs=1, num_workers=0, benchmark_mode=True\n)\n\"\"\"\n\nimport os, time, random, warnings, hashlib, math\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\n\n# VOI LUT import (compat across pydicom versions)\ntry:\n    from pydicom.pixel_data_handlers import apply_voi_lut\nexcept Exception:\n    try:\n        from pydicom.pixel_data_handlers.util import apply_voi_lut\n    except Exception:\n        def apply_voi_lut(x, ds): return x\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nwarnings.filterwarnings(\"ignore\")\n\n# =============================================================================\n# CONFIG\n# =============================================================================\nclass Config:\n    # Kaggle dataset\n    DATA_DIR   = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\n    SERIES_DIR = f\"{DATA_DIR}/series\"\n    TRAIN_CSV  = f\"{DATA_DIR}/train.csv\"\n\n    # Train defaults\n    IMG_SIZE   = 288\n    BATCH_SIZE = 2\n    EPOCHS     = 1\n    LR         = 2e-4\n    NUM_WORKERS= 0\n    SEED       = 42\n    USE_AMP    = True\n\n    # Logs / cache\n    LOG_EVERY_N = 50\n    USE_CACHE = True\n    CACHE_DIR = \"/kaggle/working/mip_cache\"\n    CACHE_VERSION = \"v5.0\"\n\n    # DICOM/MIP\n    LARGE_SERIES_THRESHOLD = 1   # use streaming path for all (lowest RAM)\n    MAX_WORKERS = 1              # keep it simple/stable in Kaggle\n\n    # Multi-window CT (L, W) triplet ‚Üí 3 channels\n    CT_WINDOWS = [(40, 80), (200, 500), (600, 2800)]  # brain, vessel/soft, bone\n\n    # Small subset so one run completes quickly; set both to None to use ALL\n    SMOKE_TRAIN_LIMIT = 600\n    SMOKE_VAL_LIMIT   = 200\n\n    # Early stopping (optional)\n    EARLY_STOP_PATIENCE = None  # set to int for longer runs\n\n    # Labels (13 sites + global)\n    TARGET_COLS = [\n        \"Left Infraclinoid Internal Carotid Artery\",\n        \"Right Infraclinoid Internal Carotid Artery\",\n        \"Left Supraclinoid Internal Carotid Artery\",\n        \"Right Supraclinoid Internal Carotid Artery\",\n        \"Left Middle Cerebral Artery\",\n        \"Right Middle Cerebral Artery\",\n        \"Anterior Communicating Artery\",\n        \"Left Anterior Cerebral Artery\",\n        \"Right Anterior Cerebral Artery\",\n        \"Left Posterior Communicating Artery\",\n        \"Right Posterior Communicating Artery\",\n        \"Basilar Tip\",\n        \"Other Posterior Circulation\",\n        \"Aneurysm Present\",\n    ]\n\n# =============================================================================\n# UTIL\n# =============================================================================\ndef set_seed(seed=42, benchmark_mode=False):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = not benchmark_mode\n    torch.backends.cudnn.benchmark     = benchmark_mode\n\ndef device() -> str:\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef count_params(m: nn.Module) -> int:\n    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n\n# =============================================================================\n# DICOM I/O & NORMALIZATION\n# =============================================================================\ndef iter_dicom_files(series_path: str) -> List[str]:\n    sp = Path(series_path)\n    dcm_files = list(sp.glob(\"*.dcm\"))\n    if not dcm_files:\n        dcm_files = [f for f in sp.iterdir() if f.is_file() and not f.suffix]\n    if not dcm_files:\n        return []\n    infos = []\n    for f in dcm_files:\n        try:\n            ds = pydicom.dcmread(str(f), stop_before_pixels=True, force=True)\n            ins = getattr(ds, \"InstanceNumber\", 0)\n        except Exception:\n            ins = 0\n        infos.append((ins, str(f)))\n    infos.sort(key=lambda x: (x[0], x[1]))\n    return [p for _, p in infos]\n\ndef read_pixel(ds) -> np.ndarray:\n    \"\"\"Decode with VOI LUT + RescaleSlope/Intercept ‚Üí float32 (HU for CT).\"\"\"\n    arr = ds.pixel_array\n    try:\n        if hasattr(ds, 'VOILUTSequence') or hasattr(ds, 'WindowCenter'):\n            arr = apply_voi_lut(arr, ds)\n    except Exception:\n        pass\n    if hasattr(ds, \"RescaleSlope\") and hasattr(ds, \"RescaleIntercept\"):\n        arr = arr.astype(np.float32) * float(ds.RescaleSlope) + float(ds.RescaleIntercept)\n    else:\n        arr = arr.astype(np.float32)\n    return arr\n\ndef _ensure_gray2d(img: np.ndarray) -> np.ndarray:\n    if img.ndim == 3:  # RGB or multi-channel ‚Üí grayscale\n        if img.shape[-1] == 3:\n            img = np.mean(img, axis=-1)\n        else:\n            img = img.max(axis=-1)\n    return img.astype(np.float32)\n\ndef window_ct(img: np.ndarray, level=200, width=500) -> np.ndarray:\n    img = img.astype(np.float32)\n    lo, hi = float(level) - float(width)/2.0, float(level) + float(width)/2.0\n    img = np.clip(img, lo, hi)\n    denom = max(1e-6, (hi - lo))\n    img = (img - lo) / denom\n    return np.clip(img, 0, 1)\n\ndef normalize_mr(img: np.ndarray) -> np.ndarray:\n    img = img.astype(np.float32)\n    p1, p99 = np.percentile(img, [1, 99])\n    img = np.clip(img, p1, p99)\n    if p99 > p1:\n        img = (img - p1) / (p99 - p1)\n    return np.clip(img, 0, 1)\n\n# =============================================================================\n# MIP BUILDERS (streaming, quiet)\n# =============================================================================\ndef _cache_path(series_path: str, out_size: int, key_extra: str) -> str:\n    os.makedirs(Config.CACHE_DIR, exist_ok=True)\n    key = f\"{Config.CACHE_VERSION}_{os.path.basename(series_path)}_{out_size}_{key_extra}\"\n    h = hashlib.md5(key.encode()).hexdigest()[:16]\n    return os.path.join(Config.CACHE_DIR, f\"mip_{h}.npy\")\n\ndef _load_cache(path: str) -> Optional[np.ndarray]:\n    try:\n        if Config.USE_CACHE and os.path.exists(path):\n            arr = np.load(path, allow_pickle=False)\n            return arr.astype(np.float32) / 255.0\n    except Exception:\n        pass\n    return None\n\ndef _save_cache(arr: np.ndarray, path: str):\n    if not Config.USE_CACHE: return\n    try:\n        np.save(path, (arr * 255).astype(np.uint8), allow_pickle=False)\n    except Exception:\n        pass\n\ndef make_triplanar_mips_stream(series_path: str, is_ct: bool, out_size: int) -> np.ndarray:\n    \"\"\"\n    MRI/MRA path: tri-planar MIPs (max over Z yields axial; stack per-slice maxima for cor/sag).\n    If is_ct is True, still usable (not typical); kept for completeness.\n    \"\"\"\n    cache = _cache_path(series_path, out_size, key_extra=f\"tri_isct{int(is_ct)}\")\n    cached = _load_cache(cache)\n    if cached is not None: return cached\n\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n\n    axial = None\n    cor_rows = None  # (Z, W)\n    sag_cols = None  # (Z, H)\n\n    H = W = None\n    z = 0\n    for f in files:\n        try:\n            ds  = pydicom.dcmread(f, force=True)\n            arr = read_pixel(ds)\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            img = _ensure_gray2d(arr)\n\n            if axial is None:\n                H, W = img.shape\n                axial    = img.copy()\n                cor_rows = np.zeros((len(files), W), dtype=np.float32)\n                sag_cols = np.zeros((len(files), H), dtype=np.float32)\n            else:\n                np.maximum(axial, img, out=axial)\n\n            cor_rows[z, :] = img.max(axis=0)\n            sag_cols[z, :] = img.max(axis=1)\n            z += 1\n        except Exception:\n            continue\n\n    if axial is None: raise RuntimeError(\"No decodable slices\")\n\n    # Normalize: CT uses CT-like windowing (but tri-planar often for MR)\n    if is_ct:\n        axial    = window_ct(axial, 200, 500)\n        cor_rows = window_ct(cor_rows, 200, 500)\n        sag_cols = window_ct(sag_cols, 200, 500)\n    else:\n        axial    = normalize_mr(axial)\n        cor_rows = normalize_mr(cor_rows)\n        sag_cols = normalize_mr(sag_cols)\n\n    axial    = cv2.resize(axial,    (out_size, out_size), interpolation=cv2.INTER_AREA)\n    coronal  = cv2.resize(cor_rows, (out_size, out_size), interpolation=cv2.INTER_AREA)\n    sagittal = cv2.resize(sag_cols, (out_size, out_size), interpolation=cv2.INTER_AREA)\n\n    mips = np.stack([axial, coronal, sagittal], axis=0).astype(np.float32)\n    _save_cache(mips, cache)\n    return mips\n\ndef make_ct_multiwindow_axial_mip_stream(series_path: str, out_size: int) -> np.ndarray:\n    \"\"\"\n    CT/CTA path: build ONE axial MIP in HU, then apply 3 windows ‚Üí 3 channels.\n    \"\"\"\n    # include window triple in cache key\n    win_key = \"_\".join([f\"{l}_{w}\" for (l,w) in Config.CT_WINDOWS])\n    cache = _cache_path(series_path, out_size, key_extra=f\"ctmw_{win_key}\")\n    cached = _load_cache(cache)\n    if cached is not None: return cached\n\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n\n    axial_hu = None\n    for f in files:\n        try:\n            ds  = pydicom.dcmread(f, force=True)\n            arr = read_pixel(ds)  # HU for CT (after rescale)\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            img = _ensure_gray2d(arr)\n\n            if axial_hu is None:\n                axial_hu = img.copy()\n            else:\n                np.maximum(axial_hu, img, out=axial_hu)\n        except Exception:\n            continue\n\n    if axial_hu is None: raise RuntimeError(\"No decodable slices\")\n\n    channels = []\n    for (L, W) in Config.CT_WINDOWS:\n        ch = window_ct(axial_hu, level=L, width=W)\n        ch = cv2.resize(ch, (out_size, out_size), interpolation=cv2.INTER_AREA)\n        channels.append(ch.astype(np.float32))\n    mips = np.stack(channels, axis=0)  # 3xHxW\n    _save_cache(mips, cache)\n    return mips\n\ndef _detect_modality_from_header(series_path: str) -> Optional[str]:\n    files = iter_dicom_files(series_path)\n    if not files: return None\n    try:\n        ds = pydicom.dcmread(files[0], stop_before_pixels=True, force=True)\n        mod = str(getattr(ds, \"Modality\", \"\")).upper()\n        return mod or None\n    except Exception:\n        return None\n\n# =============================================================================\n# DATASET & FILTERING\n# =============================================================================\ndef stratified_split(df: pd.DataFrame, global_col=\"Aneurysm Present\", seed=42, n_splits=5):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    tr_idx, va_idx = next(skf.split(df, df[global_col]))\n    return df.iloc[tr_idx].copy(), df.iloc[va_idx].copy()\n\ndef safe_series_path(series_dir: str, uid: str) -> str:\n    p = os.path.join(series_dir, str(uid))\n    if not os.path.exists(p): raise FileNotFoundError(p)\n    return p\n\ndef _quick_series_decode_ok(series_path: str) -> bool:\n    \"\"\"Try decoding ONE slice: robust and version-agnostic.\"\"\"\n    try:\n        files = iter_dicom_files(series_path)\n        if not files: return False\n        ds = pydicom.dcmread(files[0], force=True)\n        _ = ds.pixel_array\n        return True\n    except Exception:\n        return False\n\ndef filter_decodable_df(df: pd.DataFrame, series_dir: str) -> pd.DataFrame:\n    uids = df[\"SeriesInstanceUID\"].astype(str).tolist()\n    keep_mask = []\n    for uid in uids:\n        sp = os.path.join(series_dir, uid)\n        keep_mask.append(_quick_series_decode_ok(sp))\n    kept = df[keep_mask].reset_index(drop=True)\n    print(f\"Decodable series (quick test): {len(kept)}/{len(df)} kept\")\n    return kept\n\nclass MIPDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, series_dir: str, out_size: int):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.out_size = out_size\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss:\n            raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n\n        # modality hint from CSV if present; else detect from header\n        mod_hint = row.get(\"Modality\", None)\n        if pd.isna(mod_hint) or not str(mod_hint).strip():\n            mod_hint = _detect_modality_from_header(sp)\n        mod_up = str(mod_hint).upper() if mod_hint is not None else \"\"\n\n        is_ct = (mod_up in [\"CT\", \"CTA\"])\n\n        try:\n            if is_ct:\n                mips = make_ct_multiwindow_axial_mip_stream(sp, self.out_size)\n            else:\n                mips = make_triplanar_mips_stream(sp, is_ct=False, out_size=self.out_size)\n        except Exception:\n            # Last-resort fallback to keep training running\n            mips = np.zeros((3, self.out_size, self.out_size), dtype=np.float32)\n\n        x = torch.from_numpy(mips).float()\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\n# =============================================================================\n# MODEL / METRICS\n# =============================================================================\ndef build_efficientnet_b0(n_out=14) -> nn.Module:\n    try:\n        model = torchvision.models.efficientnet_b0(\n            weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        )\n    except Exception:\n        model = torchvision.models.efficientnet_b0(pretrained=True)\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, n_out)\n    return model\n\ndef compute_auc_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_auc, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_auc[c] = np.nan\n                continue\n            auc = roc_auc_score(y_true[:, i], y_prob[:, i])\n            col_auc[c] = float(auc); macro_vals.append(float(auc))\n        except Exception:\n            col_auc[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_auc, macro\n\ndef compute_ap_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_ap, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_ap[c] = np.nan\n                continue\n            ap = average_precision_score(y_true[:, i], y_prob[:, i])\n            col_ap[c] = float(ap); macro_vals.append(float(ap))\n        except Exception:\n            col_ap[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_ap, macro\n\ndef tune_thresholds_best_f1(y_true: np.ndarray, y_prob: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns per-label thresholds (0..1) maximizing F1 on val.\n    \"\"\"\n    n_labels = y_true.shape[1]\n    thrs = np.zeros(n_labels, dtype=np.float32)\n    grid = np.linspace(0.0, 1.0, 101)\n    for i in range(n_labels):\n        yi = y_true[:, i].astype(np.int32)\n        pi = y_prob[:, i]\n        if len(np.unique(yi)) < 2:\n            thrs[i] = 0.5\n            continue\n        best_f1, best_t = -1.0, 0.5\n        for t in grid:\n            pred = (pi >= t).astype(np.int32)\n            tp = int((pred & (yi == 1)).sum())\n            fp = int((pred & (yi == 0)).sum())\n            fn = int(((1 - pred) & (yi == 1)).sum())\n            precision = tp / max(1, (tp + fp))\n            recall    = tp / max(1, (tp + fn))\n            f1 = 2*precision*recall / max(1e-8, (precision + recall))\n            if f1 > best_f1:\n                best_f1, best_t = f1, t\n        thrs[i] = best_t\n    return thrs\n\ndef confusion_stats(y_true: np.ndarray, y_prob: np.ndarray, thrs: np.ndarray,\n                    cols: List[str], top_k: int = 6) -> pd.DataFrame:\n    rows = []\n    for i, c in enumerate(cols):\n        yi = y_true[:, i].astype(np.int32)\n        pi = (y_prob[:, i] >= thrs[i]).astype(np.int32)\n        tp = int((pi & (yi == 1)).sum())\n        fp = int((pi & (yi == 0)).sum())\n        tn = int(((1 - pi) & (yi == 0)).sum())\n        fn = int(((1 - pi) & (yi == 1)).sum())\n        prec = tp / max(1, (tp + fp))\n        rec  = tp / max(1, (tp + fn))\n        f1   = 2*prec*rec / max(1e-8, (prec + rec))\n        rows.append([c, thrs[i], tp, fp, tn, fn, prec, rec, f1])\n    df = pd.DataFrame(rows, columns=[\"label\",\"thr\",\"TP\",\"FP\",\"TN\",\"FN\",\"precision\",\"recall\",\"F1\"])\n    # Show a few meaningful rows first (global + common arteries)\n    priority = [\"Aneurysm Present\", \"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\",\n                \"Basilar Tip\", \"Anterior Communicating Artery\"]\n    order = priority + [c for c in cols if c not in priority]\n    df = df.set_index(\"label\").loc[order].reset_index()\n    return df.head(top_k)\n\n# =============================================================================\n# TRAIN\n# =============================================================================\ndef train_model(args):\n    print(\"== RSNA IA Detection: TRAIN ==\")\n    set_seed(args.seed, getattr(args, \"benchmark_mode\", False))\n    dev = device()\n    print(f\"Device: {dev} | AMP: {Config.USE_AMP}\")\n\n    csv_path = os.path.join(args.data_dir, \"train.csv\")\n    if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n    df = pd.read_csv(csv_path)\n    print(f\"Total rows in CSV: {len(df):,}\")\n\n    # Split (no leakage)\n    train_df, val_df = stratified_split(df, seed=args.seed)\n\n    # Smoke limits (quick runs). Set both to None to use ALL.\n    if Config.SMOKE_TRAIN_LIMIT is not None:\n        train_df = train_df.head(Config.SMOKE_TRAIN_LIMIT).copy()\n    if Config.SMOKE_VAL_LIMIT is not None:\n        val_df   = val_df.head(Config.SMOKE_VAL_LIMIT).copy()\n\n    series_dir = os.path.join(args.data_dir, \"series\")\n    print(\"Scanning decodability (quick test on first slice of each series)...\")\n    train_keep = filter_decodable_df(train_df, series_dir)\n    val_keep   = filter_decodable_df(val_df,   series_dir)\n\n    # Fallback if filtering keeps 0\n    if len(train_keep) == 0:\n        print(\"‚ö†Ô∏è  Kept 0 for train ‚Äî using unfiltered subset.\")\n        train_keep = train_df.head(64).copy()\n    if len(val_keep) == 0:\n        print(\"‚ö†Ô∏è  Kept 0 for val ‚Äî using unfiltered subset.\")\n        val_keep = val_df.head(32).copy()\n\n    print(f\"Train: {len(train_keep):,} | Val: {len(val_keep):,}\")\n\n    train_ds = MIPDataset(train_keep, series_dir, args.img_size)\n    val_ds   = MIPDataset(val_keep,   series_dir, args.img_size)\n\n    tkw = dict(batch_size=args.batch_size, shuffle=True,  num_workers=args.num_workers, drop_last=True)\n    vkw = dict(batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, drop_last=False)\n    if dev == \"cuda\":\n        tkw[\"pin_memory\"] = True; vkw[\"pin_memory\"] = True\n    train_loader = DataLoader(train_ds, **tkw)\n    val_loader   = DataLoader(val_ds, **vkw)\n\n    model = build_efficientnet_b0(len(Config.TARGET_COLS)).to(dev)\n    print(f\"Model params: {count_params(model):,}\")\n\n    # Class imbalance weights\n    posw = []\n    for c in Config.TARGET_COLS:\n        pos = train_keep[c].sum()\n        neg = len(train_keep) - pos\n        w = min(max((neg / max(1.0, pos)), 1.0), 50.0) if pos > 0 else 1.0\n        posw.append(w)\n    posw = torch.tensor(posw, device=dev)\n\n    criterion = nn.BCEWithLogitsLoss(pos_weight=posw)\n    opt = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n    sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=args.epochs)\n\n    use_amp = (dev == \"cuda\") and Config.USE_AMP\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    best_auc = -1.0\n    best_ckpt = args.out\n    patience_left = Config.EARLY_STOP_PATIENCE if Config.EARLY_STOP_PATIENCE is not None else 1_000_000\n\n    for epoch in range(args.epochs):\n        # ----------------- Train ----------------- #\n        model.train()\n        run_loss = 0.0; correct = 0; total = 0\n        t0 = time.time()\n        for b, (x, y, _) in enumerate(train_loader, 1):\n            x, y = x.to(dev), y.to(dev)\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                out = model(x)\n                loss = criterion(out, y)\n            scaler.scale(loss).backward()\n            scaler.step(opt); scaler.update()\n\n            run_loss += loss.item()\n            preds = (torch.sigmoid(out) > 0.5).float()\n            correct += (preds == y).sum().item(); total += y.numel()\n\n            if b % Config.LOG_EVERY_N == 0 or b == 1:\n                print(f\"[E{epoch+1} {b}/{len(train_loader)}] \"\n                      f\"loss={run_loss/b:.4f} acc={correct/max(1,total):.3f} \"\n                      f\"lr={sch.get_last_lr()[0]:.2e}\")\n\n        train_loss = run_loss / max(1, len(train_loader))\n        train_acc  = correct / max(1, total)\n\n        # ----------------- Val ----------------- #\n        model.eval()\n        val_loss = 0.0\n        preds_all, targs_all, uids_all = [], [], []\n        with torch.no_grad():\n            for x, y, uids in val_loader:\n                x, y = x.to(dev), y.to(dev)\n                with torch.cuda.amp.autocast(enabled=use_amp):\n                    out = model(x); loss = criterion(out, y)\n                val_loss += loss.item()\n                preds_all.append(torch.sigmoid(out).cpu().numpy())\n                targs_all.append(y.cpu().numpy())\n                uids_all.extend(list(uids))\n\n        val_loss /= max(1, len(val_loader))\n        P = np.vstack(preds_all) if preds_all else np.zeros((0, len(Config.TARGET_COLS)))\n        T = np.vstack(targs_all) if targs_all else np.zeros((0, len(Config.TARGET_COLS)))\n\n        col_aucs, macro_auc = compute_auc_per_column(T, P, Config.TARGET_COLS)\n        col_aps , macro_ap  = compute_ap_per_column(T, P, Config.TARGET_COLS)\n\n        dt = time.time() - t0\n        print(f\"Epoch {epoch+1}/{args.epochs} | {dt:.1f}s  \"\n              f\"train_loss={train_loss:.4f} train_acc={train_acc:.3f}  \"\n              f\"val_loss={val_loss:.4f} macro_auc={macro_auc:.4f} macro_ap={macro_ap:.4f}\")\n\n        # Threshold tuning (val only)\n        thrs = tune_thresholds_best_f1(T, P)\n        conf_df = confusion_stats(T, P, thrs, Config.TARGET_COLS, top_k=6)\n        print(\"\\nVal confusion summary (top labels, tuned thresholds):\")\n        for _, r in conf_df.iterrows():\n            print(f\"  {r['label'][:28]:28s} thr={r['thr']:.2f}  TP={r['TP']:3d} FP={r['FP']:3d} \"\n                  f\"TN={r['TN']:3d} FN={r['FN']:3d}  P={r['precision']:.2f} R={r['recall']:.2f} F1={r['F1']:.2f}\")\n        print(\"\")\n\n        # Save val predictions CSV for inspection\n        out_csv = \"/kaggle/working/val_preds.csv\"\n        val_out = pd.DataFrame({\"SeriesInstanceUID\": uids_all})\n        for i, c in enumerate(Config.TARGET_COLS):\n            val_out[c + \"_prob\"] = P[:, i]\n            val_out[c + \"_true\"] = T[:, i]\n        val_out.to_csv(out_csv, index=False)\n        print(f\"Saved validation predictions to {out_csv} (shape={val_out.shape})\")\n\n        # Save best checkpoint (stores thresholds too)\n        if macro_auc > best_auc:\n            best_auc = macro_auc\n            torch.save({\n                \"epoch\": epoch+1,\n                \"model_state_dict\": model.state_dict(),\n                \"optimizer_state_dict\": opt.state_dict(),\n                \"scheduler_state_dict\": sch.state_dict(),\n                \"auc_macro\": macro_auc,\n                \"target_cols\": Config.TARGET_COLS,\n                \"thresholds\": thrs,  # tuned on val\n                \"config\": {\n                    \"img_size\": args.img_size,\n                    \"batch_size\": args.batch_size,\n                    \"lr\": args.lr,\n                    \"seed\": args.seed,\n                    \"ct_windows\": Config.CT_WINDOWS,\n                }\n            }, best_ckpt)\n            print(f\"Saved new best: {best_ckpt} (macro_auc={macro_auc:.4f})\")\n            patience_left = Config.EARLY_STOP_PATIENCE if Config.EARLY_STOP_PATIENCE is not None else patience_left\n        else:\n            if Config.EARLY_STOP_PATIENCE is not None:\n                patience_left -= 1\n                print(f\"No AUC improvement. Early-stop patience left: {patience_left}\")\n                if patience_left <= 0:\n                    print(\"Early stopping.\")\n                    break\n\n        sch.step()\n\n    print(f\"Training complete. Best macro AUC: {best_auc:.4f} | ckpt={best_ckpt}\")\n    return best_ckpt\n\n# =============================================================================\n# JUPYTER HELPER\n# =============================================================================\ndef train_model_jupyter(data_dir=None, img_size=None, batch_size=None, epochs=None,\n                        lr=None, num_workers=None, seed=None, out=None, benchmark_mode=False):\n    class A: pass\n    a = A()\n    a.data_dir = data_dir or Config.DATA_DIR\n    a.img_size = img_size or Config.IMG_SIZE\n    a.batch_size = batch_size or Config.BATCH_SIZE\n    a.epochs = epochs or Config.EPOCHS\n    a.lr = lr or Config.LR\n    a.num_workers = num_workers if num_workers is not None else Config.NUM_WORKERS\n    a.seed = seed or Config.SEED\n    a.out = out or \"/kaggle/working/best.pt\"\n    a.benchmark_mode = benchmark_mode\n    return train_model(a)\n\nprint(\"Loaded improved script. Now run train_model_jupyter(...) below, e.g.:\")\nprint('train_model_jupyter(data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", img_size=288, batch_size=2, epochs=1, num_workers=0, benchmark_mode=True)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T18:06:07.343408Z","iopub.execute_input":"2025-09-15T18:06:07.344261Z","iopub.status.idle":"2025-09-15T18:06:22.242359Z","shell.execute_reply.started":"2025-09-15T18:06:07.344232Z","shell.execute_reply":"2025-09-15T18:06:22.241695Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Loaded improved script. Now run train_model_jupyter(...) below, e.g.:\ntrain_model_jupyter(data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", img_size=288, batch_size=2, epochs=1, num_workers=0, benchmark_mode=True)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Balanced run (recommended)\nConfig.SMOKE_TRAIN_LIMIT = 600   # use the 600/200 smoke split\nConfig.SMOKE_VAL_LIMIT   = 200\nConfig.IMG_SIZE          = 288   # good quality, reasonable time\nConfig.LOG_EVERY_N       = 50    # not too chatty\n\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=Config.IMG_SIZE,\n    batch_size=2,\n    epochs=2,              # 2 passes gives noticeably more signal than 1\n    num_workers=0,         # safest/stable on Kaggle for our MIP path\n    benchmark_mode=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T19:20:49.199760Z","iopub.execute_input":"2025-09-08T19:20:49.200689Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"== RSNA IA Detection: TRAIN ==\nDevice: cuda | AMP: True\nTotal rows in CSV: 4,348\nScanning decodability (quick test on first slice of each series)...\nDecodable series (quick test): 600/600 kept\nDecodable series (quick test): 200/200 kept\nTrain: 600 | Val: 200\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 144MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model params: 4,025,482\n[E1 1/300] loss=0.8897 acc=0.500 lr=2.00e-04\n[E1 50/300] loss=1.5262 acc=0.763 lr=2.00e-04\n[E1 100/300] loss=1.2935 acc=0.786 lr=2.00e-04\n[E1 150/300] loss=1.2237 acc=0.793 lr=2.00e-04\n[E1 200/300] loss=1.2101 acc=0.780 lr=2.00e-04\n[E1 250/300] loss=1.2693 acc=0.756 lr=2.00e-04\n[E1 300/300] loss=1.2662 acc=0.722 lr=2.00e-04\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":" # keep the same smoke limits & size\nConfig.SMOKE_TRAIN_LIMIT = 600\nConfig.SMOKE_VAL_LIMIT   = 200\nConfig.IMG_SIZE          = 288\nConfig.LOG_EVERY_N       = 50\n\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=Config.IMG_SIZE,\n    batch_size=2,\n    epochs=5,          # bump to 4; with cache this should be quick now\n    num_workers=0,\n    benchmark_mode=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T16:46:20.557665Z","iopub.execute_input":"2025-09-09T16:46:20.558331Z","iopub.status.idle":"2025-09-09T18:20:03.536513Z","shell.execute_reply.started":"2025-09-09T16:46:20.558303Z","shell.execute_reply":"2025-09-09T18:20:03.535764Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"== RSNA IA Detection: TRAIN ==\nDevice: cuda | AMP: True\nTotal rows in CSV: 4,348\nScanning decodability (quick test on first slice of each series)...\nDecodable series (quick test): 600/600 kept\nDecodable series (quick test): 200/200 kept\nTrain: 600 | Val: 200\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 131MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Model params: 4,025,482\n[E1 1/300] loss=0.8896 acc=0.500 lr=2.00e-04\n[E1 50/300] loss=1.5262 acc=0.763 lr=2.00e-04\n[E1 100/300] loss=1.2941 acc=0.785 lr=2.00e-04\n[E1 150/300] loss=1.2252 acc=0.789 lr=2.00e-04\n[E1 200/300] loss=1.2138 acc=0.770 lr=2.00e-04\n[E1 250/300] loss=1.2674 acc=0.746 lr=2.00e-04\n[E1 300/300] loss=1.2615 acc=0.715 lr=2.00e-04\nEpoch 1/5 | 4248.5s  train_loss=1.2615 train_acc=0.715  val_loss=1.3004 macro_auc=0.5612 macro_ap=0.1007\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.41  TP= 96 FP= 93 TN=  9 FN=  2  P=0.51 R=0.98 F1=0.67\n  Left Middle Cerebral Artery  thr=0.55  TP=  5 FP= 45 TN=145 FN=  5  P=0.10 R=0.50 F1=0.17\n  Right Middle Cerebral Artery thr=0.45  TP= 17 FP=122 TN= 57 FN=  4  P=0.12 R=0.81 F1=0.21\n  Basilar Tip                  thr=0.72  TP=  1 FP=  1 TN=195 FN=  3  P=0.50 R=0.25 F1=0.33\n  Anterior Communicating Arter thr=0.56  TP=  5 FP= 34 TN=152 FN=  9  P=0.13 R=0.36 F1=0.19\n  Left Infraclinoid Internal C thr=0.55  TP=  1 FP= 50 TN=149 FN=  0  P=0.02 R=1.00 F1=0.04\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 29))\nSaved new best: /kaggle/working/best.pt (macro_auc=0.5612)\n[E2 1/300] loss=1.5217 acc=0.536 lr=1.81e-04\n[E2 50/300] loss=1.1674 acc=0.511 lr=1.81e-04\n[E2 100/300] loss=1.0973 acc=0.549 lr=1.81e-04\n[E2 150/300] loss=1.1269 acc=0.572 lr=1.81e-04\n[E2 200/300] loss=1.1370 acc=0.592 lr=1.81e-04\n[E2 250/300] loss=1.1833 acc=0.593 lr=1.81e-04\n[E2 300/300] loss=1.1981 acc=0.592 lr=1.81e-04\nEpoch 2/5 | 15.6s  train_loss=1.1981 train_acc=0.592  val_loss=1.2561 macro_auc=0.6546 macro_ap=0.1583\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.48  TP= 62 FP= 27 TN= 75 FN= 36  P=0.70 R=0.63 F1=0.66\n  Left Middle Cerebral Artery  thr=0.60  TP=  4 FP= 17 TN=173 FN=  6  P=0.19 R=0.40 F1=0.26\n  Right Middle Cerebral Artery thr=0.52  TP= 11 FP= 68 TN=111 FN= 10  P=0.14 R=0.52 F1=0.22\n  Basilar Tip                  thr=0.72  TP=  2 FP=  5 TN=191 FN=  2  P=0.29 R=0.50 F1=0.36\n  Anterior Communicating Arter thr=0.58  TP=  6 FP= 59 TN=127 FN=  8  P=0.09 R=0.43 F1=0.15\n  Left Infraclinoid Internal C thr=0.61  TP=  1 FP= 12 TN=187 FN=  0  P=0.08 R=1.00 F1=0.14\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 29))\nSaved new best: /kaggle/working/best.pt (macro_auc=0.6546)\n[E3 1/300] loss=0.5956 acc=0.679 lr=1.31e-04\n[E3 50/300] loss=1.2181 acc=0.544 lr=1.31e-04\n[E3 100/300] loss=1.1756 acc=0.557 lr=1.31e-04\n[E3 150/300] loss=1.1877 acc=0.582 lr=1.31e-04\n[E3 200/300] loss=1.1709 acc=0.583 lr=1.31e-04\n[E3 250/300] loss=1.1410 acc=0.593 lr=1.31e-04\n[E3 300/300] loss=1.1345 acc=0.601 lr=1.31e-04\nEpoch 3/5 | 13.1s  train_loss=1.1345 train_acc=0.601  val_loss=1.3271 macro_auc=0.6252 macro_ap=0.1590\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.47  TP= 63 FP= 22 TN= 80 FN= 35  P=0.74 R=0.64 F1=0.69\n  Left Middle Cerebral Artery  thr=0.58  TP=  8 FP= 41 TN=149 FN=  2  P=0.16 R=0.80 F1=0.27\n  Right Middle Cerebral Artery thr=0.37  TP= 20 FP=154 TN= 25 FN=  1  P=0.11 R=0.95 F1=0.21\n  Basilar Tip                  thr=0.70  TP=  1 FP=  1 TN=195 FN=  3  P=0.50 R=0.25 F1=0.33\n  Anterior Communicating Arter thr=0.62  TP=  2 FP=  7 TN=179 FN= 12  P=0.22 R=0.14 F1=0.17\n  Left Infraclinoid Internal C thr=0.37  TP=  1 FP=114 TN= 85 FN=  0  P=0.01 R=1.00 F1=0.02\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 29))\n[E4 1/300] loss=1.2745 acc=0.536 lr=6.91e-05\n[E4 50/300] loss=1.0000 acc=0.672 lr=6.91e-05\n[E4 100/300] loss=1.0350 acc=0.678 lr=6.91e-05\n[E4 150/300] loss=1.1196 acc=0.656 lr=6.91e-05\n[E4 200/300] loss=1.1199 acc=0.667 lr=6.91e-05\n[E4 250/300] loss=1.1165 acc=0.672 lr=6.91e-05\n[E4 300/300] loss=1.0901 acc=0.676 lr=6.91e-05\nEpoch 4/5 | 13.2s  train_loss=1.0901 train_acc=0.676  val_loss=1.3244 macro_auc=0.6451 macro_ap=0.1368\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.30  TP= 91 FP= 79 TN= 23 FN=  7  P=0.54 R=0.93 F1=0.68\n  Left Middle Cerebral Artery  thr=0.53  TP=  8 FP= 55 TN=135 FN=  2  P=0.13 R=0.80 F1=0.22\n  Right Middle Cerebral Artery thr=0.31  TP= 21 FP=166 TN= 13 FN=  0  P=0.11 R=1.00 F1=0.20\n  Basilar Tip                  thr=0.70  TP=  1 FP=  4 TN=192 FN=  3  P=0.20 R=0.25 F1=0.22\n  Anterior Communicating Arter thr=0.51  TP=  7 FP= 56 TN=130 FN=  7  P=0.11 R=0.50 F1=0.18\n  Left Infraclinoid Internal C thr=0.48  TP=  1 FP= 44 TN=155 FN=  0  P=0.02 R=1.00 F1=0.04\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 29))\n[E5 1/300] loss=1.4105 acc=0.714 lr=1.91e-05\n[E5 50/300] loss=1.0645 acc=0.699 lr=1.91e-05\n[E5 100/300] loss=1.1112 acc=0.695 lr=1.91e-05\n[E5 150/300] loss=1.1136 acc=0.700 lr=1.91e-05\n[E5 200/300] loss=1.0832 acc=0.704 lr=1.91e-05\n[E5 250/300] loss=1.0488 acc=0.707 lr=1.91e-05\n[E5 300/300] loss=1.0479 acc=0.708 lr=1.91e-05\nEpoch 5/5 | 13.1s  train_loss=1.0479 train_acc=0.708  val_loss=1.3704 macro_auc=0.6300 macro_ap=0.1458\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.23  TP= 96 FP= 92 TN= 10 FN=  2  P=0.51 R=0.98 F1=0.67\n  Left Middle Cerebral Artery  thr=0.48  TP=  7 FP= 40 TN=150 FN=  3  P=0.15 R=0.70 F1=0.25\n  Right Middle Cerebral Artery thr=0.36  TP= 16 FP=122 TN= 57 FN=  5  P=0.12 R=0.76 F1=0.20\n  Basilar Tip                  thr=0.73  TP=  1 FP=  0 TN=196 FN=  3  P=1.00 R=0.25 F1=0.40\n  Anterior Communicating Arter thr=0.28  TP= 13 FP=123 TN= 63 FN=  1  P=0.10 R=0.93 F1=0.17\n  Left Infraclinoid Internal C thr=0.41  TP=  1 FP= 86 TN=113 FN=  0  P=0.01 R=1.00 F1=0.02\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 29))\nTraining complete. Best macro AUC: 0.6546 | ckpt=/kaggle/working/best.pt\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/best.pt'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"Config.SMOKE_TRAIN_LIMIT = None\nConfig.SMOKE_VAL_LIMIT   = None\nConfig.IMG_SIZE          = 288\nConfig.LOG_EVERY_N       = 200  # quieter logs\n\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=Config.IMG_SIZE,\n    batch_size=2,\n    epochs=2,          # keep it short to avoid overfit\n    num_workers=0,\n    benchmark_mode=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T18:29:20.085459Z","iopub.execute_input":"2025-09-09T18:29:20.085889Z","execution_failed":"2025-09-10T10:22:03.041Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"== RSNA IA Detection: TRAIN ==\nDevice: cuda | AMP: True\nTotal rows in CSV: 4,348\nScanning decodability (quick test on first slice of each series)...\nDecodable series (quick test): 3478/3478 kept\nDecodable series (quick test): 870/870 kept\nTrain: 3,478 | Val: 870\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 133MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Model params: 4,025,482\n[E1 1/1739] loss=1.0247 acc=0.464 lr=2.00e-04\n[E1 200/1739] loss=1.3171 acc=0.703 lr=2.00e-04\n[E1 400/1739] loss=1.3034 acc=0.608 lr=2.00e-04\n[E1 600/1739] loss=1.3061 acc=0.568 lr=2.00e-04\n[E1 800/1739] loss=1.2708 acc=0.574 lr=2.00e-04\n[E1 1000/1739] loss=1.2677 acc=0.582 lr=2.00e-04\n[E1 1200/1739] loss=1.2543 acc=0.582 lr=2.00e-04\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **TEST4**","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nRSNA Intracranial Aneurysm Detection - Stable Baseline + Bone-aware Highlight (Kaggle-ready)\n\n- MRI/MRA  : tri-planar MIPs (axial/coronal/sagittal) ‚Üí highlight stretch (all pixels)\n- CT/CTA   : multi-window axial MIP (3 windows: brain/soft/bone) ‚Üí bone-aware highlight\n             (highlight applied everywhere EXCEPT where a bone mask says \"bone\")\n- Robust DICOM decode (VOI LUT + RescaleSlope/Intercept), quiet & cached\n- BCEWithLogits + pos_weight\n- Fixed seed, no-leakage split\n- Val metrics: per-label AUROC, PR-AUC; per-label confusion at tuned thresholds\n- Threshold tuning on val (best F1 per label)\n- Saves: /kaggle/working/val_preds.csv and best checkpoint with tuned thresholds\n\nRun example:\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=288, batch_size=2, epochs=1, num_workers=0, benchmark_mode=True\n)\n\"\"\"\n\nimport os, time, random, warnings, hashlib\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\n\n# VOI LUT import (compat across pydicom versions)\ntry:\n    from pydicom.pixel_data_handlers import apply_voi_lut\nexcept Exception:\n    try:\n        from pydicom.pixel_data_handlers.util import apply_voi_lut\n    except Exception:\n        def apply_voi_lut(x, ds): return x\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nwarnings.filterwarnings(\"ignore\")\n\n# =============================================================================\n# CONFIG\n# =============================================================================\nclass Config:\n    # Kaggle dataset\n    DATA_DIR   = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\n    SERIES_DIR = f\"{DATA_DIR}/series\"\n    TRAIN_CSV  = f\"{DATA_DIR}/train.csv\"\n\n    # Train defaults\n    IMG_SIZE   = 288\n    BATCH_SIZE = 2\n    EPOCHS     = 1\n    LR         = 2e-4\n    NUM_WORKERS= 0\n    SEED       = 42\n    USE_AMP    = True\n\n    # Logs / cache\n    LOG_EVERY_N = 50\n    USE_CACHE = True\n    CACHE_DIR = \"/kaggle/working/mip_cache\"\n    CACHE_VERSION = \"v6.0\"\n\n    # DICOM/MIP (streaming always ‚Üí lowest RAM)\n    LARGE_SERIES_THRESHOLD = 1\n    MAX_WORKERS = 1\n\n    # Multi-window CT (L, W) triplet ‚Üí 3 channels\n    CT_WINDOWS = [(40, 80), (200, 500), (600, 2800)]  # brain, soft/vessel, bone\n\n    # Bone-aware highlight controls for CT\n    CT_BONE_MASK_HU = 700          # HU above this is considered bone\n    CT_HIGHLIGHT_SKIP_BONE = True  # do not highlight pixels flagged as bone\n\n    # Global highlight controls (applied after normalization/windowing)\n    HIGHLIGHT_ENABLE     = True    # turn highlight on\n    HIGHLIGHT_TOP_PCT    = 1.0     # brighten top % pixels (0..100)\n    HIGHLIGHT_GAMMA      = 0.7     # <1 brightens highlights more\n    HIGHLIGHT_BLEND      = 0.6     # 0=orig, 1=full highlight\n    HIGHLIGHT_ONLY_NON_CT= False   # if True, never highlight CT; we keep False because we skip bone anyway\n\n    # Small subset so one run completes quickly; set both to None to use ALL\n    SMOKE_TRAIN_LIMIT = 600\n    SMOKE_VAL_LIMIT   = 200\n\n    # Early stopping (optional)\n    EARLY_STOP_PATIENCE = None  # set to int for longer runs\n\n    # Labels (13 sites + global)\n    TARGET_COLS = [\n        \"Left Infraclinoid Internal Carotid Artery\",\n        \"Right Infraclinoid Internal Carotid Artery\",\n        \"Left Supraclinoid Internal Carotid Artery\",\n        \"Right Supraclinoid Internal Carotid Artery\",\n        \"Left Middle Cerebral Artery\",\n        \"Right Middle Cerebral Artery\",\n        \"Anterior Communicating Artery\",\n        \"Left Anterior Cerebral Artery\",\n        \"Right Anterior Cerebral Artery\",\n        \"Left Posterior Communicating Artery\",\n        \"Right Posterior Communicating Artery\",\n        \"Basilar Tip\",\n        \"Other Posterior Circulation\",\n        \"Aneurysm Present\",\n    ]\n\n# =============================================================================\n# UTIL\n# =============================================================================\ndef set_seed(seed=42, benchmark_mode=False):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = not benchmark_mode\n    torch.backends.cudnn.benchmark     = benchmark_mode\n\ndef device() -> str:\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef count_params(m: nn.Module) -> int:\n    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n\n# =============================================================================\n# DICOM I/O & NORMALIZATION\n# =============================================================================\ndef iter_dicom_files(series_path: str) -> List[str]:\n    sp = Path(series_path)\n    dcm_files = list(sp.glob(\"*.dcm\"))\n    if not dcm_files:\n        dcm_files = [f for f in sp.iterdir() if f.is_file() and not f.suffix]\n    if not dcm_files:\n        return []\n    infos = []\n    for f in dcm_files:\n        try:\n            ds = pydicom.dcmread(str(f), stop_before_pixels=True, force=True)\n            ins = getattr(ds, \"InstanceNumber\", 0)\n        except Exception:\n            ins = 0\n        infos.append((ins, str(f)))\n    infos.sort(key=lambda x: (x[0], x[1]))\n    return [p for _, p in infos]\n\ndef read_pixel(ds) -> np.ndarray:\n    \"\"\"Decode with VOI LUT + RescaleSlope/Intercept ‚Üí float32 (HU for CT).\"\"\"\n    arr = ds.pixel_array\n    try:\n        if hasattr(ds, 'VOILUTSequence') or hasattr(ds, 'WindowCenter'):\n            arr = apply_voi_lut(arr, ds)\n    except Exception:\n        pass\n    if hasattr(ds, \"RescaleSlope\") and hasattr(ds, \"RescaleIntercept\"):\n        arr = arr.astype(np.float32) * float(ds.RescaleSlope) + float(ds.RescaleIntercept)\n    else:\n        arr = arr.astype(np.float32)\n    return arr\n\ndef _ensure_gray2d(img: np.ndarray) -> np.ndarray:\n    if img.ndim == 3:  # RGB or multi-channel ‚Üí grayscale\n        if img.shape[-1] == 3:\n            img = np.mean(img, axis=-1)\n        else:\n            img = img.max(axis=-1)\n    return img.astype(np.float32)\n\ndef window_ct(img: np.ndarray, level=200, width=500) -> np.ndarray:\n    img = img.astype(np.float32)\n    lo, hi = float(level) - float(width)/2.0, float(level) + float(width)/2.0\n    img = np.clip(img, lo, hi)\n    denom = max(1e-6, (hi - lo))\n    img = (img - lo) / denom\n    return np.clip(img, 0, 1)\n\ndef normalize_mr(img: np.ndarray) -> np.ndarray:\n    img = img.astype(np.float32)\n    p1, p99 = np.percentile(img, [1, 99])\n    img = np.clip(img, p1, p99)\n    if p99 > p1:\n        img = (img - p1) / (p99 - p1)\n    return np.clip(img, 0, 1)\n\n# =============================================================================\n# HIGHLIGHT STRETCH\n# =============================================================================\ndef highlight_stretch(img01: np.ndarray,\n                      pct: float = None,\n                      gamma: float = None,\n                      blend: float = None) -> np.ndarray:\n    \"\"\"\n    Brighten only the top `pct` percent of pixels in [0..1], with gamma and blend.\n    Below the percentile, pixels remain unchanged (smooth, one-sided stretch).\n    \"\"\"\n    pct   = Config.HIGHLIGHT_TOP_PCT if pct is None else pct\n    gamma = Config.HIGHLIGHT_GAMMA   if gamma is None else gamma\n    blend = Config.HIGHLIGHT_BLEND   if blend is None else blend\n\n    img = img01.astype(np.float32)\n    img = np.clip(img, 0.0, 1.0)\n\n    if pct <= 0.0:\n        return img.copy()\n\n    thr = np.percentile(img, 100.0 - pct)\n    # If image is flat or threshold at top, do nothing\n    if not np.isfinite(thr) or thr >= 0.999:\n        return img.copy()\n\n    out = img.copy()\n    mask = img >= thr\n    # stretch the tail to [0..1]\n    denom = max(1e-6, 1.0 - thr)\n    hi = (img - thr) / denom\n    # gamma shaping (gamma<1 -> brighter)\n    if gamma > 0:\n        hi = np.power(hi, 1.0 / gamma)\n    # blend tail with original (keep continuity at thr)\n    out[mask] = (1.0 - blend) * img[mask] + blend * hi[mask]\n    return np.clip(out, 0.0, 1.0)\n\n# =============================================================================\n# MIP BUILDERS (streaming, quiet)\n# =============================================================================\ndef _cache_path(series_path: str, out_size: int, key_extra: str) -> str:\n    os.makedirs(Config.CACHE_DIR, exist_ok=True)\n    hl = f\"hl{int(Config.HIGHLIGHT_ENABLE)}_{Config.HIGHLIGHT_TOP_PCT:.2f}_{Config.HIGHLIGHT_GAMMA:.2f}_{Config.HIGHLIGHT_BLEND:.2f}\"\n    key = f\"{Config.CACHE_VERSION}_{os.path.basename(series_path)}_{out_size}_{key_extra}_{hl}_skipbone{int(Config.CT_HIGHLIGHT_SKIP_BONE)}_{Config.CT_BONE_MASK_HU}\"\n    h = hashlib.md5(key.encode()).hexdigest()[:16]\n    return os.path.join(Config.CACHE_DIR, f\"mip_{h}.npy\")\n\ndef _load_cache(path: str) -> Optional[np.ndarray]:\n    try:\n        if Config.USE_CACHE and os.path.exists(path):\n            arr = np.load(path, allow_pickle=False)\n            return arr.astype(np.float32) / 255.0\n    except Exception:\n        pass\n    return None\n\ndef _save_cache(arr: np.ndarray, path: str):\n    if not Config.USE_CACHE: return\n    try:\n        np.save(path, (arr * 255).astype(np.uint8), allow_pickle=False)\n    except Exception:\n        pass\n\ndef make_triplanar_mips_stream(series_path: str, is_ct: bool, out_size: int) -> np.ndarray:\n    \"\"\"\n    MRI/MRA path: tri-planar MIPs; apply highlight stretch on each plane (no bone mask).\n    If is_ct is True, still usable; not the default for CT.\n    \"\"\"\n    cache = _cache_path(series_path, out_size, key_extra=f\"tri_isct{int(is_ct)}\")\n    cached = _load_cache(cache)\n    if cached is not None: return cached\n\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n\n    axial = None\n    cor_rows = None  # (Z, W)\n    sag_cols = None  # (Z, H)\n\n    H = W = None\n    z = 0\n    for f in files:\n        try:\n            ds  = pydicom.dcmread(f, force=True)\n            arr = read_pixel(ds)\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            img = _ensure_gray2d(arr)\n\n            if axial is None:\n                H, W = img.shape\n                axial    = img.copy()\n                cor_rows = np.zeros((len(files), W), dtype=np.float32)\n                sag_cols = np.zeros((len(files), H), dtype=np.float32)\n            else:\n                np.maximum(axial, img, out=axial)\n\n            cor_rows[z, :] = img.max(axis=0)\n            sag_cols[z, :] = img.max(axis=1)\n            z += 1\n        except Exception:\n            continue\n\n    if axial is None: raise RuntimeError(\"No decodable slices\")\n\n    # Normalize\n    if is_ct:\n        axial    = window_ct(axial, 200, 500)\n        cor_rows = window_ct(cor_rows, 200, 500)\n        sag_cols = window_ct(sag_cols, 200, 500)\n    else:\n        axial    = normalize_mr(axial)\n        cor_rows = normalize_mr(cor_rows)\n        sag_cols = normalize_mr(sag_cols)\n\n    # Resize\n    axial    = cv2.resize(axial,    (out_size, out_size), interpolation=cv2.INTER_AREA)\n    coronal  = cv2.resize(cor_rows, (out_size, out_size), interpolation=cv2.INTER_AREA)\n    sagittal = cv2.resize(sag_cols, (out_size, out_size), interpolation=cv2.INTER_AREA)\n\n    # Highlight (MRI/MRA: no bone mask)\n    do_highlight = Config.HIGHLIGHT_ENABLE and (not (Config.HIGHLIGHT_ONLY_NON_CT and is_ct))\n    if do_highlight:\n        axial    = highlight_stretch(axial)\n        coronal  = highlight_stretch(coronal)\n        sagittal = highlight_stretch(sagittal)\n\n    mips = np.stack([axial, coronal, sagittal], axis=0).astype(np.float32)\n    _save_cache(mips, cache)\n    return mips\n\ndef make_ct_multiwindow_axial_mip_stream(series_path: str, out_size: int) -> np.ndarray:\n    \"\"\"\n    CT/CTA path:\n      1) Build axial MIP in HU\n      2) Build axial *bone mask* MIP from HU threshold (CT_BONE_MASK_HU)\n      3) Apply three CT windows to axial HU ‚Üí 3 channels\n      4) Apply highlight on each channel, but SKIP pixels where bone mask==1\n    \"\"\"\n    win_key = \"_\".join([f\"{l}_{w}\" for (l,w) in Config.CT_WINDOWS])\n    cache = _cache_path(series_path, out_size, key_extra=f\"ctmw_{win_key}\")\n    cached = _load_cache(cache)\n    if cached is not None: return cached\n\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n\n    axial_hu = None\n    axial_bone = None  # bone mask MIP\n\n    for f in files:\n        try:\n            ds  = pydicom.dcmread(f, force=True)\n            arr = read_pixel(ds)  # after rescale ‚Üí HU\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            img = _ensure_gray2d(arr)  # float HU\n\n            # Build intensity axial HU MIP\n            if axial_hu is None:\n                axial_hu = img.copy()\n            else:\n                np.maximum(axial_hu, img, out=axial_hu)\n\n            # Build bone MIP from per-slice threshold\n            bone_slice = (img > float(Config.CT_BONE_MASK_HU)).astype(np.uint8)\n            if axial_bone is None:\n                axial_bone = bone_slice.copy()\n            else:\n                np.maximum(axial_bone, bone_slice, out=axial_bone)\n        except Exception:\n            continue\n\n    if axial_hu is None: raise RuntimeError(\"No decodable slices\")\n\n    # Resize bone mask to output size (nearest preserves binary)\n    bone_mip = cv2.resize(axial_bone, (out_size, out_size), interpolation=cv2.INTER_NEAREST)\n\n    # Create 3 windowed channels in [0..1]\n    channels = []\n    for (L, W) in Config.CT_WINDOWS:\n        ch = window_ct(axial_hu, level=L, width=W)  # 0..1\n        ch = cv2.resize(ch, (out_size, out_size), interpolation=cv2.INTER_AREA)\n        channels.append(ch.astype(np.float32))\n\n    # Highlight handling for CT\n    do_highlight = Config.HIGHLIGHT_ENABLE and (not Config.HIGHLIGHT_ONLY_NON_CT)\n    if do_highlight:\n        if Config.CT_HIGHLIGHT_SKIP_BONE:\n            # Apply highlight only where bone_mip == 0\n            inv_bone = (bone_mip == 0)\n            for i in range(len(channels)):\n                hi = highlight_stretch(channels[i])\n                # keep original in bone pixels, apply highlight elsewhere\n                channels[i] = np.where(inv_bone, hi, channels[i])\n        else:\n            # Highlight everywhere (may brighten bone too)\n            for i in range(len(channels)):\n                channels[i] = highlight_stretch(channels[i])\n\n    mips = np.stack(channels, axis=0)  # 3xHxW\n    _save_cache(mips, cache)\n    return mips\n\ndef _detect_modality_from_header(series_path: str) -> Optional[str]:\n    files = iter_dicom_files(series_path)\n    if not files: return None\n    try:\n        ds = pydicom.dcmread(files[0], stop_before_pixels=True, force=True)\n        mod = str(getattr(ds, \"Modality\", \"\")).upper()\n        return mod or None\n    except Exception:\n        return None\n\n# =============================================================================\n# DATASET & FILTERING\n# =============================================================================\ndef stratified_split(df: pd.DataFrame, global_col=\"Aneurysm Present\", seed=42, n_splits=5):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    tr_idx, va_idx = next(skf.split(df, df[global_col]))\n    return df.iloc[tr_idx].copy(), df.iloc[va_idx].copy()\n\ndef safe_series_path(series_dir: str, uid: str) -> str:\n    p = os.path.join(series_dir, str(uid))\n    if not os.path.exists(p): raise FileNotFoundError(p)\n    return p\n\ndef _quick_series_decode_ok(series_path: str) -> bool:\n    \"\"\"Try decoding ONE slice: robust and version-agnostic.\"\"\"\n    try:\n        files = iter_dicom_files(series_path)\n        if not files: return False\n        ds = pydicom.dcmread(files[0], force=True)\n        _ = ds.pixel_array\n        return True\n    except Exception:\n        return False\n\ndef filter_decodable_df(df: pd.DataFrame, series_dir: str) -> pd.DataFrame:\n    uids = df[\"SeriesInstanceUID\"].astype(str).tolist()\n    keep_mask = []\n    for uid in uids:\n        sp = os.path.join(series_dir, uid)\n        keep_mask.append(_quick_series_decode_ok(sp))\n    kept = df[keep_mask].reset_index(drop=True)\n    print(f\"Decodable series (quick test): {len(kept)}/{len(df)} kept\")\n    return kept\n\nclass MIPDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, series_dir: str, out_size: int):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.out_size = out_size\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss:\n            raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n\n        # modality hint from CSV if present; else detect from header\n        mod_hint = row.get(\"Modality\", None)\n        if pd.isna(mod_hint) or not str(mod_hint).strip():\n            mod_hint = _detect_modality_from_header(sp)\n        mod_up = str(mod_hint).upper() if mod_hint is not None else \"\"\n\n        is_ct = (mod_up in [\"CT\", \"CTA\"])\n\n        try:\n            if is_ct:\n                mips = make_ct_multiwindow_axial_mip_stream(sp, self.out_size)\n            else:\n                mips = make_triplanar_mips_stream(sp, is_ct=False, out_size=self.out_size)\n        except Exception:\n            # Last-resort fallback to keep training running\n            mips = np.zeros((3, self.out_size, self.out_size), dtype=np.float32)\n\n        x = torch.from_numpy(mips).float()\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\n# =============================================================================\n# MODEL / METRICS\n# =============================================================================\ndef build_efficientnet_b0(n_out=14) -> nn.Module:\n    try:\n        model = torchvision.models.efficientnet_b0(\n            weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        )\n    except Exception:\n        model = torchvision.models.efficientnet_b0(pretrained=True)\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, n_out)\n    return model\n\ndef compute_auc_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_auc, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_auc[c] = np.nan\n                continue\n            auc = roc_auc_score(y_true[:, i], y_prob[:, i])\n            col_auc[c] = float(auc); macro_vals.append(float(auc))\n        except Exception:\n            col_auc[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_auc, macro\n\ndef compute_ap_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_ap, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_ap[c] = np.nan\n                continue\n            ap = average_precision_score(y_true[:, i], y_prob[:, i])\n            col_ap[c] = float(ap); macro_vals.append(float(ap))\n        except Exception:\n            col_ap[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_ap, macro\n\ndef tune_thresholds_best_f1(y_true: np.ndarray, y_prob: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns per-label thresholds (0..1) maximizing F1 on val.\n    \"\"\"\n    n_labels = y_true.shape[1]\n    thrs = np.zeros(n_labels, dtype=np.float32)\n    grid = np.linspace(0.0, 1.0, 101)\n    for i in range(n_labels):\n        yi = y_true[:, i].astype(np.int32)\n        pi = y_prob[:, i]\n        if len(np.unique(yi)) < 2:\n            thrs[i] = 0.5\n            continue\n        best_f1, best_t = -1.0, 0.5\n        for t in grid:\n            pred = (pi >= t).astype(np.int32)\n            tp = int((pred & (yi == 1)).sum())\n            fp = int((pred & (yi == 0)).sum())\n            fn = int(((1 - pred) & (yi == 1)).sum())\n            precision = tp / max(1, (tp + fp))\n            recall    = tp / max(1, (tp + fn))\n            f1 = 2*precision*recall / max(1e-8, (precision + recall))\n            if f1 > best_f1:\n                best_f1, best_t = f1, t\n        thrs[i] = best_t\n    return thrs\n\ndef confusion_stats(y_true: np.ndarray, y_prob: np.ndarray, thrs: np.ndarray,\n                    cols: List[str], top_k: int = 6) -> pd.DataFrame:\n    rows = []\n    for i, c in enumerate(cols):\n        yi = y_true[:, i].astype(np.int32)\n        pi = (y_prob[:, i] >= thrs[i]).astype(np.int32)\n        tp = int((pi & (yi == 1)).sum())\n        fp = int((pi & (yi == 0)).sum())\n        tn = int(((1 - pi) & (yi == 0)).sum())\n        fn = int(((1 - pi) & (yi == 1)).sum())\n        prec = tp / max(1, (tp + fp))\n        rec  = tp / max(1, (tp + fn))\n        f1   = 2*prec*rec / max(1e-8, (prec + rec))\n        rows.append([c, thrs[i], tp, fp, tn, fn, prec, rec, f1])\n    df = pd.DataFrame(rows, columns=[\"label\",\"thr\",\"TP\",\"FP\",\"TN\",\"FN\",\"precision\",\"recall\",\"F1\"])\n    priority = [\"Aneurysm Present\", \"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\",\n                \"Basilar Tip\", \"Anterior Communicating Artery\"]\n    order = priority + [c for c in cols if c not in priority]\n    df = df.set_index(\"label\").loc[order].reset_index()\n    return df.head(top_k)\n\n# =============================================================================\n# TRAIN\n# =============================================================================\ndef train_model(args):\n    print(\"== RSNA IA Detection: TRAIN ==\")\n    set_seed(args.seed, getattr(args, \"benchmark_mode\", False))\n    dev = device()\n    print(f\"Device: {dev} | AMP: {Config.USE_AMP}\")\n\n    csv_path = os.path.join(args.data_dir, \"train.csv\")\n    if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n    df = pd.read_csv(csv_path)\n    print(f\"Total rows in CSV: {len(df):,}\")\n\n    # Split (no leakage)\n    train_df, val_df = stratified_split(df, seed=args.seed)\n\n    # Smoke limits (quick runs). Set both to None to use ALL.\n    if Config.SMOKE_TRAIN_LIMIT is not None:\n        train_df = train_df.head(Config.SMOKE_TRAIN_LIMIT).copy()\n    if Config.SMOKE_VAL_LIMIT is not None:\n        val_df   = val_df.head(Config.SMOKE_VAL_LIMIT).copy()\n\n    series_dir = os.path.join(args.data_dir, \"series\")\n    print(\"Scanning decodability (quick test on first slice of each series)...\")\n    train_keep = filter_decodable_df(train_df, series_dir)\n    val_keep   = filter_decodable_df(val_df,   series_dir)\n\n    # Fallback if filtering keeps 0\n    if len(train_keep) == 0:\n        print(\"‚ö†Ô∏è  Kept 0 for train ‚Äî using unfiltered subset.\")\n        train_keep = train_df.head(64).copy()\n    if len(val_keep) == 0:\n        print(\"‚ö†Ô∏è  Kept 0 for val ‚Äî using unfiltered subset.\")\n        val_keep = val_df.head(32).copy()\n\n    print(f\"Train: {len(train_keep):,} | Val: {len(val_keep):,}\")\n\n    train_ds = MIPDataset(train_keep, series_dir, args.img_size)\n    val_ds   = MIPDataset(val_keep,   series_dir, args.img_size)\n\n    tkw = dict(batch_size=args.batch_size, shuffle=True,  num_workers=args.num_workers, drop_last=True)\n    vkw = dict(batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, drop_last=False)\n    if dev == \"cuda\":\n        tkw[\"pin_memory\"] = True; vkw[\"pin_memory\"] = True\n    train_loader = DataLoader(train_ds, **tkw)\n    val_loader   = DataLoader(val_ds, **vkw)\n\n    model = build_efficientnet_b0(len(Config.TARGET_COLS)).to(dev)\n    print(f\"Model params: {count_params(model):,}\")\n\n    # Class imbalance weights\n    posw = []\n    for c in Config.TARGET_COLS:\n        pos = train_keep[c].sum()\n        neg = len(train_keep) - pos\n        w = min(max((neg / max(1.0, pos)), 1.0), 50.0) if pos > 0 else 1.0\n        posw.append(w)\n    posw = torch.tensor(posw, device=dev)\n\n    criterion = nn.BCEWithLogitsLoss(pos_weight=posw)\n    opt = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n    sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=args.epochs)\n\n    use_amp = (dev == \"cuda\") and Config.USE_AMP\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    best_auc = -1.0\n    best_ckpt = args.out\n    patience_left = Config.EARLY_STOP_PATIENCE if Config.EARLY_STOP_PATIENCE is not None else 1_000_000\n\n    for epoch in range(args.epochs):\n        # ----------------- Train ----------------- #\n        model.train()\n        run_loss = 0.0; correct = 0; total = 0\n        t0 = time.time()\n        for b, (x, y, _) in enumerate(train_loader, 1):\n            x, y = x.to(dev), y.to(dev)\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                out = model(x)\n                loss = criterion(out, y)\n            scaler.scale(loss).backward()\n            scaler.step(opt); scaler.update()\n\n            run_loss += loss.item()\n            preds = (torch.sigmoid(out) > 0.5).float()\n            correct += (preds == y).sum().item(); total += y.numel()\n\n            if b % Config.LOG_EVERY_N == 0 or b == 1:\n                print(f\"[E{epoch+1} {b}/{len(train_loader)}] \"\n                      f\"loss={run_loss/b:.4f} acc={correct/max(1,total):.3f} \"\n                      f\"lr={sch.get_last_lr()[0]:.2e}\")\n\n        train_loss = run_loss / max(1, len(train_loader))\n        train_acc  = correct / max(1, total)\n\n        # ----------------- Val ----------------- #\n        model.eval()\n        val_loss = 0.0\n        preds_all, targs_all, uids_all = [], [], []\n        with torch.no_grad():\n            for x, y, uids in val_loader:\n                x, y = x.to(dev), y.to(dev)\n                with torch.cuda.amp.autocast(enabled=use_amp):\n                    out = model(x); loss = criterion(out, y)\n                val_loss += loss.item()\n                preds_all.append(torch.sigmoid(out).cpu().numpy())\n                targs_all.append(y.cpu().numpy())\n                uids_all.extend(list(uids))\n\n        val_loss /= max(1, len(val_loader))\n        P = np.vstack(preds_all) if preds_all else np.zeros((0, len(Config.TARGET_COLS)))\n        T = np.vstack(targs_all) if targs_all else np.zeros((0, len(Config.TARGET_COLS)))\n\n        col_aucs, macro_auc = compute_auc_per_column(T, P, Config.TARGET_COLS)\n        col_aps , macro_ap  = compute_ap_per_column(T, P, Config.TARGET_COLS)\n\n        dt = time.time() - t0\n        print(f\"Epoch {epoch+1}/{args.epochs} | {dt:.1f}s  \"\n              f\"train_loss={train_loss:.4f} train_acc={train_acc:.3f}  \"\n              f\"val_loss={val_loss:.4f} macro_auc={macro_auc:.4f} macro_ap={macro_ap:.4f}\")\n\n        # Threshold tuning (val only)\n        thrs = tune_thresholds_best_f1(T, P)\n        conf_df = confusion_stats(T, P, thrs, Config.TARGET_COLS, top_k=6)\n        print(\"\\nVal confusion summary (top labels, tuned thresholds):\")\n        for _, r in conf_df.iterrows():\n            print(f\"  {r['label'][:28]:28s} thr={r['thr']:.2f}  TP={r['TP']:3d} FP={r['FP']:3d} \"\n                  f\"TN={r['TN']:3d} FN={r['FN']:3d}  P={r['precision']:.2f} R={r['recall']:.2f} F1={r['F1']:.2f}\")\n        print(\"\")\n\n        # Save val predictions CSV for inspection\n        out_csv = \"/kaggle/working/val_preds.csv\"\n        val_out = pd.DataFrame({\"SeriesInstanceUID\": uids_all})\n        for i, c in enumerate(Config.TARGET_COLS):\n            val_out[c + \"_prob\"] = P[:, i]\n            val_out[c + \"_true\"] = T[:, i]\n        val_out.to_csv(out_csv, index=False)\n        print(f\"Saved validation predictions to {out_csv} (shape={val_out.shape})\")\n\n        # Save best checkpoint (stores thresholds too)\n        if macro_auc > best_auc:\n            best_auc = macro_auc\n            torch.save({\n                \"epoch\": epoch+1,\n                \"model_state_dict\": model.state_dict(),\n                \"optimizer_state_dict\": opt.state_dict(),\n                \"scheduler_state_dict\": sch.state_dict(),\n                \"auc_macro\": macro_auc,\n                \"target_cols\": Config.TARGET_COLS,\n                \"thresholds\": thrs,  # tuned on val\n                \"config\": {\n                    \"img_size\": args.img_size,\n                    \"batch_size\": args.batch_size,\n                    \"lr\": args.lr,\n                    \"seed\": args.seed,\n                    \"ct_windows\": Config.CT_WINDOWS,\n                    \"highlight\": {\n                        \"enable\": Config.HIGHLIGHT_ENABLE,\n                        \"pct\": Config.HIGHLIGHT_TOP_PCT,\n                        \"gamma\": Config.HIGHLIGHT_GAMMA,\n                        \"blend\": Config.HIGHLIGHT_BLEND,\n                        \"ct_skip_bone\": Config.CT_HIGHLIGHT_SKIP_BONE,\n                        \"bone_hu\": Config.CT_BONE_MASK_HU,\n                    }\n                }\n            }, best_ckpt)\n            print(f\"Saved new best: {best_ckpt} (macro_auc={macro_auc:.4f})\")\n            patience_left = Config.EARLY_STOP_PATIENCE if Config.EARLY_STOP_PATIENCE is not None else patience_left\n        else:\n            if Config.EARLY_STOP_PATIENCE is not None:\n                patience_left -= 1\n                print(f\"No AUC improvement. Early-stop patience left: {patience_left}\")\n                if patience_left <= 0:\n                    print(\"Early stopping.\")\n                    break\n\n        sch.step()\n\n    print(f\"Training complete. Best macro AUC: {best_auc:.4f} | ckpt={best_ckpt}\")\n    return best_ckpt\n\n# =============================================================================\n# JUPYTER HELPER\n# =============================================================================\ndef train_model_jupyter(data_dir=None, img_size=None, batch_size=None, epochs=None,\n                        lr=None, num_workers=None, seed=None, out=None, benchmark_mode=False):\n    class A: pass\n    a = A()\n    a.data_dir = data_dir or Config.DATA_DIR\n    a.img_size = img_size or Config.IMG_SIZE\n    a.batch_size = batch_size or Config.BATCH_SIZE\n    a.epochs = epochs or Config.EPOCHS\n    a.lr = lr or Config.LR\n    a.num_workers = num_workers if num_workers is not None else Config.NUM_WORKERS\n    a.seed = seed or Config.SEED\n    a.out = out or \"/kaggle/working/best.pt\"\n    a.benchmark_mode = benchmark_mode\n    return train_model(a)\n\nprint(\"Loaded improved script (bone-aware highlight). Example:\")\nprint('train_model_jupyter(data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", img_size=288, batch_size=2, epochs=1, num_workers=0, benchmark_mode=True)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T18:07:48.082355Z","iopub.execute_input":"2025-09-15T18:07:48.083203Z","iopub.status.idle":"2025-09-15T18:07:48.338724Z","shell.execute_reply.started":"2025-09-15T18:07:48.083175Z","shell.execute_reply":"2025-09-15T18:07:48.338075Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Loaded improved script (bone-aware highlight). Example:\ntrain_model_jupyter(data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", img_size=288, batch_size=2, epochs=1, num_workers=0, benchmark_mode=True)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- Recommended baseline ---\nConfig.SMOKE_TRAIN_LIMIT = 600\nConfig.SMOKE_VAL_LIMIT   = 200\nConfig.IMG_SIZE          = 288\nConfig.LOG_EVERY_N       = 50\nConfig.USE_CACHE         = True\n\n# bone-aware highlight (ON)\nConfig.HIGHLIGHT_CT      = True\nConfig.BONE_SUPPRESS     = True\nConfig.BONE_THRESH_HU    = 300\nConfig.BONE_MORPH_K      = 3\nConfig.HIGHLIGHT_MRI     = True\n\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=Config.IMG_SIZE,\n    batch_size=2,\n    epochs=2,        # you can use 2‚Äì3 once stable\n    num_workers=0,\n    benchmark_mode=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T18:08:14.272179Z","iopub.execute_input":"2025-09-15T18:08:14.272715Z","iopub.status.idle":"2025-09-15T19:47:49.908188Z","shell.execute_reply.started":"2025-09-15T18:08:14.272689Z","shell.execute_reply":"2025-09-15T19:47:49.903966Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"== RSNA IA Detection: TRAIN ==\nDevice: cuda | AMP: True\nTotal rows in CSV: 4,348\nScanning decodability (quick test on first slice of each series)...\nDecodable series (quick test): 600/600 kept\nDecodable series (quick test): 200/200 kept\nTrain: 600 | Val: 200\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 141MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model params: 4,025,482\n[E1 1/300] loss=0.8897 acc=0.500 lr=2.00e-04\n[E1 50/300] loss=1.5267 acc=0.761 lr=2.00e-04\n[E1 100/300] loss=1.2954 acc=0.790 lr=2.00e-04\n[E1 150/300] loss=1.2250 acc=0.790 lr=2.00e-04\n[E1 200/300] loss=1.2158 acc=0.764 lr=2.00e-04\n[E1 250/300] loss=1.2630 acc=0.744 lr=2.00e-04\n[E1 300/300] loss=1.2614 acc=0.710 lr=2.00e-04\nEpoch 1/2 | 4563.1s  train_loss=1.2614 train_acc=0.710  val_loss=1.3187 macro_auc=0.5604 macro_ap=0.1066\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.38  TP= 98 FP= 98 TN=  4 FN=  0  P=0.50 R=1.00 F1=0.67\n  Left Middle Cerebral Artery  thr=0.52  TP=  9 FP=134 TN= 56 FN=  1  P=0.06 R=0.90 F1=0.12\n  Right Middle Cerebral Artery thr=0.40  TP= 20 FP=159 TN= 20 FN=  1  P=0.11 R=0.95 F1=0.20\n  Basilar Tip                  thr=0.67  TP=  2 FP=  6 TN=190 FN=  2  P=0.25 R=0.50 F1=0.33\n  Anterior Communicating Arter thr=0.58  TP=  3 FP=  6 TN=180 FN= 11  P=0.33 R=0.21 F1=0.26\n  Left Infraclinoid Internal C thr=0.56  TP=  1 FP= 15 TN=184 FN=  0  P=0.06 R=1.00 F1=0.12\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 29))\nSaved new best: /kaggle/working/best.pt (macro_auc=0.5604)\n[E2 1/300] loss=1.4287 acc=0.500 lr=1.00e-04\n[E2 50/300] loss=1.1700 acc=0.533 lr=1.00e-04\n[E2 100/300] loss=1.0939 acc=0.554 lr=1.00e-04\n[E2 150/300] loss=1.1180 acc=0.574 lr=1.00e-04\n[E2 200/300] loss=1.1387 acc=0.589 lr=1.00e-04\n[E2 250/300] loss=1.1724 acc=0.597 lr=1.00e-04\n[E2 300/300] loss=1.1818 acc=0.600 lr=1.00e-04\nEpoch 2/2 | 17.5s  train_loss=1.1818 train_acc=0.600  val_loss=1.2776 macro_auc=0.5958 macro_ap=0.1134\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.37  TP= 98 FP= 99 TN=  3 FN=  0  P=0.50 R=1.00 F1=0.66\n  Left Middle Cerebral Artery  thr=0.54  TP= 10 FP= 71 TN=119 FN=  0  P=0.12 R=1.00 F1=0.22\n  Right Middle Cerebral Artery thr=0.50  TP= 17 FP=111 TN= 68 FN=  4  P=0.13 R=0.81 F1=0.23\n  Basilar Tip                  thr=0.67  TP=  2 FP= 13 TN=183 FN=  2  P=0.13 R=0.50 F1=0.21\n  Anterior Communicating Arter thr=0.57  TP=  4 FP= 34 TN=152 FN= 10  P=0.11 R=0.29 F1=0.15\n  Left Infraclinoid Internal C thr=0.53  TP=  1 FP= 18 TN=181 FN=  0  P=0.05 R=1.00 F1=0.10\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 29))\nSaved new best: /kaggle/working/best.pt (macro_auc=0.5958)\nTraining complete. Best macro AUC: 0.5958 | ckpt=/kaggle/working/best.pt\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/best.pt'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nRSNA Intracranial Aneurysm Detection - Baseline (patched)\n- MRI/MRA  : tri-planar MIPs (axial/coronal/sagittal) ‚Üí highlight stretch\n- CT/CTA   : multi-window axial MIP (brain/soft/bone) ‚Üí bone-aware highlight with morphology\n- DICOM decode (VOI LUT + Rescale) robust, quiet & cached\n- Loss: BCEWithLogits + Focal (Œ≥=2) with per-class pos_weight\n- Class-balanced sampler (rare positives appear regularly)\n- Optional consistency penalty: locations ‚â§ \"Aneurysm Present\"\n- Metrics: per-label AUC/AP, macro AUC/AP, micro AP\n- Per-label threshold tuning (max F1), confusion summary\n- Saves: /kaggle/working/val_preds.csv and best checkpoint\n\nExample:\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=288, batch_size=2, epochs=2, num_workers=0, benchmark_mode=True\n)\n\"\"\"\n\nimport os, time, random, warnings, hashlib\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\n\n# VOI LUT import (compat across pydicom versions)\ntry:\n    from pydicom.pixel_data_handlers import apply_voi_lut\nexcept Exception:\n    try:\n        from pydicom.pixel_data_handlers.util import apply_voi_lut\n    except Exception:\n        def apply_voi_lut(x, ds): return x\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torchvision\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nwarnings.filterwarnings(\"ignore\")\n\n# =============================================================================\n# CONFIG\n# =============================================================================\nclass Config:\n    # Kaggle dataset\n    DATA_DIR   = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\n    SERIES_DIR = f\"{DATA_DIR}/series\"\n    TRAIN_CSV  = f\"{DATA_DIR}/train.csv\"\n\n    # Train defaults\n    IMG_SIZE   = 288\n    BATCH_SIZE = 2\n    EPOCHS     = 1\n    LR         = 2e-4\n    NUM_WORKERS= 0\n    SEED       = 42\n    USE_AMP    = True\n\n    # Logs / cache\n    LOG_EVERY_N = 50\n    USE_CACHE = True\n    CACHE_DIR = \"/kaggle/working/mip_cache\"\n    CACHE_VERSION = \"v7.0\"\n\n    # DICOM/MIP (streaming always ‚Üí lowest RAM)\n    LARGE_SERIES_THRESHOLD = 1\n    MAX_WORKERS = 1\n\n    # Multi-window CT (L, W) triplet ‚Üí 3 channels\n    CT_WINDOWS = [(40, 80), (200, 500), (600, 2800)]  # brain, soft/vessel, bone\n\n    # Highlight master switches\n    HIGHLIGHT_ENABLE      = True\n    HIGHLIGHT_ONLY_NON_CT = False  # keep False; we skip bone anyway\n    HIGHLIGHT_TOP_PCT     = 1.0\n    HIGHLIGHT_GAMMA       = 0.7\n    HIGHLIGHT_BLEND       = 0.6\n\n    # CT bone-aware highlight\n    CT_HIGHLIGHT_SKIP_BONE = True\n    CT_BONE_MASK_HU        = 300      # intended lower threshold\n    CT_BONE_MORPH_K        = 3        # morphology kernel (0 disables)\n\n    # Small subset so one run completes quickly; set both to None to use ALL\n    SMOKE_TRAIN_LIMIT = 600\n    SMOKE_VAL_LIMIT   = 200\n\n    # Early stopping (optional)\n    EARLY_STOP_PATIENCE = None  # set to int for longer runs\n\n    # Consistency penalty (locations shouldn't exceed \"Present\")\n    CONSISTENCY_W = 0.2  # set 0.0 to disable\n\n    # Labels (13 sites + global)\n    TARGET_COLS = [\n        \"Left Infraclinoid Internal Carotid Artery\",\n        \"Right Infraclinoid Internal Carotid Artery\",\n        \"Left Supraclinoid Internal Carotid Artery\",\n        \"Right Supraclinoid Internal Carotid Artery\",\n        \"Left Middle Cerebral Artery\",\n        \"Right Middle Cerebral Artery\",\n        \"Anterior Communicating Artery\",\n        \"Left Anterior Cerebral Artery\",\n        \"Right Anterior Cerebral Artery\",\n        \"Left Posterior Communicating Artery\",\n        \"Right Posterior Communicating Artery\",\n        \"Basilar Tip\",\n        \"Other Posterior Circulation\",\n        \"Aneurysm Present\",\n    ]\n\n# ImageNet normalization (works fine even though channels ‚â† RGB semantics)\nIMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\nIMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n\n# =============================================================================\n# UTIL\n# =============================================================================\ndef set_seed(seed=42, benchmark_mode=False):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = not benchmark_mode\n    torch.backends.cudnn.benchmark     = benchmark_mode\n\ndef device() -> str:\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef count_params(m: nn.Module) -> int:\n    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n\n# =============================================================================\n# DICOM I/O & NORMALIZATION\n# =============================================================================\ndef iter_dicom_files(series_path: str) -> List[str]:\n    sp = Path(series_path)\n    dcm_files = list(sp.glob(\"*.dcm\"))\n    if not dcm_files:\n        dcm_files = [f for f in sp.iterdir() if f.is_file() and not f.suffix]\n    if not dcm_files:\n        return []\n    infos = []\n    for f in dcm_files:\n        try:\n            ds = pydicom.dcmread(str(f), stop_before_pixels=True, force=True)\n            ins = getattr(ds, \"InstanceNumber\", 0)\n        except Exception:\n            ins = 0\n        infos.append((ins, str(f)))\n    infos.sort(key=lambda x: (x[0], x[1]))\n    return [p for _, p in infos]\n\ndef read_pixel(ds) -> np.ndarray:\n    \"\"\"Decode with VOI LUT + RescaleSlope/Intercept ‚Üí float32 (HU for CT).\"\"\"\n    arr = ds.pixel_array\n    try:\n        if hasattr(ds, 'VOILUTSequence') or hasattr(ds, 'WindowCenter'):\n            arr = apply_voi_lut(arr, ds)\n    except Exception:\n        pass\n    if hasattr(ds, \"RescaleSlope\") and hasattr(ds, \"RescaleIntercept\"):\n        arr = arr.astype(np.float32) * float(ds.RescaleSlope) + float(ds.RescaleIntercept)\n    else:\n        arr = arr.astype(np.float32)\n    return arr\n\ndef _ensure_gray2d(img: np.ndarray) -> np.ndarray:\n    if img.ndim == 3:  # RGB or multi-channel ‚Üí grayscale\n        if img.shape[-1] == 3:\n            img = np.mean(img, axis=-1)\n        else:\n            img = img.max(axis=-1)\n    return img.astype(np.float32)\n\ndef window_ct(img: np.ndarray, level=200, width=500) -> np.ndarray:\n    img = img.astype(np.float32)\n    lo, hi = float(level) - float(width)/2.0, float(level) + float(width)/2.0\n    img = np.clip(img, lo, hi)\n    denom = max(1e-6, (hi - lo))\n    img = (img - lo) / denom\n    return np.clip(img, 0, 1)\n\ndef normalize_mr(img: np.ndarray) -> np.ndarray:\n    img = img.astype(np.float32)\n    p1, p99 = np.percentile(img, [1, 99])\n    img = np.clip(img, p1, p99)\n    if p99 > p1:\n        img = (img - p1) / (p99 - p1)\n    return np.clip(img, 0, 1)\n\n# =============================================================================\n# HIGHLIGHT STRETCH\n# =============================================================================\ndef highlight_stretch(img01: np.ndarray,\n                      pct: float = None,\n                      gamma: float = None,\n                      blend: float = None) -> np.ndarray:\n    \"\"\"\n    Brighten only the top `pct` percent of pixels in [0..1], with gamma and blend.\n    Below the percentile, pixels remain unchanged (smooth, one-sided stretch).\n    \"\"\"\n    pct   = Config.HIGHLIGHT_TOP_PCT if pct is None else pct\n    gamma = Config.HIGHLIGHT_GAMMA   if gamma is None else gamma\n    blend = Config.HIGHLIGHT_BLEND   if blend is None else blend\n\n    img = img01.astype(np.float32)\n    img = np.clip(img, 0.0, 1.0)\n\n    if pct <= 0.0:\n        return img.copy()\n\n    thr = np.percentile(img, 100.0 - pct)\n    # If image is flat or threshold at top, do nothing\n    if not np.isfinite(thr) or thr >= 0.999:\n        return img.copy()\n\n    out = img.copy()\n    mask = img >= thr\n    # stretch the tail to [0..1]\n    denom = max(1e-6, 1.0 - thr)\n    hi = (img - thr) / denom\n    # gamma shaping (gamma<1 -> brighter)\n    if gamma > 0:\n        hi = np.power(hi, 1.0 / gamma)\n    # blend tail with original (keep continuity at thr)\n    out[mask] = (1.0 - blend) * img[mask] + blend * hi[mask]\n    return np.clip(out, 0.0, 1.0)\n\n# =============================================================================\n# MIP BUILDERS (streaming, quiet)\n# =============================================================================\ndef _cache_path(series_path: str, out_size: int, key_extra: str) -> str:\n    os.makedirs(Config.CACHE_DIR, exist_ok=True)\n    hl = f\"hl{int(Config.HIGHLIGHT_ENABLE)}_{Config.HIGHLIGHT_TOP_PCT:.2f}_{Config.HIGHLIGHT_GAMMA:.2f}_{Config.HIGHLIGHT_BLEND:.2f}\"\n    key = f\"{Config.CACHE_VERSION}_{os.path.basename(series_path)}_{out_size}_{key_extra}_{hl}_skipbone{int(Config.CT_HIGHLIGHT_SKIP_BONE)}_{Config.CT_BONE_MASK_HU}_morph{Config.CT_BONE_MORPH_K}\"\n    h = hashlib.md5(key.encode()).hexdigest()[:16]\n    return os.path.join(Config.CACHE_DIR, f\"mip_{h}.npy\")\n\ndef _load_cache(path: str) -> Optional[np.ndarray]:\n    try:\n        if Config.USE_CACHE and os.path.exists(path):\n            arr = np.load(path, allow_pickle=False)\n            return arr.astype(np.float32) / 255.0\n    except Exception:\n        pass\n    return None\n\ndef _save_cache(arr: np.ndarray, path: str):\n    if not Config.USE_CACHE: return\n    try:\n        np.save(path, (arr * 255).astype(np.uint8), allow_pickle=False)\n    except Exception:\n        pass\n\ndef make_triplanar_mips_stream(series_path: str, is_ct: bool, out_size: int) -> np.ndarray:\n    \"\"\"\n    MRI/MRA path: tri-planar MIPs; apply highlight stretch on each plane (no bone mask).\n    If is_ct is True, still usable; not the default for CT.\n    \"\"\"\n    cache = _cache_path(series_path, out_size, key_extra=f\"tri_isct{int(is_ct)}\")\n    cached = _load_cache(cache)\n    if cached is not None: return cached\n\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n\n    axial = None\n    cor_rows = None  # (Z, W)\n    sag_cols = None  # (Z, H)\n\n    H = W = None\n    z = 0\n    for f in files:\n        try:\n            ds  = pydicom.dcmread(f, force=True)\n            arr = read_pixel(ds)\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            img = _ensure_gray2d(arr)\n\n            if axial is None:\n                H, W = img.shape\n                axial    = img.copy()\n                cor_rows = np.zeros((len(files), W), dtype=np.float32)\n                sag_cols = np.zeros((len(files), H), dtype=np.float32)\n            else:\n                np.maximum(axial, img, out=axial)\n\n            cor_rows[z, :] = img.max(axis=0)\n            sag_cols[z, :] = img.max(axis=1)\n            z += 1\n        except Exception:\n            continue\n\n    if axial is None: raise RuntimeError(\"No decodable slices\")\n\n    # Normalize\n    if is_ct:\n        axial    = window_ct(axial, 200, 500)\n        cor_rows = window_ct(cor_rows, 200, 500)\n        sag_cols = window_ct(sag_cols, 200, 500)\n    else:\n        axial    = normalize_mr(axial)\n        cor_rows = normalize_mr(cor_rows)\n        sag_cols = normalize_mr(sag_cols)\n\n    # Resize\n    axial    = cv2.resize(axial,    (out_size, out_size), interpolation=cv2.INTER_AREA)\n    coronal  = cv2.resize(cor_rows, (out_size, out_size), interpolation=cv2.INTER_AREA)\n    sagittal = cv2.resize(sag_cols, (out_size, out_size), interpolation=cv2.INTER_AREA)\n\n    # Highlight (MRI/MRA: no bone mask)\n    do_highlight = Config.HIGHLIGHT_ENABLE and (not (Config.HIGHLIGHT_ONLY_NON_CT and is_ct))\n    if do_highlight:\n        axial    = highlight_stretch(axial)\n        coronal  = highlight_stretch(coronal)\n        sagittal = highlight_stretch(sagittal)\n\n    mips = np.stack([axial, coronal, sagittal], axis=0).astype(np.float32)\n    _save_cache(mips, cache)\n    return mips\n\ndef _morph_clean(mask: np.ndarray, k: int) -> np.ndarray:\n    if k is None or k <= 0: return mask\n    kernel = np.ones((k,k), np.uint8)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  kernel)\n    return mask\n\ndef make_ct_multiwindow_axial_mip_stream(series_path: str, out_size: int) -> np.ndarray:\n    \"\"\"\n    CT/CTA path:\n      1) Build axial MIP in HU\n      2) Build axial *bone mask* MIP from HU threshold (CT_BONE_MASK_HU) + morphology\n      3) Apply three CT windows to axial HU ‚Üí 3 channels\n      4) Apply highlight on each channel, but SKIP pixels where bone mask==1\n    \"\"\"\n    win_key = \"_\".join([f\"{l}_{w}\" for (l,w) in Config.CT_WINDOWS])\n    cache = _cache_path(series_path, out_size, key_extra=f\"ctmw_{win_key}\")\n    cached = _load_cache(cache)\n    if cached is not None: return cached\n\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n\n    axial_hu = None\n    axial_bone = None  # bone mask MIP\n\n    for f in files:\n        try:\n            ds  = pydicom.dcmread(f, force=True)\n            arr = read_pixel(ds)  # after rescale ‚Üí HU\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            img = _ensure_gray2d(arr)  # float HU\n\n            # Build intensity axial HU MIP\n            if axial_hu is None:\n                axial_hu = img.copy()\n            else:\n                np.maximum(axial_hu, img, out=axial_hu)\n\n            # Build bone MIP from per-slice threshold\n            bone_slice = (img > float(Config.CT_BONE_MASK_HU)).astype(np.uint8)\n            if axial_bone is None:\n                axial_bone = bone_slice.copy()\n            else:\n                np.maximum(axial_bone, bone_slice, out=axial_bone)\n        except Exception:\n            continue\n\n    if axial_hu is None: raise RuntimeError(\"No decodable slices\")\n\n    # Resize bone mask to output size and clean\n    bone_mip = cv2.resize(axial_bone, (out_size, out_size), interpolation=cv2.INTER_NEAREST)\n    bone_mip = _morph_clean(bone_mip.astype(np.uint8), Config.CT_BONE_MORPH_K)\n\n    # Create 3 windowed channels in [0..1]\n    channels = []\n    for (L, W) in Config.CT_WINDOWS:\n        ch = window_ct(axial_hu, level=L, width=W)  # 0..1\n        ch = cv2.resize(ch, (out_size, out_size), interpolation=cv2.INTER_AREA)\n        channels.append(ch.astype(np.float32))\n\n    # Highlight handling for CT\n    do_highlight = Config.HIGHLIGHT_ENABLE and (not Config.HIGHLIGHT_ONLY_NON_CT)\n    if do_highlight:\n        if Config.CT_HIGHLIGHT_SKIP_BONE:\n            inv_bone = (bone_mip == 0)\n            for i in range(len(channels)):\n                hi = highlight_stretch(channels[i])\n                channels[i] = np.where(inv_bone, hi, channels[i])\n        else:\n            for i in range(len(channels)):\n                channels[i] = highlight_stretch(channels[i])\n\n    mips = np.stack(channels, axis=0)  # 3xHxW\n    _save_cache(mips, cache)\n    return mips\n\ndef _detect_modality_from_header(series_path: str) -> Optional[str]:\n    files = iter_dicom_files(series_path)\n    if not files: return None\n    try:\n        ds = pydicom.dcmread(files[0], stop_before_pixels=True, force=True)\n        mod = str(getattr(ds, \"Modality\", \"\")).upper()\n        return mod or None\n    except Exception:\n        return None\n\n# =============================================================================\n# DATASET & FILTERING\n# =============================================================================\ndef stratified_split(df: pd.DataFrame, global_col=\"Aneurysm Present\", seed=42, n_splits=5):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    tr_idx, va_idx = next(skf.split(df, df[global_col]))\n    return df.iloc[tr_idx].copy(), df.iloc[va_idx].copy()\n\ndef safe_series_path(series_dir: str, uid: str) -> str:\n    p = os.path.join(series_dir, str(uid))\n    if not os.path.exists(p): raise FileNotFoundError(p)\n    return p\n\ndef _quick_series_decode_ok(series_path: str) -> bool:\n    \"\"\"Try decoding ONE slice: robust and version-agnostic.\"\"\"\n    try:\n        files = iter_dicom_files(series_path)\n        if not files: return False\n        ds = pydicom.dcmread(files[0], force=True)\n        _ = ds.pixel_array\n        return True\n    except Exception:\n        return False\n\ndef filter_decodable_df(df: pd.DataFrame, series_dir: str) -> pd.DataFrame:\n    uids = df[\"SeriesInstanceUID\"].astype(str).tolist()\n    keep_mask = []\n    for uid in uids:\n        sp = os.path.join(series_dir, uid)\n        keep_mask.append(_quick_series_decode_ok(sp))\n    kept = df[keep_mask].reset_index(drop=True)\n    print(f\"Decodable series (quick test): {len(kept)}/{len(df)} kept\")\n    return kept\n\nclass MIPDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, series_dir: str, out_size: int):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.out_size = out_size\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss:\n            raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n\n        # modality hint from CSV if present; else detect from header\n        mod_hint = row.get(\"Modality\", None)\n        if pd.isna(mod_hint) or not str(mod_hint).strip():\n            mod_hint = _detect_modality_from_header(sp)\n        mod_up = str(mod_hint).upper() if mod_hint is not None else \"\"\n\n        is_ct = (mod_up in [\"CT\", \"CTA\"])\n\n        try:\n            if is_ct:\n                mips = make_ct_multiwindow_axial_mip_stream(sp, self.out_size)\n            else:\n                mips = make_triplanar_mips_stream(sp, is_ct=False, out_size=self.out_size)\n        except Exception:\n            # Last-resort fallback to keep training running\n            mips = np.zeros((3, self.out_size, self.out_size), dtype=np.float32)\n\n        x = torch.from_numpy(mips).float()       # [3,H,W] in [0,1]\n        # ImageNet normalization\n        x = (x - IMAGENET_MEAN) / IMAGENET_STD\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\ndef build_class_balanced_sampler(df: pd.DataFrame, target_cols: List[str]) -> WeightedRandomSampler:\n    pos = df[target_cols].sum(0).values\n    neg = len(df) - pos\n    cls_w = np.where(pos > 0, neg / np.maximum(1, pos), 1.0)\n    cls_w = np.clip(cls_w, 1.0, 50.0)\n    Y = df[target_cols].values.astype(np.float32)\n    w = 1.0 + (Y * cls_w).sum(1)\n    w = torch.as_tensor(w, dtype=torch.double)\n    sampler = WeightedRandomSampler(weights=w, num_samples=len(df), replacement=True)\n    return sampler\n\n# =============================================================================\n# MODEL / METRICS\n# =============================================================================\ndef build_efficientnet_b0(n_out=14) -> nn.Module:\n    try:\n        model = torchvision.models.efficientnet_b0(\n            weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1\n        )\n    except Exception:\n        model = torchvision.models.efficientnet_b0(pretrained=True)\n    in_features = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(in_features, n_out)\n    return model\n\nclass BCEWithLogitsFocal(nn.Module):\n    def __init__(self, pos_weight=None, gamma=2.0, reduction=\"mean\"):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction=\"none\")\n        self.gamma = gamma\n        self.reduction = reduction\n    def forward(self, logits, targets):\n        bce = self.bce(logits, targets)              # [B,C]\n        p = torch.sigmoid(logits)\n        pt = p*targets + (1-p)*(1-targets)\n        focal = (1.0 - pt).clamp_min(1e-6).pow(self.gamma)\n        loss = focal * bce\n        if self.reduction == \"mean\":\n            return loss.mean()\n        elif self.reduction == \"sum\":\n            return loss.sum()\n        return loss\n\ndef compute_auc_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_auc, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_auc[c] = np.nan\n                continue\n            auc = roc_auc_score(y_true[:, i], y_prob[:, i])\n            col_auc[c] = float(auc); macro_vals.append(float(auc))\n        except Exception:\n            col_auc[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_auc, macro\n\ndef compute_ap_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_ap, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_ap[c] = np.nan\n                continue\n            ap = average_precision_score(y_true[:, i], y_prob[:, i])\n            col_ap[c] = float(ap); macro_vals.append(float(ap))\n        except Exception:\n            col_ap[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_ap, macro\n\ndef compute_micro_ap(y_true: np.ndarray, y_prob: np.ndarray):\n    mask = (y_true.sum(0) > 0) & ((1 - y_true).sum(0) > 0)\n    if mask.sum() == 0: return np.nan\n    yt = y_true[:, mask].ravel()\n    yp = y_prob[:, mask].ravel()\n    return average_precision_score(yt, yp)\n\ndef tune_thresholds_best_f1(y_true: np.ndarray, y_prob: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns per-label thresholds (0..1) maximizing F1 on val.\n    \"\"\"\n    n_labels = y_true.shape[1]\n    thrs = np.zeros(n_labels, dtype=np.float32)\n    grid = np.linspace(0.0, 1.0, 101)\n    for i in range(n_labels):\n        yi = y_true[:, i].astype(np.int32)\n        pi = y_prob[:, i]\n        if len(np.unique(yi)) < 2:\n            thrs[i] = 0.5\n            continue\n        best_f1, best_t = -1.0, 0.5\n        for t in grid:\n            pred = (pi >= t).astype(np.int32)\n            tp = int((pred & (yi == 1)).sum())\n            fp = int((pred & (yi == 0)).sum())\n            fn = int(((1 - pred) & (yi == 1)).sum())\n            precision = tp / max(1, (tp + fp))\n            recall    = tp / max(1, (tp + fn))\n            f1 = 2*precision*recall / max(1e-8, (precision + recall))\n            if f1 > best_f1:\n                best_f1, best_t = f1, t\n        thrs[i] = best_t\n    return thrs\n\ndef confusion_stats(y_true: np.ndarray, y_prob: np.ndarray, thrs: np.ndarray,\n                    cols: List[str], top_k: int = 6) -> pd.DataFrame:\n    rows = []\n    for i, c in enumerate(cols):\n        yi = y_true[:, i].astype(np.int32)\n        pi = (y_prob[:, i] >= thrs[i]).astype(np.int32)\n        tp = int((pi & (yi == 1)).sum())\n        fp = int((pi & (yi == 0)).sum())\n        tn = int(((1 - pi) & (yi == 0)).sum())\n        fn = int(((1 - pi) & (yi == 1)).sum())\n        prec = tp / max(1, (tp + fp))\n        rec  = tp / max(1, (tp + fn))\n        f1   = 2*prec*rec / max(1e-8, (prec + rec))\n        rows.append([c, thrs[i], tp, fp, tn, fn, prec, rec, f1])\n    df = pd.DataFrame(rows, columns=[\"label\",\"thr\",\"TP\",\"FP\",\"TN\",\"FN\",\"precision\",\"recall\",\"F1\"])\n    priority = [\"Aneurysm Present\", \"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\",\n                \"Basilar Tip\", \"Anterior Communicating Artery\"]\n    order = priority + [c for c in cols if c not in priority]\n    df = df.set_index(\"label\").loc[order].reset_index()\n    return df.head(top_k)\n\n# =============================================================================\n# TRAIN\n# =============================================================================\ndef train_model(args):\n    print(\"== RSNA IA Detection: TRAIN ==\")\n    set_seed(args.seed, getattr(args, \"benchmark_mode\", False))\n    dev = device()\n    print(f\"Device: {dev} | AMP: {Config.USE_AMP}\")\n\n    csv_path = os.path.join(args.data_dir, \"train.csv\")\n    if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n    df = pd.read_csv(csv_path)\n    print(f\"Total rows in CSV: {len(df):,}\")\n\n    # Split (no leakage)\n    train_df, val_df = stratified_split(df, seed=args.seed)\n\n    # Smoke limits (quick runs). Set both to None to use ALL.\n    if Config.SMOKE_TRAIN_LIMIT is not None:\n        train_df = train_df.head(Config.SMOKE_TRAIN_LIMIT).copy()\n    if Config.SMOKE_VAL_LIMIT is not None:\n        val_df   = val_df.head(Config.SMOKE_VAL_LIMIT).copy()\n\n    series_dir = os.path.join(args.data_dir, \"series\")\n    print(\"Scanning decodability (quick test on first slice of each series)...\")\n    train_keep = filter_decodable_df(train_df, series_dir)\n    val_keep   = filter_decodable_df(val_df,   series_dir)\n\n    # Fallback if filtering keeps 0\n    if len(train_keep) == 0:\n        print(\"‚ö†Ô∏è  Kept 0 for train ‚Äî using unfiltered subset.\")\n        train_keep = train_df.head(64).copy()\n    if len(val_keep) == 0:\n        print(\"‚ö†Ô∏è  Kept 0 for val ‚Äî using unfiltered subset.\")\n        val_keep = val_df.head(32).copy()\n\n    print(f\"Train: {len(train_keep):,} | Val: {len(val_keep):,}\")\n\n    train_ds = MIPDataset(train_keep, series_dir, args.img_size)\n    val_ds   = MIPDataset(val_keep,   series_dir, args.img_size)\n\n    # Class-balanced sampler for train\n    train_sampler = build_class_balanced_sampler(train_keep, Config.TARGET_COLS)\n\n    tkw = dict(batch_size=args.batch_size, sampler=train_sampler, num_workers=args.num_workers, drop_last=True)\n    vkw = dict(batch_size=args.batch_size, shuffle=False,     num_workers=args.num_workers, drop_last=False)\n    if dev == \"cuda\":\n        tkw[\"pin_memory\"] = True; vkw[\"pin_memory\"] = True\n    train_loader = DataLoader(train_ds, **tkw)\n    val_loader   = DataLoader(val_ds, **vkw)\n\n    model = build_efficientnet_b0(len(Config.TARGET_COLS)).to(dev)\n    print(f\"Model params: {count_params(model):,}\")\n\n    # Class imbalance weights (per label)\n    posw = []\n    for c in Config.TARGET_COLS:\n        pos = train_keep[c].sum()\n        neg = len(train_keep) - pos\n        w = (neg / max(1.0, pos)) if pos > 0 else 1.0\n        w = float(np.clip(w, 1.0, 50.0))\n        posw.append(w)\n    posw = torch.tensor(posw, device=dev)\n\n    criterion = BCEWithLogitsFocal(pos_weight=posw, gamma=2.0)\n    opt = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)\n    sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=args.epochs)\n\n    use_amp = (dev == \"cuda\") and Config.USE_AMP\n    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\n    present_idx = Config.TARGET_COLS.index(\"Aneurysm Present\")\n    loc_idx = [i for i,_c in enumerate(Config.TARGET_COLS) if i != present_idx]\n\n    best_auc = -1.0\n    best_ckpt = args.out\n    patience_left = Config.EARLY_STOP_PATIENCE if Config.EARLY_STOP_PATIENCE is not None else 1_000_000\n\n    for epoch in range(args.epochs):\n        # ----------------- Train ----------------- #\n        model.train()\n        run_loss = 0.0\n        t0 = time.time()\n        for b, (x, y, _) in enumerate(train_loader, 1):\n            x, y = x.to(dev, non_blocking=True), y.to(dev, non_blocking=True)\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                out = model(x)\n                loss = criterion(out, y)\n\n                # Consistency penalty (locations shouldn't exceed \"Present\")\n                if Config.CONSISTENCY_W > 0:\n                    probs = torch.sigmoid(out)\n                    present = probs[:, present_idx:present_idx+1]  # [B,1]\n                    loc_probs = probs[:, loc_idx]                  # [B,L]\n                    consistency = torch.clamp(loc_probs - present, min=0.0).pow(2).mean()\n                    loss = loss + Config.CONSISTENCY_W * consistency\n\n            scaler.scale(loss).backward()\n            scaler.step(opt); scaler.update()\n\n            run_loss += loss.item()\n\n            if b % Config.LOG_EVERY_N == 0 or b == 1:\n                print(f\"[E{epoch+1} {b}/{len(train_loader)}] loss={run_loss/b:.4f} lr={sch.get_last_lr()[0]:.2e}\")\n\n        train_loss = run_loss / max(1, len(train_loader))\n\n        # ----------------- Val ----------------- #\n        model.eval()\n        val_loss = 0.0\n        preds_all, targs_all, uids_all = [], [], []\n        with torch.no_grad():\n            for x, y, uids in val_loader:\n                x, y = x.to(dev, non_blocking=True), y.to(dev, non_blocking=True)\n                with torch.cuda.amp.autocast(enabled=use_amp):\n                    out = model(x); loss = criterion(out, y)\n                val_loss += loss.item()\n                preds_all.append(torch.sigmoid(out).cpu().numpy())\n                targs_all.append(y.cpu().numpy())\n                uids_all.extend(list(uids))\n\n        val_loss /= max(1, len(val_loader))\n        P = np.vstack(preds_all) if preds_all else np.zeros((0, len(Config.TARGET_COLS)))\n        T = np.vstack(targs_all) if targs_all else np.zeros((0, len(Config.TARGET_COLS)))\n\n        col_aucs, macro_auc = compute_auc_per_column(T, P, Config.TARGET_COLS)\n        col_aps , macro_ap  = compute_ap_per_column(T, P, Config.TARGET_COLS)\n        micro_ap = compute_micro_ap(T, P)\n\n        dt = time.time() - t0\n        print(f\"Epoch {epoch+1}/{args.epochs} | {dt:.1f}s  \"\n              f\"train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n              f\"macro_auc={macro_auc:.4f} macro_ap={macro_ap:.4f} micro_ap={micro_ap:.4f}\")\n\n        # Threshold tuning (val only)\n        thrs = tune_thresholds_best_f1(T, P)\n        conf_df = confusion_stats(T, P, thrs, Config.TARGET_COLS, top_k=6)\n        print(\"\\nVal confusion summary (top labels, tuned thresholds):\")\n        for _, r in conf_df.iterrows():\n            print(f\"  {r['label'][:28]:28s} thr={r['thr']:.2f}  TP={r['TP']:3d} FP={r['FP']:3d} \"\n                  f\"TN={r['TN']:3d} FN={r['FN']:3d}  P={r['precision']:.2f} R={r['recall']:.2f} F1={r['F1']:.2f}\")\n        print(\"\")\n\n        # Save val predictions CSV for inspection\n        out_csv = \"/kaggle/working/val_preds.csv\"\n        val_out = pd.DataFrame({\"SeriesInstanceUID\": uids_all})\n        for i, c in enumerate(Config.TARGET_COLS):\n            val_out[c + \"_prob\"] = P[:, i]\n            val_out[c + \"_true\"] = T[:, i]\n            val_out[c + \"_thr\"]  = thrs[i]\n        val_out.to_csv(out_csv, index=False)\n        print(f\"Saved validation predictions to {out_csv} (shape={val_out.shape})\")\n\n        # Save best checkpoint (stores thresholds too)\n        if macro_auc > best_auc:\n            best_auc = macro_auc\n            torch.save({\n                \"epoch\": epoch+1,\n                \"model_state_dict\": model.state_dict(),\n                \"optimizer_state_dict\": opt.state_dict(),\n                \"scheduler_state_dict\": sch.state_dict(),\n                \"auc_macro\": macro_auc,\n                \"target_cols\": Config.TARGET_COLS,\n                \"thresholds\": thrs,  # tuned on val\n                \"config\": {\n                    \"img_size\": args.img_size,\n                    \"batch_size\": args.batch_size,\n                    \"lr\": args.lr,\n                    \"seed\": args.seed,\n                    \"ct_windows\": Config.CT_WINDOWS,\n                    \"highlight\": {\n                        \"enable\": Config.HIGHLIGHT_ENABLE,\n                        \"pct\": Config.HIGHLIGHT_TOP_PCT,\n                        \"gamma\": Config.HIGHLIGHT_GAMMA,\n                        \"blend\": Config.HIGHLIGHT_BLEND,\n                        \"ct_skip_bone\": Config.CT_HIGHLIGHT_SKIP_BONE,\n                        \"bone_hu\": Config.CT_BONE_MASK_HU,\n                        \"morph_k\": Config.CT_BONE_MORPH_K,\n                    },\n                    \"consistency_w\": Config.CONSISTENCY_W,\n                }\n            }, best_ckpt)\n            print(f\"Saved new best: {best_ckpt} (macro_auc={macro_auc:.4f})\")\n            patience_left = Config.EARLY_STOP_PATIENCE if Config.EARLY_STOP_PATIENCE is not None else patience_left\n        else:\n            if Config.EARLY_STOP_PATIENCE is not None:\n                patience_left -= 1\n                print(f\"No AUC improvement. Early-stop patience left: {patience_left}\")\n                if patience_left <= 0:\n                    print(\"Early stopping.\")\n                    break\n\n        sch.step()\n\n    print(f\"Training complete. Best macro AUC: {best_auc:.4f} | ckpt={best_ckpt}\")\n    return best_ckpt\n\n# =============================================================================\n# JUPYTER HELPER\n# =============================================================================\ndef train_model_jupyter(data_dir=None, img_size=None, batch_size=None, epochs=None,\n                        lr=None, num_workers=None, seed=None, out=None, benchmark_mode=False):\n    class A: pass\n    a = A()\n    a.data_dir = data_dir or Config.DATA_DIR\n    a.img_size = img_size or Config.IMG_SIZE\n    a.batch_size = batch_size or Config.BATCH_SIZE\n    a.epochs = epochs or Config.EPOCHS\n    a.lr = lr or Config.LR\n    a.num_workers = num_workers if num_workers is not None else Config.NUM_WORKERS\n    a.seed = seed or Config.SEED\n    a.out = out or \"/kaggle/working/best.pt\"\n    a.benchmark_mode = benchmark_mode\n    return train_model(a)\n\nprint(\"Loaded script (normalized, focal, sampler, morphology). Example:\")\nprint('train_model_jupyter(data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", img_size=288, batch_size=2, epochs=2, num_workers=0, benchmark_mode=True)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T21:26:55.661179Z","iopub.execute_input":"2025-09-15T21:26:55.661442Z","iopub.status.idle":"2025-09-15T21:27:14.010814Z","shell.execute_reply.started":"2025-09-15T21:26:55.661420Z","shell.execute_reply":"2025-09-15T21:27:14.009936Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Loaded script (normalized, focal, sampler, morphology). Example:\ntrain_model_jupyter(data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", img_size=288, batch_size=2, epochs=2, num_workers=0, benchmark_mode=True)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n# --- Recommended baseline run (smoke) ---\nConfig.SMOKE_TRAIN_LIMIT = 600\nConfig.SMOKE_VAL_LIMIT   = 200\nConfig.IMG_SIZE          = 288\nConfig.USE_CACHE         = True\n\n# Bone-aware highlight settings you intended\nConfig.CT_BONE_MASK_HU   = 300\nConfig.CT_BONE_MORPH_K   = 3\nConfig.HIGHLIGHT_ENABLE  = True\nConfig.CT_HIGHLIGHT_SKIP_BONE = True\n\n# Optional: ease off consistency if you want pure baseline\nConfig.CONSISTENCY_W = 0.2  # set to 0.0 to disable\n\ntrain_model_jupyter(\n    data_dir=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n    img_size=Config.IMG_SIZE,\n    batch_size=2,\n    epochs=2,\n    num_workers=0,\n    benchmark_mode=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T21:27:24.376887Z","iopub.execute_input":"2025-09-15T21:27:24.377153Z","iopub.status.idle":"2025-09-15T22:37:43.282842Z","shell.execute_reply.started":"2025-09-15T21:27:24.377133Z","shell.execute_reply":"2025-09-15T22:37:43.275669Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"== RSNA IA Detection: TRAIN ==\nDevice: cuda | AMP: True\nTotal rows in CSV: 4,348\nScanning decodability (quick test on first slice of each series)...\nDecodable series (quick test): 600/600 kept\nDecodable series (quick test): 200/200 kept\nTrain: 600 | Val: 200\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 146MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model params: 4,025,482\n[E1 1/300] loss=0.7246 lr=2.00e-04\n[E1 50/300] loss=0.6062 lr=2.00e-04\n[E1 100/300] loss=0.6490 lr=2.00e-04\n[E1 150/300] loss=0.6121 lr=2.00e-04\n[E1 200/300] loss=0.5900 lr=2.00e-04\n[E1 250/300] loss=0.5596 lr=2.00e-04\n[E1 300/300] loss=0.5391 lr=2.00e-04\nEpoch 1/2 | 2317.8s  train_loss=0.5391  val_loss=0.3466  macro_auc=0.5837 macro_ap=0.1102 micro_ap=0.1348\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.45  TP= 95 FP= 91 TN= 11 FN=  3  P=0.51 R=0.97 F1=0.67\n  Left Middle Cerebral Artery  thr=0.54  TP=  9 FP= 74 TN=116 FN=  1  P=0.11 R=0.90 F1=0.19\n  Right Middle Cerebral Artery thr=0.60  TP=  5 FP= 10 TN=169 FN= 16  P=0.33 R=0.24 F1=0.28\n  Basilar Tip                  thr=0.50  TP=  3 FP= 83 TN=113 FN=  1  P=0.03 R=0.75 F1=0.07\n  Anterior Communicating Arter thr=0.42  TP= 14 FP=180 TN=  6 FN=  0  P=0.07 R=1.00 F1=0.13\n  Left Infraclinoid Internal C thr=0.58  TP=  1 FP= 96 TN=103 FN=  0  P=0.01 R=1.00 F1=0.02\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 43))\nSaved new best: /kaggle/working/best.pt (macro_auc=0.5837)\n[E2 1/300] loss=0.3947 lr=1.00e-04\n[E2 50/300] loss=0.4182 lr=1.00e-04\n[E2 100/300] loss=0.4114 lr=1.00e-04\n[E2 150/300] loss=0.4072 lr=1.00e-04\n[E2 200/300] loss=0.4039 lr=1.00e-04\n[E2 250/300] loss=0.4017 lr=1.00e-04\n[E2 300/300] loss=0.3998 lr=1.00e-04\nEpoch 2/2 | 351.0s  train_loss=0.3998  val_loss=0.3467  macro_auc=0.5110 macro_ap=0.1024 micro_ap=0.1197\n\nVal confusion summary (top labels, tuned thresholds):\n  Aneurysm Present             thr=0.41  TP= 97 FP= 99 TN=  3 FN=  1  P=0.49 R=0.99 F1=0.66\n  Left Middle Cerebral Artery  thr=0.60  TP=  4 FP= 24 TN=166 FN=  6  P=0.14 R=0.40 F1=0.21\n  Right Middle Cerebral Artery thr=0.58  TP=  7 FP= 23 TN=156 FN= 14  P=0.23 R=0.33 F1=0.27\n  Basilar Tip                  thr=0.60  TP=  1 FP=  8 TN=188 FN=  3  P=0.11 R=0.25 F1=0.15\n  Anterior Communicating Arter thr=0.47  TP= 11 FP=127 TN= 59 FN=  3  P=0.08 R=0.79 F1=0.14\n  Left Infraclinoid Internal C thr=0.54  TP=  1 FP=141 TN= 58 FN=  0  P=0.01 R=1.00 F1=0.01\n\nSaved validation predictions to /kaggle/working/val_preds.csv (shape=(200, 43))\nTraining complete. Best macro AUC: 0.5837 | ckpt=/kaggle/working/best.pt\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/best.pt'"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# **TEST5**","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nRSNA Intracranial Aneurysm Detection - Modality-Split + 2.5D MIL + ASL + Temp Scaling\n\nWhat this script does:\n- Splits the dataset by modality and trains two separate models: CTA/CT and MR/MRA.\n- Default representation: 2.5D Attention-MIL (top-K axial slices per study ‚Üí features ‚Üí attention pooling).\n- Optional: 3D crop around Circle of Willis (enable via Config.MODE_3D = True).\n- CTA pipeline: multi-window HU, bone mask + morphology, Frangi vesselness (with fallback), vessel-weighted highlight.\n- MR pipeline: per-slice percentile normalization; tri-planar MIPs NOT used (we use axial slices for MIL).\n- Loss: Asymmetric Loss (ASL) by default; BCE+Focal available.\n- Hierarchical heads: Present + 13 Locations. Locations are gated at inference by Present^alpha. Consistency penalty in training.\n- Temperature scaling (per label) on validation logits; thresholds then chosen:\n    - Present: smallest t with precision >= TARGET_PRECISION_PRESENT (default 0.80)\n    - Locations: per-label F1-tuned (you can change to target precision too)\n- Metrics: per-label AUC/AP, macro AUC/AP, micro AP; confusion at chosen thresholds.\n- Outputs (per modality): /kaggle/working/{mod}_val_preds.csv and {mod}_best.pt\n\nQuick start (same dataset you used):\n  - Just run the cell. To try 3D later: set Config.MODE_3D = True and keep batch_size small (e.g., 1).\n\"\"\"\n\nimport os, time, random, warnings, hashlib, math\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\n\n# Optional vesselness (Frangi); we ship a safe fallback if skimage is missing\ntry:\n    from skimage.filters import frangi as frangi2d\n    _HAS_FRANGI = True\nexcept Exception:\n    _HAS_FRANGI = False\n\nfrom scipy import ndimage as ndi\n\n# VOI LUT import (compat across pydicom versions)\ntry:\n    from pydicom.pixel_data_handlers import apply_voi_lut\nexcept Exception:\n    try:\n        from pydicom.pixel_data_handlers.util import apply_voi_lut\n    except Exception:\n        def apply_voi_lut(x, ds): return x\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torchvision\nfrom torchvision.models.video import r3d_18\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nwarnings.filterwarnings(\"ignore\")\n\n# =============================================================================\n# CONFIG\n# =============================================================================\nclass Config:\n    # Kaggle dataset\n    DATA_DIR   = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\n    SERIES_DIR = f\"{DATA_DIR}/series\"\n    TRAIN_CSV  = f\"{DATA_DIR}/train.csv\"\n\n    # Train defaults (2.5D MIL)\n    IMG_SIZE            = 320      # 288‚Äì384 is fine for MIL\n    BATCH_SIZE          = 2\n    EPOCHS              = 8\n    LR                  = 3e-4\n    NUM_WORKERS         = 0\n    SEED                = 42\n    USE_AMP             = True\n\n    # 3D mode (optional). If True, we switch the model and dataset to 3D crops.\n    MODE_3D             = False\n    VOL_CROP_SIZE       = 96       # cubic crop edge (e.g., 96 or 112)\n    VOL_ISO_SPACING_MM  = 1.2\n\n    # MIL slice selection\n    K_SLICES            = 16       # top-K axial slices per study\n    VESSELNESS_BLEND    = 0.35     # CTA only: boost channels by (1 + blend*vesselness)\n\n    # Loss\n    LOSS_NAME           = \"ASL\"    # \"ASL\" or \"FOCAL_BCE\"\n    FOCAL_GAMMA         = 2.0      # if using FOCAL_BCE\n\n    # Logs / cache\n    LOG_EVERY_N         = 50\n    USE_CACHE           = True\n    CACHE_DIR           = \"/kaggle/working/mip_cache\"\n    CACHE_VERSION       = \"v8.0\"\n\n    # CT windows (L, W)\n    CT_WINDOWS          = [(40, 80), (200, 500), (600, 2800)]  # brain, soft/vessel, bone\n\n    # Bone-aware highlight (CTA)\n    HIGHLIGHT_ENABLE     = True\n    HIGHLIGHT_TOP_PCT    = 1.0\n    HIGHLIGHT_GAMMA      = 0.7\n    HIGHLIGHT_BLEND      = 0.6\n    CT_HIGHLIGHT_SKIP_BONE = True\n    CT_BONE_MASK_HU      = 300\n    CT_BONE_MORPH_K      = 3\n\n    # Temperature scaling & thresholds\n    DO_TEMP_SCALING      = True\n    TARGET_PRECISION_PRESENT = 0.80\n    GATE_ALPHA           = 1.0     # locations *= present_prob ** alpha\n\n    # Consistency penalty\n    CONSISTENCY_W        = 0.2\n\n    # Small smoke subset for quick tests (set both None to use ALL)\n    SMOKE_TRAIN_LIMIT    = None\n    SMOKE_VAL_LIMIT      = None\n\n    # Labels (13 sites + global)\n    TARGET_COLS = [\n        \"Left Infraclinoid Internal Carotid Artery\",\n        \"Right Infraclinoid Internal Carotid Artery\",\n        \"Left Supraclinoid Internal Carotid Artery\",\n        \"Right Supraclinoid Internal Carotid Artery\",\n        \"Left Middle Cerebral Artery\",\n        \"Right Middle Cerebral Artery\",\n        \"Anterior Communicating Artery\",\n        \"Left Anterior Cerebral Artery\",\n        \"Right Anterior Cerebral Artery\",\n        \"Left Posterior Communicating Artery\",\n        \"Right Posterior Communicating Artery\",\n        \"Basilar Tip\",\n        \"Other Posterior Circulation\",\n        \"Aneurysm Present\",\n    ]\n\n# ImageNet normalization (works fine even though channels ‚â† RGB semantics)\nIMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\nIMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n\ndef set_seed(seed=42, benchmark_mode=False):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = not benchmark_mode\n    torch.backends.cudnn.benchmark     = benchmark_mode\n\ndef device() -> str:\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef count_params(m: nn.Module) -> int:\n    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n\n# =============================================================================\n# DICOM I/O & NORMALIZATION\n# =============================================================================\ndef iter_dicom_files(series_path: str) -> List[str]:\n    sp = Path(series_path)\n    dcm_files = list(sp.glob(\"*.dcm\"))\n    if not dcm_files:\n        dcm_files = [f for f in sp.iterdir() if f.is_file() and not f.suffix]\n    if not dcm_files:\n        return []\n    infos = []\n    for f in dcm_files:\n        try:\n            ds = pydicom.dcmread(str(f), stop_before_pixels=True, force=True)\n            ins = getattr(ds, \"InstanceNumber\", 0)\n        except Exception:\n            ins = 0\n        infos.append((ins, str(f)))\n    infos.sort(key=lambda x: (x[0], x[1]))\n    return [p for _, p in infos]\n\ndef read_pixel(ds) -> np.ndarray:\n    arr = ds.pixel_array\n    try:\n        if hasattr(ds, 'VOILUTSequence') or hasattr(ds, 'WindowCenter'):\n            arr = apply_voi_lut(arr, ds)\n    except Exception:\n        pass\n    if hasattr(ds, \"RescaleSlope\") and hasattr(ds, \"RescaleIntercept\"):\n        arr = arr.astype(np.float32) * float(ds.RescaleSlope) + float(ds.RescaleIntercept)\n    else:\n        arr = arr.astype(np.float32)\n    return arr\n\ndef read_volume_hu(series_path: str) -> Tuple[np.ndarray, Tuple[float,float,float]]:\n    \"\"\"Returns volume in HU [Z,H,W] and voxel spacing (z,y,x).\"\"\"\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n    slices, zs = [], []\n    spacing_yx = (1.0, 1.0)\n    for fp in files:\n        try:\n            ds = pydicom.dcmread(fp, force=True)\n            arr = read_pixel(ds)\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            if hasattr(ds, \"PixelSpacing\"):\n                spacing_yx = (float(ds.PixelSpacing[0]), float(ds.PixelSpacing[1]))\n            st = float(getattr(ds, \"SliceThickness\", 1.0))\n            zs.append(st)\n            slices.append(arr.astype(np.float32))\n        except Exception:\n            continue\n    if not slices: raise RuntimeError(\"No decodable slices\")\n    vol = np.stack(slices, axis=0)   # [Z,H,W]\n    spacing = (np.median(zs) if zs else 1.0, spacing_yx[0], spacing_yx[1])\n    return vol, spacing\n\ndef _ensure_gray2d(img: np.ndarray) -> np.ndarray:\n    if img.ndim == 3:\n        if img.shape[-1] == 3:\n            img = np.mean(img, axis=-1)\n        else:\n            img = img.max(axis=-1)\n    return img.astype(np.float32)\n\ndef window_ct(img: np.ndarray, level=200, width=500) -> np.ndarray:\n    img = img.astype(np.float32)\n    lo, hi = float(level) - float(width)/2.0, float(level) + float(width)/2.0\n    img = np.clip(img, lo, hi)\n    denom = max(1e-6, (hi - lo))\n    img = (img - lo) / denom\n    return np.clip(img, 0, 1)\n\ndef normalize_mr(img: np.ndarray) -> np.ndarray:\n    img = img.astype(np.float32)\n    p1, p99 = np.percentile(img, [1, 99])\n    img = np.clip(img, p1, p99)\n    if p99 > p1:\n        img = (img - p1) / (p99 - p1)\n    return np.clip(img, 0, 1)\n\n# =============================================================================\n# CTA vesselness & highlight\n# =============================================================================\ndef vesselness_2d_soft(img01: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns vesselness in [0,1] for a 2D slice (CTA soft-tissue window).\n    Uses skimage.frangi if available; otherwise a safe LoG-based fallback.\n    \"\"\"\n    img01 = np.clip(img01.astype(np.float32), 0, 1)\n    if _HAS_FRANGI:\n        try:\n            v = frangi2d(img01, sigmas=(1, 2, 3), alpha=0.5, beta=0.5, gamma=15.0, black_ridges=False)\n            v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0)\n            v = (v - v.min()) / max(1e-6, (v.max() - v.min()))\n            return v.astype(np.float32)\n        except Exception:\n            pass\n    # Fallback: multi-sigma Laplacian-of-Gaussian magnitude (proxy)\n    sigmas = [1.0, 2.0, 3.0]\n    acc = np.zeros_like(img01, dtype=np.float32)\n    for s in sigmas:\n        g = ndi.gaussian_laplace(img01, sigma=s)\n        acc = np.maximum(acc, -g)  # vessels bright ‚Üí negative LoG\n    acc = (acc - acc.min()) / max(1e-6, (acc.max() - acc.min()))\n    return acc\n\ndef highlight_stretch(img01: np.ndarray, pct=None, gamma=None, blend=None) -> np.ndarray:\n    pct   = Config.HIGHLIGHT_TOP_PCT if pct is None else pct\n    gamma = Config.HIGHLIGHT_GAMMA   if gamma is None else gamma\n    blend = Config.HIGHLIGHT_BLEND   if blend is None else blend\n    img = img01.astype(np.float32); img = np.clip(img, 0.0, 1.0)\n    if pct <= 0.0: return img.copy()\n    thr = np.percentile(img, 100.0 - pct)\n    if not np.isfinite(thr) or thr >= 0.999: return img.copy()\n    out = img.copy(); mask = img >= thr\n    denom = max(1e-6, 1.0 - thr)\n    hi = (img - thr) / denom\n    if gamma > 0: hi = np.power(hi, 1.0 / gamma)\n    out[mask] = (1.0 - blend) * img[mask] + blend * hi[mask]\n    return np.clip(out, 0.0, 1.0)\n\ndef morph_clean(mask: np.ndarray, k: int) -> np.ndarray:\n    if k is None or k <= 0: return mask\n    kernel = np.ones((k,k), np.uint8)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  kernel)\n    return mask\n\n# =============================================================================\n# CACHE KEYS\n# =============================================================================\ndef _cache_path(series_path: str, out_size: int, key_extra: str) -> str:\n    os.makedirs(Config.CACHE_DIR, exist_ok=True)\n    key = f\"{Config.CACHE_VERSION}_{os.path.basename(series_path)}_{out_size}_{key_extra}_bone{Config.CT_BONE_MASK_HU}_m{Config.CT_BONE_MORPH_K}\"\n    h = hashlib.md5(key.encode()).hexdigest()[:16]\n    return os.path.join(Config.CACHE_DIR, f\"buf_{h}.npy\")\n\ndef _load_cache(path: str) -> Optional[np.ndarray]:\n    try:\n        if Config.USE_CACHE and os.path.exists(path):\n            arr = np.load(path, allow_pickle=False)\n            return arr\n    except Exception:\n        pass\n    return None\n\ndef _save_cache(arr: np.ndarray, path: str):\n    if not Config.USE_CACHE: return\n    try:\n        np.save(path, arr, allow_pickle=False)\n    except Exception:\n        pass\n\n# =============================================================================\n# 2.5D MIL DATASET (CTA & MR)\n# =============================================================================\ndef pick_topk_slices_cta(vol_hu: np.ndarray, k: int, out_size: int) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Returns [K,3,H,W] CTA slices (3 CT windows) and a vesselness map per slice [K,H,W] for optional weighting.\n    \"\"\"\n    Z, H, W = vol_hu.shape\n    # Build windowed axial stacks\n    wins = []\n    soft = None\n    for (L, Wd) in Config.CT_WINDOWS:\n        ch = []\n        for z in range(Z):\n            ch.append(window_ct(vol_hu[z], level=L, width=Wd))\n        ch = np.stack(ch, 0)  # [Z,H,W]\n        wins.append(ch)\n        if (L, Wd) == (200, 500): soft = ch\n    if soft is None: soft = wins[1]\n\n    # Vesselness per slice on soft-tissue window\n    vness = []\n    for z in range(Z):\n        v = vesselness_2d_soft(soft[z])\n        vness.append(v)\n    vness = np.stack(vness, 0)  # [Z,H,W]\n\n    # Score slices by mean vesselness near center (robust)\n    cy0, cx0, r = H//2, W//2, min(H, W)//4\n    yy, xx = np.ogrid[:H, :W]\n    circ = ((yy-cy0)**2 + (xx-cx0)**2) <= r*r\n    slice_scores = (vness * circ).sum((1,2)) / max(1, circ.sum())\n\n    idx = np.argsort(-slice_scores)[:k]\n    idx = np.sort(idx)\n    # assemble channels, resize\n    imgs = []\n    vnks = []\n    for z in idx:\n        chans = []\n        for ch in wins:\n            im = cv2.resize(ch[z], (out_size, out_size), interpolation=cv2.INTER_AREA)\n            chans.append(im.astype(np.float32))\n        v = cv2.resize(vness[z], (out_size, out_size), interpolation=cv2.INTER_AREA).astype(np.float32)\n        # Optional vesselness-weighted boost of each channel\n        if Config.VESSELNESS_BLEND > 0:\n            boost = (1.0 + Config.VESSELNESS_BLEND * v)\n            chans = [np.clip(c * boost, 0, 1) for c in chans]\n\n        # Optional highlight, skip bone areas\n        if Config.HIGHLIGHT_ENABLE:\n            # Bone mask from bone window: threshold BEFORE highlight\n            bone_mip = (cv2.resize(wins[2][z], (out_size, out_size), interpolation=cv2.INTER_AREA) > \n                        (Config.CT_BONE_MASK_HU - (-1024)) / (2800))  # rough; safe fallback\n            bone_mip = morph_clean(bone_mip.astype(np.uint8), Config.CT_BONE_MORPH_K).astype(bool)\n            for i in range(len(chans)):\n                hi = highlight_stretch(chans[i])\n                if Config.CT_HIGHLIGHT_SKIP_BONE:\n                    chans[i] = np.where(~bone_mip, hi, chans[i]).astype(np.float32)\n                else:\n                    chans[i] = hi\n\n        imgs.append(np.stack(chans, 0))   # [3,H,W]\n        vnks.append(v)\n    return np.stack(imgs, 0), np.stack(vnks, 0)  # [K,3,H,W], [K,H,W]\n\ndef pick_topk_slices_mr(vol: np.ndarray, k: int, out_size: int) -> np.ndarray:\n    \"\"\"\n    Returns [K,3,H,W] MR slices (replicate normalized slice into 3 channels).\n    We rank slices by their 99th percentile intensity (brighter vessels).\n    \"\"\"\n    Z, H, W = vol.shape\n    norm = []\n    scores = []\n    for z in range(Z):\n        im = normalize_mr(vol[z])\n        scores.append(np.percentile(im, 99))\n        im = cv2.resize(im, (out_size, out_size), interpolation=cv2.INTER_AREA)\n        # gentle highlight\n        if Config.HIGHLIGHT_ENABLE:\n            im = highlight_stretch(im)\n        norm.append(im.astype(np.float32))\n    idx = np.argsort(-np.array(scores))[:k]\n    idx = np.sort(idx)\n    out = []\n    for z in idx:\n        im = norm[z]\n        out.append(np.stack([im, im, im], 0))\n    return np.stack(out, 0)  # [K,3,H,W]\n\ndef build_2d_mil_buffers(series_path: str, is_ct: bool, out_size: int, k_slices: int):\n    cache = _cache_path(series_path, out_size, key_extra=f\"mil2d_ct{int(is_ct)}_k{k_slices}\")\n    cached = _load_cache(cache)\n    if cached is not None:\n        return cached\n    vol, _ = read_volume_hu(series_path) if is_ct else read_volume_hu(series_path)  # MR read same but not HU-scale\n    if is_ct:\n        imgs, _v = pick_topk_slices_cta(vol, k_slices, out_size)   # [K,3,H,W]\n        buf = imgs\n    else:\n        imgs = pick_topk_slices_mr(vol, k_slices, out_size)\n        buf = imgs\n    _save_cache(buf, cache)\n    return buf\n\n# =============================================================================\n# 3D CROP DATASET (optional)\n# =============================================================================\ndef resample_iso(vol: np.ndarray, spacing: Tuple[float,float,float], iso=1.2) -> np.ndarray:\n    \"\"\"Resample volume [Z,H,W] to isotropic spacing ~iso (mm).\"\"\"\n    z,y,x = spacing\n    zoom = (z/iso, y/iso, x/iso)\n    out = ndi.zoom(vol.astype(np.float32), zoom=zoom, order=1)\n    return out\n\ndef find_cof_bbox_cta(vol_hu_iso: np.ndarray, out_edge: int) -> Tuple[int,int,int]:\n    \"\"\"Very simple: use vesselness on soft window to get a coarse COM, then center a cube.\"\"\"\n    # Build soft window stack in [0,1]\n    Z,H,W = vol_hu_iso.shape\n    soft = np.stack([window_ct(vol_hu_iso[z], 200, 500) for z in range(Z)], 0)\n    # Vesselness per slice and combine\n    v3 = np.zeros_like(soft)\n    for z in range(Z):\n        v3[z] = vesselness_2d_soft(soft[z])\n    v3 = ndi.gaussian_filter(v3, sigma=1.0)\n    # Center of mass\n    m = v3 / max(1e-6, v3.sum())\n    zz, yy, xx = np.indices(v3.shape)\n    cz = int(np.clip((zz*m).sum(), 0, Z-1))\n    cy = int(np.clip((yy*m).sum(), 0, H-1))\n    cx = int(np.clip((xx*m).sum(), 0, W-1))\n    return cz, cy, cx\n\ndef crop_cube(vol: np.ndarray, center: Tuple[int,int,int], edge: int) -> np.ndarray:\n    cz, cy, cx = center\n    Z,H,W = vol.shape\n    r = edge//2\n    z0, z1 = max(0, cz-r), min(Z, cz+r)\n    y0, y1 = max(0, cy-r), min(H, cy+r)\n    x0, x1 = max(0, cx-r), min(W, cx+r)\n    cube = np.zeros((edge, edge, edge), np.float32)\n    cz0 = (edge - (z1 - z0))//2\n    cy0 = (edge - (y1 - y0))//2\n    cx0 = (edge - (x1 - x0))//2\n    cube[cz0:cz0+(z1-z0), cy0:cy0+(y1-y0), cx0:cx0+(x1-x0)] = vol[z0:z1, y0:y1, x0:x1]\n    return cube\n\n# =============================================================================\n# DATASET & SAMPLER\n# =============================================================================\ndef stratified_split(df: pd.DataFrame, global_col=\"Aneurysm Present\", seed=42, n_splits=5):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    tr_idx, va_idx = next(skf.split(df, df[global_col]))\n    return df.iloc[tr_idx].copy(), df.iloc[va_idx].copy()\n\ndef safe_series_path(series_dir: str, uid: str) -> str:\n    p = os.path.join(series_dir, str(uid))\n    if not os.path.exists(p): raise FileNotFoundError(p)\n    return p\n\ndef _detect_modality_from_header(series_path: str) -> Optional[str]:\n    files = iter_dicom_files(series_path)\n    if not files: return None\n    try:\n        ds = pydicom.dcmread(files[0], stop_before_pixels=True, force=True)\n        return str(getattr(ds, \"Modality\", \"\")).upper() or None\n    except Exception:\n        return None\n\ndef filter_decodable_df(df: pd.DataFrame, series_dir: str) -> pd.DataFrame:\n    uids = df[\"SeriesInstanceUID\"].astype(str).tolist()\n    keep_mask = []\n    for uid in uids:\n        sp = os.path.join(series_dir, uid)\n        ok = False\n        try:\n            files = iter_dicom_files(sp)\n            if files:\n                ds = pydicom.dcmread(files[0], force=True)\n                _ = ds.pixel_array\n                ok = True\n        except Exception:\n            ok = False\n        keep_mask.append(ok)\n    kept = df[keep_mask].reset_index(drop=True)\n    print(f\"Decodable series (quick test): {len(kept)}/{len(df)} kept\")\n    return kept\n\nclass MIL2DDataset(Dataset):\n    \"\"\"Returns one study as K slices [K,3,H,W], normalized for ImageNet, and label vector [C].\"\"\"\n    def __init__(self, df: pd.DataFrame, series_dir: str, out_size: int, k_slices: int, modality: str):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.out_size = out_size\n        self.k_slices = k_slices\n        self.modality = modality  # \"CT\" or \"MR\"\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss: raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n        if self.modality == \"CT\":\n            buf = build_2d_mil_buffers(sp, is_ct=True, out_size=self.out_size, k_slices=self.k_slices)  # [K,3,H,W]\n        else:\n            buf = build_2d_mil_buffers(sp, is_ct=False, out_size=self.out_size, k_slices=self.k_slices)\n        x = torch.from_numpy(buf).float()         # [K,3,H,W] in [0,1]\n        # ImageNet normalization per-slice\n        x = (x - IMAGENET_MEAN) / IMAGENET_STD\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\nclass Vol3DDataset(Dataset):\n    \"\"\"3D crop dataset: returns [3,D,H,W] by stacking same HU volume into 3 channels, normalized ~ImageNet.\"\"\"\n    def __init__(self, df: pd.DataFrame, series_dir: str, crop_edge: int, iso: float, modality: str):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.edge = crop_edge\n        self.iso = iso\n        self.modality = modality\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss: raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n        vol_hu, spacing = read_volume_hu(sp)\n        vol_iso = resample_iso(vol_hu, spacing, iso=self.iso)  # [Z,H,W]\n        if self.modality == \"CT\":\n            cz, cy, cx = find_cof_bbox_cta(vol_iso, self.edge)\n        else:\n            # For MR, use 99th-percentile intensity COM\n            v = np.clip(vol_iso, np.percentile(vol_iso, 1), np.percentile(vol_iso, 99))\n            v = (v - v.min()) / max(1e-6, (v.max() - v.min()))\n            m = v / max(1e-6, v.sum())\n            zz, yy, xx = np.indices(v.shape)\n            cz = int(np.clip((zz*m).sum(), 0, v.shape[0]-1))\n            cy = int(np.clip((yy*m).sum(), 0, v.shape[1]-1))\n            cx = int(np.clip((xx*m).sum(), 0, v.shape[2]-1))\n        cube = crop_cube(vol_iso, (cz,cy,cx), self.edge)  # [D,H,W]\n        # Window for CT; MR percentile normalize\n        if self.modality == \"CT\":\n            # Use soft-tissue window as base, but replicate into 3 channels\n            D,H,W = cube.shape\n            ch = np.stack([window_ct(cube[d], 200, 500) for d in range(D)], 0)\n        else:\n            v = np.clip(cube, np.percentile(cube, 1), np.percentile(cube, 99))\n            ch = (v - v.min()) / max(1e-6, (v.max()-v.min()))\n        # Stack to 3 channels for 3D Net\n        vol3 = np.stack([ch, ch, ch], 0)  # [3,D,H,W]\n        x = torch.from_numpy(vol3).float()\n        # crude \"ImageNet-like\" normalization channel-wise\n        for c in range(3):\n            x[c] = (x[c] - IMAGENET_MEAN[c]) / IMAGENET_STD[c]\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\ndef build_class_balanced_sampler(df: pd.DataFrame, target_cols: List[str]) -> WeightedRandomSampler:\n    pos = df[target_cols].sum(0).values\n    neg = len(df) - pos\n    cls_w = np.where(pos > 0, neg / np.maximum(1, pos), 1.0)\n    cls_w = np.clip(cls_w, 1.0, 50.0)\n    Y = df[target_cols].values.astype(np.float32)\n    w = 1.0 + (Y * cls_w).sum(1)\n    w = torch.as_tensor(w, dtype=torch.double)\n    return WeightedRandomSampler(weights=w, num_samples=len(df), replacement=True)\n\n# =============================================================================\n# MODELS\n# =============================================================================\ndef efficientnet_b2_features():\n    # torchvision EfficientNet-B2 returns features via model.features\n    m = torchvision.models.efficientnet_b2(weights=torchvision.models.EfficientNet_B2_Weights.IMAGENET1K_V1)\n    feat_dim = m.classifier[1].in_features\n    backbone = nn.Sequential(m.features, nn.AdaptiveAvgPool2d(1), nn.Flatten())  # -> [B, feat_dim]\n    return backbone, feat_dim\n\nclass AttnMIL(nn.Module):\n    \"\"\"Processes K slices with a 2D backbone and attention-pools to a study embedding.\"\"\"\n    def __init__(self, feat_dim, hidden=512):\n        super().__init__()\n        self.attn = nn.Sequential(\n            nn.Linear(feat_dim, hidden), nn.ReLU(inplace=True),\n            nn.Linear(hidden, 1)\n        )\n    def forward(self, F):  # F: [B,K,D]\n        A = self.attn(F).squeeze(-1)           # [B,K]\n        A = torch.softmax(A, dim=1)            # weights sum to 1\n        M = torch.sum(F * A.unsqueeze(-1), 1)  # [B,D]\n        return M, A\n\nclass HierHead(nn.Module):\n    \"\"\"Two heads: Present (1) + Locations (13).\"\"\"\n    def __init__(self, in_dim, n_locs=13):\n        super().__init__()\n        self.present = nn.Linear(in_dim, 1)\n        self.locs    = nn.Linear(in_dim, n_locs)\n    def forward(self, z):\n        return self.present(z).squeeze(-1), self.locs(z)\n\nclass MIL2DModel(nn.Module):\n    def __init__(self, n_out=14):\n        super().__init__()\n        self.backbone, feat_dim = efficientnet_b2_features()\n        self.mil = AttnMIL(feat_dim)\n        self.head = HierHead(feat_dim, n_locs=n_out-1)\n    def forward(self, x):  # x: [B,K,3,H,W]\n        B,K,C,H,W = x.shape\n        x = x.view(B*K, C, H, W)\n        f = self.backbone(x)                 # [B*K, D]\n        f = f.view(B, K, -1)                 # [B,K,D]\n        z, att = self.mil(f)                 # [B,D], [B,K]\n        present, locs = self.head(z)         # [B], [B,13]\n        logits = torch.cat([locs, present.unsqueeze(-1)], dim=1)  # [B,14] (locations first)\n        return logits, att\n\nclass Res3DModel(nn.Module):\n    def __init__(self, n_out=14):\n        super().__init__()\n        m = r3d_18(weights=None)\n        m.fc = nn.Linear(m.fc.in_features, 512)\n        self.backbone = m\n        self.head = HierHead(512, n_locs=n_out-1)\n    def forward(self, x):  # [B,3,D,H,W] ‚Üí r3d expects [B,3,T,H,W]\n        z = self.backbone(x)                 # [B,512]\n        present, locs = self.head(z)\n        logits = torch.cat([locs, present.unsqueeze(-1)], dim=1)\n        return logits, None\n\n# =============================================================================\n# LOSSES\n# =============================================================================\nclass AsymmetricLoss(nn.Module):\n    \"\"\"\n    Asymmetric Loss (ASL) for multi-label classification.\n    Params near standard: gamma_neg=4, gamma_pos=0, clip=0.05 (margin), disable_torch_grad_focal\n    \"\"\"\n    def __init__(self, gamma_pos=0, gamma_neg=4, clip=0.05, eps=1e-8):\n        super().__init__()\n        self.gp = gamma_pos\n        self.gn = gamma_neg\n        self.clip = clip\n        self.eps = eps\n\n    def forward(self, logits, targets):\n        x_sigmoid = torch.sigmoid(logits)\n        xs_pos = x_sigmoid\n        xs_neg = 1.0 - x_sigmoid\n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg + self.clip).clamp(max=1)\n        loss_pos = targets * torch.log(xs_pos.clamp(min=self.eps))\n        loss_neg = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps))\n        loss = loss_pos + loss_neg\n        # Asymmetric focusing\n        if self.gp > 0 or self.gn > 0:\n            pt = x_sigmoid * targets + (1 - x_sigmoid) * (1 - targets)\n            one_sided_gamma = self.gp * targets + self.gn * (1 - targets)\n            focal_weight = (1 - pt) ** one_sided_gamma\n            loss *= focal_weight\n        return -loss.mean()\n\nclass BCEWithLogitsFocal(nn.Module):\n    def __init__(self, pos_weight=None, gamma=2.0):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction=\"none\")\n        self.gamma = gamma\n    def forward(self, logits, targets):\n        bce = self.bce(logits, targets)\n        p = torch.sigmoid(logits)\n        pt = p*targets + (1-p)*(1-targets)\n        focal = (1.0 - pt).clamp_min(1e-6).pow(self.gamma)\n        return (focal * bce).mean()\n\n# =============================================================================\n# METRICS & THRESHOLDS\n# =============================================================================\ndef compute_auc_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_auc, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_auc[c] = np.nan\n                continue\n            auc = roc_auc_score(y_true[:, i], y_prob[:, i])\n            col_auc[c] = float(auc); macro_vals.append(float(auc))\n        except Exception:\n            col_auc[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_auc, macro\n\ndef compute_ap_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_ap, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_ap[c] = np.nan\n                continue\n            ap = average_precision_score(y_true[:, i], y_prob[:, i])\n            col_ap[c] = float(ap); macro_vals.append(float(ap))\n        except Exception:\n            col_ap[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_ap, macro\n\ndef compute_micro_ap(y_true: np.ndarray, y_prob: np.ndarray):\n    mask = (y_true.sum(0) > 0) & ((1 - y_true).sum(0) > 0)\n    if mask.sum() == 0: return np.nan\n    return average_precision_score(y_true[:, mask].ravel(), y_prob[:, mask].ravel())\n\ndef tune_thresholds_best_f1(y_true: np.ndarray, y_prob: np.ndarray) -> np.ndarray:\n    n_labels = y_true.shape[1]\n    thrs = np.zeros(n_labels, dtype=np.float32)\n    grid = np.linspace(0.0, 1.0, 1001)\n    for i in range(n_labels):\n        yi = y_true[:, i].astype(np.int32)\n        pi = y_prob[:, i]\n        if len(np.unique(yi)) < 2: thrs[i] = 0.5; continue\n        best_f1, best_t = -1.0, 0.5\n        for t in grid:\n            pred = (pi >= t).astype(np.int32)\n            tp = int((pred & (yi == 1)).sum()); fp = int((pred & (yi == 0)).sum())\n            fn = int(((1 - pred) & (yi == 1)).sum())\n            precision = tp / max(1, (tp + fp)); recall = tp / max(1, (tp + fn))\n            f1 = 2*precision*recall / max(1e-8, (precision + recall))\n            if f1 > best_f1: best_f1, best_t = f1, t\n        thrs[i] = best_t\n    return thrs\n\ndef smallest_t_for_precision(y_true: np.ndarray, y_prob: np.ndarray, target_p=0.8) -> float:\n    order = np.argsort(-y_prob)\n    y = y_true[order]; p = y_prob[order]\n    tp=0; fp=0\n    best_t = 1.0\n    for i in range(len(y)):\n        if y[i] == 1: tp += 1\n        else: fp += 1\n        prec = tp / max(1, tp+fp)\n        if prec >= target_p:\n            best_t = p[i]\n            break\n    return float(best_t)\n\ndef confusion_stats(y_true: np.ndarray, y_prob: np.ndarray, thrs: np.ndarray,\n                    cols: List[str], top_k: int = 6) -> pd.DataFrame:\n    rows = []\n    for i, c in enumerate(cols):\n        yi = y_true[:, i].astype(np.int32)\n        pi = (y_prob[:, i] >= thrs[i]).astype(np.int32)\n        tp = int((pi & (yi == 1)).sum())\n        fp = int((pi & (yi == 0)).sum())\n        tn = int(((1 - pi) & (yi == 0)).sum())\n        fn = int(((1 - pi) & (yi == 1)).sum())\n        prec = tp / max(1, (tp + fp))\n        rec  = tp / max(1, (tp + fn))\n        f1   = 2*prec*rec / max(1e-8, (prec + rec))\n        rows.append([c, thrs[i], tp, fp, tn, fn, prec, rec, f1])\n    df = pd.DataFrame(rows, columns=[\"label\",\"thr\",\"TP\",\"FP\",\"TN\",\"FN\",\"precision\",\"recall\",\"F1\"])\n    priority = [\"Aneurysm Present\", \"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\",\n                \"Basilar Tip\", \"Anterior Communicating Artery\"]\n    order = priority + [c for c in cols if c not in priority]\n    df = df.set_index(\"label\").loc[order].reset_index()\n    return df.head(top_k)\n\n# =============================================================================\n# TEMPERATURE SCALING (per label)\n# =============================================================================\n@torch.no_grad()\ndef collect_logits(model, loader, dev, mode_3d=False):\n    model.eval()\n    logits_list, targets_list, uids = [], [], []\n    for batch in loader:\n        x, y, idlist = batch\n        x = x.to(dev, non_blocking=True)\n        y = y.to(dev, non_blocking=True)\n        if mode_3d:\n            out, _ = model(x)              # [B,14]\n        else:\n            out, _ = model(x)              # [B,14]\n        logits_list.append(out.detach().cpu())\n        targets_list.append(y.detach().cpu())\n        uids.extend(list(idlist))\n    L = torch.cat(logits_list, 0).numpy()\n    T = torch.cat(targets_list, 0).numpy()\n    return L, T, uids\n\ndef fit_temperature_per_label(logits: np.ndarray, targets: np.ndarray, max_iter=200, lr=0.05) -> np.ndarray:\n    \"\"\"\n    Fit a temperature per column minimizing BCEWithLogits on val.\n    Returns temperatures shape [C], >= 1e-3.\n    \"\"\"\n    L = torch.tensor(logits, dtype=torch.float32)\n    Y = torch.tensor(targets, dtype=torch.float32)\n    C = L.shape[1]\n    temps = torch.ones(C, dtype=torch.float32, requires_grad=True)\n    optim_t = torch.optim.Adam([temps], lr=lr)\n    for _ in range(max_iter):\n        optim_t.zero_grad()\n        scaled = L / temps.clamp_min(1e-3)\n        loss = nn.BCEWithLogitsLoss()(scaled, Y)\n        loss.backward()\n        optim_t.step()\n    return temps.detach().clamp_min(1e-3).cpu().numpy()\n\n# =============================================================================\n# TRAIN / EVAL LOOP (one modality)\n# =============================================================================\ndef run_one_modality(modality_name: str, full_df: pd.DataFrame, series_dir: str, dev: str):\n    \"\"\"\n    modality_name: \"CT\"  -> use CTA/CT subset\n                   \"MR\"  -> use MR/MRA subset\n    \"\"\"\n    is_ct = (modality_name == \"CT\")\n    print(f\"\\n================= TRAINING MODALITY: {modality_name} =================\")\n\n    # Subset df by modality\n    df = full_df.copy()\n    # Prefer CSV Modality, else read header\n    mod = df.get(\"Modality\")\n    if mod is None:\n        df[\"Modality\"] = \"\"\n    if \"Modality\" in df.columns:\n        df[\"Modality\"] = df[\"Modality\"].fillna(\"\")\n    modes = []\n    for _, r in df.iterrows():\n        m = str(r.get(\"Modality\", \"\")).upper()\n        if not m:\n            try:\n                m = _detect_modality_from_header(os.path.join(series_dir, str(r[\"SeriesInstanceUID\"]))) or \"\"\n            except Exception:\n                m = \"\"\n        modes.append(m)\n    df[\"__mod\"] = modes\n    if is_ct:\n        sub = df[df[\"__mod\"].isin([\"CT\",\"CTA\"])].reset_index(drop=True)\n    else:\n        sub = df[df[\"__mod\"].isin([\"MR\",\"MRA\"])].reset_index(drop=True)\n\n    if len(sub) == 0:\n        print(f\"No {modality_name} studies found. Skipping.\")\n        return None\n\n    # Split stratified by \"Aneurysm Present\"\n    train_df, val_df = stratified_split(sub, seed=Config.SEED)\n\n    # Optional smoke limits\n    if Config.SMOKE_TRAIN_LIMIT is not None:\n        train_df = train_df.head(Config.SMOKE_TRAIN_LIMIT).copy()\n    if Config.SMOKE_VAL_LIMIT is not None:\n        val_df   = val_df.head(Config.SMOKE_VAL_LIMIT).copy()\n\n    # Filter decodable\n    print(\"Scanning decodability (quick test)...\")\n    train_keep = filter_decodable_df(train_df, series_dir)\n    val_keep   = filter_decodable_df(val_df, series_dir)\n    print(f\"{modality_name} Train: {len(train_keep)} | Val: {len(val_keep)}\")\n\n    # Build datasets/loaders\n    if Config.MODE_3D:\n        train_ds = Vol3DDataset(train_keep, series_dir, Config.VOL_CROP_SIZE, Config.VOL_ISO_SPACING_MM, modality_name)\n        val_ds   = Vol3DDataset(val_keep,   series_dir, Config.VOL_CROP_SIZE, Config.VOL_ISO_SPACING_MM, modality_name)\n    else:\n        train_ds = MIL2DDataset(train_keep, series_dir, Config.IMG_SIZE, Config.K_SLICES, modality_name)\n        val_ds   = MIL2DDataset(val_keep,   series_dir, Config.IMG_SIZE, Config.K_SLICES, modality_name)\n\n    train_sampler = build_class_balanced_sampler(train_keep, Config.TARGET_COLS)\n    tkw = dict(batch_size=Config.BATCH_SIZE, sampler=train_sampler, num_workers=Config.NUM_WORKERS, drop_last=True)\n    vkw = dict(batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=Config.NUM_WORKERS, drop_last=False)\n    if dev == \"cuda\":\n        tkw[\"pin_memory\"] = True; vkw[\"pin_memory\"] = True\n    train_loader = DataLoader(train_ds, **tkw)\n    val_loader   = DataLoader(val_ds, **vkw)\n\n    # Model\n    if Config.MODE_3D:\n        model = Res3DModel(n_out=len(Config.TARGET_COLS)).to(dev)\n    else:\n        model = MIL2DModel(n_out=len(Config.TARGET_COLS)).to(dev)\n    print(f\"Model params: {count_params(model):,}\")\n\n    # Loss\n    present_idx = Config.TARGET_COLS.index(\"Aneurysm Present\")\n    if Config.LOSS_NAME.upper() == \"ASL\":\n        criterion = AsymmetricLoss(gamma_pos=0, gamma_neg=4, clip=0.05)\n    else:\n        # compute pos_weight per label from training subset\n        posw = []\n        for c in Config.TARGET_COLS:\n            pos = train_keep[c].sum(); neg = len(train_keep) - pos\n            w = (neg / max(1.0, pos)) if pos > 0 else 1.0\n            posw.append(float(np.clip(w, 1.0, 50.0)))\n        criterion = BCEWithLogitsFocal(pos_weight=torch.tensor(posw, device=dev), gamma=Config.FOCAL_GAMMA)\n\n    opt = optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-4)\n    sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=Config.EPOCHS)\n    scaler = torch.cuda.amp.GradScaler(enabled=(dev==\"cuda\" and Config.USE_AMP))\n\n    best_macro_auc = -1.0\n    best_ckpt = f\"/kaggle/working/{modality_name.lower()}_best.pt\"\n\n    # ------------- Train -------------\n    for epoch in range(Config.EPOCHS):\n        model.train()\n        run_loss = 0.0; t0 = time.time()\n        for b, (x, y, _) in enumerate(train_loader, 1):\n            x, y = x.to(dev, non_blocking=True), y.to(dev, non_blocking=True)\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=(dev==\"cuda\" and Config.USE_AMP)):\n                logits, _att = model(x)                # [B,14]\n                loss = criterion(logits, y)\n                # consistency: locations <= present\n                if Config.CONSISTENCY_W > 0:\n                    probs = torch.sigmoid(logits)\n                    present = probs[:, present_idx:present_idx+1]\n                    locs   = probs[:, :present_idx]   # [B,13]\n                    consist = torch.clamp(locs - present, min=0.0).pow(2).mean()\n                    loss = loss + Config.CONSISTENCY_W * consist\n            scaler.scale(loss).backward()\n            scaler.step(opt); scaler.update()\n            run_loss += loss.item()\n            if b % Config.LOG_EVERY_N == 0 or b == 1:\n                print(f\"[{modality_name} E{epoch+1} {b}/{len(train_loader)}] loss={run_loss/b:.4f} lr={sch.get_last_lr()[0]:.2e}\")\n        sch.step()\n\n        # ------------- Val -------------\n        model.eval()\n        val_loss = 0.0\n        logits_all, probs_all, targs_all, uids_all = [], [], [], []\n        with torch.no_grad():\n            for x, y, uids in val_loader:\n                x, y = x.to(dev, non_blocking=True), y.to(dev, non_blocking=True)\n                with torch.cuda.amp.autocast(enabled=(dev==\"cuda\" and Config.USE_AMP)):\n                    out, _att = model(x)\n                    ls = nn.BCEWithLogitsLoss(reduction=\"mean\")(out, y)\n                val_loss += ls.item()\n                logits_all.append(out.detach().cpu().numpy())\n                probs_all.append(torch.sigmoid(out).detach().cpu().numpy())\n                targs_all.append(y.detach().cpu().numpy())\n                uids_all.extend(list(uids))\n\n        L = np.vstack(logits_all)\n        P = np.vstack(probs_all)\n        T = np.vstack(targs_all)\n        col_aucs, macro_auc = compute_auc_per_column(T, P, Config.TARGET_COLS)\n        col_aps , macro_ap  = compute_ap_per_column(T, P, Config.TARGET_COLS)\n        micro_ap = compute_micro_ap(T, P)\n        dt = time.time() - t0\n        print(f\"{modality_name} Epoch {epoch+1}/{Config.EPOCHS} | {dt:.1f}s  val_loss={val_loss/max(1,len(val_loader)):.4f}  \"\n              f\"macro_auc={macro_auc:.4f} macro_ap={macro_ap:.4f} micro_ap={micro_ap:.4f}\")\n\n        # Save best\n        if macro_auc > best_macro_auc:\n            best_macro_auc = macro_auc\n            torch.save({\n                \"epoch\": epoch+1,\n                \"model_state_dict\": model.state_dict(),\n                \"auc_macro\": macro_auc,\n                \"target_cols\": Config.TARGET_COLS,\n                \"config\": vars(Config),\n            }, best_ckpt)\n            print(f\"Saved new best for {modality_name}: {best_ckpt} (macro_auc={macro_auc:.4f})\")\n\n    # -------- Post-hoc calibration (temperature scaling) on final val --------\n    # Re-run val once to collect logits/targets cleanly\n    L, T, uids_all = collect_logits(model, val_loader, dev, mode_3d=Config.MODE_3D)\n    if Config.DO_TEMP_SCALING:\n        temps = fit_temperature_per_label(L, T, max_iter=200, lr=0.05)  # [C]\n    else:\n        temps = np.ones(L.shape[1], dtype=np.float32)\n    Ls = L / np.clip(temps, 1e-3, None)\n    P_cal = 1.0 / (1.0 + np.exp(-Ls))\n\n    # Gating: locations *= present^alpha\n    present_idx = Config.TARGET_COLS.index(\"Aneurysm Present\")\n    loc_idx = [i for i in range(len(Config.TARGET_COLS)) if i != present_idx]\n    if Config.GATE_ALPHA > 0:\n        pr = np.clip(P_cal[:, present_idx:present_idx+1], 0, 1) ** Config.GATE_ALPHA\n        P_cal[:, loc_idx] = P_cal[:, loc_idx] * pr\n\n    # Thresholds:\n    thrs = np.zeros(len(Config.TARGET_COLS), dtype=np.float32)\n    # 1) Present: smallest t with precision >= target\n    thrs[present_idx] = smallest_t_for_precision(T[:, present_idx], P_cal[:, present_idx], target_p=Config.TARGET_PRECISION_PRESENT)\n    # 2) Locations: F1-tuned (you can switch to target precision similarly)\n    thrs[loc_idx] = tune_thresholds_best_f1(T[:, loc_idx], P_cal[:, loc_idx])\n\n    # Confusion summary\n    conf_df = confusion_stats(T, P_cal, thrs, Config.TARGET_COLS, top_k=6)\n    print(f\"\\n{modality_name} (Calibrated) confusion summary @ thresholds:\")\n    for _, r in conf_df.iterrows():\n        print(f\"  {r['label'][:28]:28s} thr={r['thr']:.2f}  TP={r['TP']:3d} FP={r['FP']:3d} \"\n              f\"TN={r['TN']:3d} FN={r['FN']:3d}  P={r['precision']:.2f} R={r['recall']:.2f} F1={r['F1']:.2f}\")\n\n    # Metrics (calibrated)\n    col_aucs, macro_auc = compute_auc_per_column(T, P_cal, Config.TARGET_COLS)\n    col_aps , macro_ap  = compute_ap_per_column(T, P_cal, Config.TARGET_COLS)\n    micro_ap = compute_micro_ap(T, P_cal)\n    print(f\"\\n{modality_name} (Calibrated) macro_auc={macro_auc:.4f} macro_ap={macro_ap:.4f} micro_ap={micro_ap:.4f}\")\n\n    # Save per-modality val preds CSV\n    out_csv = f\"/kaggle/working/{modality_name.lower()}_val_preds.csv\"\n    df_out = pd.DataFrame({\"SeriesInstanceUID\": uids_all})\n    for i, c in enumerate(Config.TARGET_COLS):\n        df_out[c + \"_prob\"] = P_cal[:, i]\n        df_out[c + \"_true\"] = T[:, i]\n        df_out[c + \"_thr\"]  = thrs[i]\n    df_out.to_csv(out_csv, index=False)\n    print(f\"Saved {modality_name} validation predictions to {out_csv} (shape={df_out.shape})\")\n\n    # Save final checkpoint with temps + thresholds\n    torch.save({\n        \"epoch\": Config.EPOCHS,\n        \"model_state_dict\": model.state_dict(),\n        \"target_cols\": Config.TARGET_COLS,\n        \"temps\": temps.astype(np.float32),\n        \"thresholds\": thrs.astype(np.float32),\n        \"config\": vars(Config),\n        \"modality\": modality_name,\n    }, f\"/kaggle/working/{modality_name.lower()}_best.pt\")\n    print(f\"Saved {modality_name} calibrated model with temps+thresholds: /kaggle/working/{modality_name.lower()}_best.pt\")\n\n    return True\n\n# =============================================================================\n# MAIN\n# =============================================================================\ndef main():\n    print(\"== RSNA IA Detection: Modality-Split MIL (ASL, TempScaling, Gated Heads) ==\")\n    set_seed(Config.SEED, benchmark_mode=True if device()==\"cuda\" else False)\n    dev = device()\n    print(f\"Device: {dev} | AMP: {Config.USE_AMP} | 3D Mode: {Config.MODE_3D}\")\n\n    csv_path = os.path.join(Config.DATA_DIR, \"train.csv\")\n    if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n    df = pd.read_csv(csv_path)\n    series_dir = os.path.join(Config.DATA_DIR, \"series\")\n    print(f\"Rows in CSV: {len(df):,}\")\n\n    # Train per-modality\n    run_one_modality(\"CT\", df, series_dir, dev)\n    run_one_modality(\"MR\", df, series_dir, dev)\n    print(\"All done.\")\n\n# Jupyter helper\ndef train_model_jupyter(**kwargs):\n    # Allow quick overrides\n    for k,v in kwargs.items():\n        if hasattr(Config, k):\n            setattr(Config, k, v)\n    main()\n\nif __name__ == \"__main__\":\n    main()\n\nprint(\"Loaded script. Example:\")\nprint('train_model_jupyter(DATA_DIR=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", IMG_SIZE=320, K_SLICES=16, EPOCHS=8)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T22:50:13.050411Z","iopub.execute_input":"2025-09-22T22:50:13.050993Z","execution_failed":"2025-09-23T03:23:47.170Z"}},"outputs":[{"name":"stdout","text":"== RSNA IA Detection: Modality-Split MIL (ASL, TempScaling, Gated Heads) ==\nDevice: cuda | AMP: True | 3D Mode: False\nRows in CSV: 4,348\n\n================= TRAINING MODALITY: CT =================\nScanning decodability (quick test)...\nDecodable series (quick test): 1446/1446 kept\nDecodable series (quick test): 362/362 kept\nCT Train: 1446 | Val: 362\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35.2M/35.2M [00:00<00:00, 66.3MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Model params: 8,442,641\n[CT E1 1/723] loss=0.1303 lr=3.00e-04\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **TEST2**","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n\"\"\"\nRSNA Intracranial Aneurysm Detection\nModality-Split (CT vs MR) + 2.5D MIL + Asymmetric Loss + Temp Scaling\n(with Kaggle-friendly speed-ups)\n\nWhat this script does\n- Trains two separate models: CT/CTA and MR/MRA.\n- 2.5D Attention-MIL: top-K axial slices per study ‚Üí 2D backbone ‚Üí attention pooling.\n- CTA: multi-window HU, HU bone mask + morphology, optional vesselness (Frangi) ranking/boost.\n- MR: percentile normalization; axial slices for MIL.\n- Loss: Asymmetric Loss (ASL) by default (BCE+Focal available).\n- Heads: 'Present' + 13 locations; during inference, location probs are gated by Present^alpha.\n- Temperature scaling (per-label) on validation logits; thresholds then chosen:\n    * Present: smallest t with precision ‚â• TARGET_PRECISION_PRESENT (default 0.80)\n    * Locations: per-label F1 tuned\n- Outputs (per modality): /kaggle/working/{mod}_val_preds.csv and {mod}_best.pt\n\nDefault settings here favor **speed for a first pass**:\n- CT slice ranking uses fast p99 (no vesselness), K=8, 1‚Äì2 num_workers.\n- After the first run (cache built), bump K_SLICES to 16 and (optionally) enable vesselness.\n\nQuick start:\n    # just run the cell; or call:\n    train_model_jupyter(\n        DATA_DIR=\"/kaggle/input/rsna-intracranial-aneurysm-detection\",\n        IMG_SIZE=320, K_SLICES=8, EPOCHS=4\n    )\n\"\"\"\n\nimport os, time, random, warnings, hashlib, math\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Optional\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pydicom\n\n# Optional vesselness (Frangi); safe fallback if skimage isn't present\ntry:\n    from skimage.filters import frangi as frangi2d\n    _HAS_FRANGI = True\nexcept Exception:\n    _HAS_FRANGI = False\n\nfrom scipy import ndimage as ndi\n\n# VOI LUT import (compat across pydicom versions)\ntry:\n    from pydicom.pixel_data_handlers import apply_voi_lut\nexcept Exception:\n    try:\n        from pydicom.pixel_data_handlers.util import apply_voi_lut\n    except Exception:\n        def apply_voi_lut(x, ds): return x\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nimport torchvision\nfrom torchvision.models.video import r3d_18\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score\n\nwarnings.filterwarnings(\"ignore\")\n\n# =============================================================================\n# CONFIG\n# =============================================================================\nclass Config:\n    # Kaggle dataset\n    DATA_DIR   = \"/kaggle/input/rsna-intracranial-aneurysm-detection\"\n    SERIES_DIR = f\"{DATA_DIR}/series\"\n    TRAIN_CSV  = f\"{DATA_DIR}/train.csv\"\n\n    # Train defaults (2.5D MIL)\n    IMG_SIZE            = 320\n    BATCH_SIZE          = 2\n    EPOCHS              = 4\n    LR                  = 3e-4\n    # Use 1‚Äì(cpu-1) workers on Kaggle (usually 2 vCPUs); overlap CPU prep with GPU\n    NUM_WORKERS         = max(1, (os.cpu_count() or 2) - 1)\n    SEED                = 42\n    USE_AMP             = True\n\n    # 3D mode (optional). If True, we switch to a 3D backbone on cropped cubes.\n    MODE_3D             = False\n    VOL_CROP_SIZE       = 96\n    VOL_ISO_SPACING_MM  = 1.2\n\n    # MIL slice selection\n    K_SLICES            = 8                 # fast first pass; bump to 16 later\n    CTA_RANKING         = \"p99\"             # \"p99\" (fast) or \"vesselness\"\n    VESSELNESS_BLEND    = 0.0               # set 0.35 for slight boost (CTA), adds CPU\n\n    # Loss\n    LOSS_NAME           = \"ASL\"             # \"ASL\" or \"FOCAL_BCE\"\n    FOCAL_GAMMA         = 2.0               # if using FOCAL_BCE\n\n    # Logs / cache\n    LOG_EVERY_N         = 10\n    USE_CACHE           = True\n    CACHE_DIR           = \"/kaggle/working/mip_cache\"\n    CACHE_VERSION       = \"v8.1\"\n\n    # CT windows (L, W)\n    CT_WINDOWS          = [(40, 80), (200, 500), (600, 2800)]  # brain, soft/vessel, bone\n\n    # Bone-aware highlight (CTA)\n    HIGHLIGHT_ENABLE       = True\n    HIGHLIGHT_TOP_PCT      = 1.0\n    HIGHLIGHT_GAMMA        = 0.7\n    HIGHLIGHT_BLEND        = 0.6\n    CT_HIGHLIGHT_SKIP_BONE = True\n    CT_BONE_MASK_HU        = 300\n    CT_BONE_MORPH_K        = 3\n\n    # Temperature scaling & thresholds\n    DO_TEMP_SCALING      = True\n    TARGET_PRECISION_PRESENT = 0.80\n    GATE_ALPHA           = 1.0     # locations *= present_prob ** alpha\n\n    # Consistency penalty\n    CONSISTENCY_W        = 0.2\n\n    # Small smoke subset for quick tests (set both None to use ALL)\n    SMOKE_TRAIN_LIMIT    = None\n    SMOKE_VAL_LIMIT      = None\n\n    # Labels (13 sites + global)\n    TARGET_COLS = [\n        \"Left Infraclinoid Internal Carotid Artery\",\n        \"Right Infraclinoid Internal Carotid Artery\",\n        \"Left Supraclinoid Internal Carotid Artery\",\n        \"Right Supraclinoid Internal Carotid Artery\",\n        \"Left Middle Cerebral Artery\",\n        \"Right Middle Cerebral Artery\",\n        \"Anterior Communicating Artery\",\n        \"Left Anterior Cerebral Artery\",\n        \"Right Anterior Cerebral Artery\",\n        \"Left Posterior Communicating Artery\",\n        \"Right Posterior Communicating Artery\",\n        \"Basilar Tip\",\n        \"Other Posterior Circulation\",\n        \"Aneurysm Present\",\n    ]\n\n# ImageNet normalization (works even though channels ‚â† RGB semantics)\nIMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\nIMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n\n# =============================================================================\n# UTIL\n# =============================================================================\ndef set_seed(seed=42, benchmark_mode=False):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = not benchmark_mode\n    torch.backends.cudnn.benchmark     = benchmark_mode\n\ndef device() -> str:\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef count_params(m: nn.Module) -> int:\n    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n\n# =============================================================================\n# DICOM I/O & NORMALIZATION\n# =============================================================================\ndef iter_dicom_files(series_path: str) -> List[str]:\n    sp = Path(series_path)\n    dcm_files = list(sp.glob(\"*.dcm\"))\n    if not dcm_files:\n        dcm_files = [f for f in sp.iterdir() if f.is_file() and not f.suffix]\n    if not dcm_files:\n        return []\n    infos = []\n    for f in dcm_files:\n        try:\n            ds = pydicom.dcmread(str(f), stop_before_pixels=True, force=True)\n            ins = getattr(ds, \"InstanceNumber\", 0)\n        except Exception:\n            ins = 0\n        infos.append((ins, str(f)))\n    infos.sort(key=lambda x: (x[0], x[1]))\n    return [p for _, p in infos]\n\ndef read_pixel(ds) -> np.ndarray:\n    arr = ds.pixel_array\n    try:\n        if hasattr(ds, 'VOILUTSequence') or hasattr(ds, 'WindowCenter'):\n            arr = apply_voi_lut(arr, ds)\n    except Exception:\n        pass\n    if hasattr(ds, \"RescaleSlope\") and hasattr(ds, \"RescaleIntercept\"):\n        arr = arr.astype(np.float32) * float(ds.RescaleSlope) + float(ds.RescaleIntercept)\n    else:\n        arr = arr.astype(np.float32)\n    return arr\n\ndef read_volume_hu(series_path: str) -> Tuple[np.ndarray, Tuple[float,float,float]]:\n    \"\"\"Returns volume in HU [Z,H,W] and voxel spacing (z,y,x). Works for MR too (value scale just not HU).\"\"\"\n    files = iter_dicom_files(series_path)\n    if not files: raise RuntimeError(\"No DICOMs in series\")\n    slices, zs = [], []\n    spacing_yx = (1.0, 1.0)\n    for fp in files:\n        try:\n            ds = pydicom.dcmread(fp, force=True)\n            arr = read_pixel(ds)\n            if getattr(ds, \"PhotometricInterpretation\", \"MONOCHROME2\") == \"MONOCHROME1\":\n                arr = np.max(arr) - arr\n            if hasattr(ds, \"PixelSpacing\"):\n                spacing_yx = (float(ds.PixelSpacing[0]), float(ds.PixelSpacing[1]))\n            st = float(getattr(ds, \"SliceThickness\", 1.0))\n            zs.append(st)\n            slices.append(arr.astype(np.float32))\n        except Exception:\n            continue\n    if not slices: raise RuntimeError(\"No decodable slices\")\n    vol = np.stack(slices, axis=0)   # [Z,H,W]\n    spacing = (np.median(zs) if zs else 1.0, spacing_yx[0], spacing_yx[1])\n    return vol, spacing\n\ndef _ensure_gray2d(img: np.ndarray) -> np.ndarray:\n    if img.ndim == 3:\n        if img.shape[-1] == 3:\n            img = np.mean(img, axis=-1)\n        else:\n            img = img.max(axis=-1)\n    return img.astype(np.float32)\n\ndef window_ct(img: np.ndarray, level=200, width=500) -> np.ndarray:\n    img = img.astype(np.float32)\n    lo, hi = float(level) - float(width)/2.0, float(level) + float(width)/2.0\n    img = np.clip(img, lo, hi)\n    denom = max(1e-6, (hi - lo))\n    img = (img - lo) / denom\n    return np.clip(img, 0, 1)\n\ndef normalize_mr(img: np.ndarray) -> np.ndarray:\n    img = img.astype(np.float32)\n    p1, p99 = np.percentile(img, [1, 99])\n    img = np.clip(img, p1, p99)\n    if p99 > p1:\n        img = (img - p1) / (p99 - p1)\n    return np.clip(img, 0, 1)\n\n# =============================================================================\n# CTA vesselness & highlight\n# =============================================================================\ndef vesselness_2d_soft(img01: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Returns vesselness in [0,1] for a 2D slice (CTA soft-tissue window).\n    Uses skimage.frangi if available; otherwise a safe LoG-based fallback.\n    \"\"\"\n    img01 = np.clip(img01.astype(np.float32), 0, 1)\n    if _HAS_FRANGI:\n        try:\n            v = frangi2d(img01, sigmas=(1, 2, 3), alpha=0.5, beta=0.5, gamma=15.0, black_ridges=False)\n            v = np.nan_to_num(v, nan=0.0, posinf=0.0, neginf=0.0)\n            v = (v - v.min()) / max(1e-6, (v.max() - v.min()))\n            return v.astype(np.float32)\n        except Exception:\n            pass\n    # Fallback: multi-sigma Laplacian-of-Gaussian magnitude (proxy)\n    sigmas = [1.0, 2.0, 3.0]\n    acc = np.zeros_like(img01, dtype=np.float32)\n    for s in sigmas:\n        g = ndi.gaussian_laplace(img01, sigma=s)\n        acc = np.maximum(acc, -g)  # vessels bright ‚Üí negative LoG\n    acc = (acc - acc.min()) / max(1e-6, (acc.max() - acc.min()))\n    return acc\n\ndef highlight_stretch(img01: np.ndarray, pct=None, gamma=None, blend=None) -> np.ndarray:\n    pct   = Config.HIGHLIGHT_TOP_PCT if pct is None else pct\n    gamma = Config.HIGHLIGHT_GAMMA   if gamma is None else gamma\n    blend = Config.HIGHLIGHT_BLEND   if blend is None else blend\n    img = img01.astype(np.float32); img = np.clip(img, 0.0, 1.0)\n    if pct <= 0.0: return img.copy()\n    thr = np.percentile(img, 100.0 - pct)\n    if not np.isfinite(thr) or thr >= 0.999: return img.copy()\n    out = img.copy(); mask = img >= thr\n    denom = max(1e-6, 1.0 - thr)\n    hi = (img - thr) / denom\n    if gamma > 0: hi = np.power(hi, 1.0 / gamma)\n    out[mask] = (1.0 - blend) * img[mask] + blend * hi[mask]\n    return np.clip(out, 0.0, 1.0)\n\ndef morph_clean(mask: np.ndarray, k: int) -> np.ndarray:\n    if k is None or k <= 0: return mask\n    kernel = np.ones((k,k), np.uint8)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  kernel)\n    return mask\n\n# =============================================================================\n# CACHE KEYS\n# =============================================================================\ndef _cache_path(series_path: str, out_size: int, key_extra: str) -> str:\n    os.makedirs(Config.CACHE_DIR, exist_ok=True)\n    key = f\"{Config.CACHE_VERSION}_{os.path.basename(series_path)}_{out_size}_{key_extra}_k{Config.K_SLICES}_rank{Config.CTA_RANKING}_vbl{Config.VESSELNESS_BLEND}_bone{Config.CT_BONE_MASK_HU}_m{Config.CT_BONE_MORPH_K}\"\n    h = hashlib.md5(key.encode()).hexdigest()[:16]\n    return os.path.join(Config.CACHE_DIR, f\"buf_{h}.npy\")\n\ndef _load_cache(path: str) -> Optional[np.ndarray]:\n    try:\n        if Config.USE_CACHE and os.path.exists(path):\n            arr = np.load(path, allow_pickle=False)\n            return arr\n    except Exception:\n        pass\n    return None\n\ndef _save_cache(arr: np.ndarray, path: str):\n    if not Config.USE_CACHE: return\n    try:\n        np.save(path, arr, allow_pickle=False)\n    except Exception:\n        pass\n\n# =============================================================================\n# 2.5D MIL DATASET (CTA & MR)\n# =============================================================================\ndef pick_topk_slices_cta_fast(vol_hu: np.ndarray, k: int, out_size: int) -> np.ndarray:\n    \"\"\"\n    Fast CTA path:\n      - Build CT windows\n      - Rank slices by 99th percentile on soft-tissue window (200/500)\n      - Bone mask in HU (> Config.CT_BONE_MASK_HU), then highlight (skip bone)\n    Returns [K,3,H,W]\n    \"\"\"\n    Z, H, W = vol_hu.shape\n    # Build window stacks once\n    wins = []\n    for (L, Wd) in Config.CT_WINDOWS:\n        ch = np.stack([window_ct(vol_hu[z], level=L, width=Wd) for z in range(Z)], 0).astype(np.float32)\n        wins.append(ch)\n    soft = wins[1]  # (200,500)\n\n    # Rank by 99th percentile (fast)\n    p99 = np.array([np.percentile(soft[z], 99) for z in range(Z)], dtype=np.float32)\n    idx = np.sort(np.argsort(-p99)[:k])\n\n    # Assemble channels & highlight\n    imgs = []\n    for z in idx:\n        chans = [cv2.resize(ch[z], (out_size, out_size), interpolation=cv2.INTER_AREA) for ch in wins]\n\n        # Bone mask directly from HU threshold (then resize & morph clean)\n        bone_mask = (vol_hu[z] > float(Config.CT_BONE_MASK_HU)).astype(np.uint8)\n        bone_mask = cv2.resize(bone_mask, (out_size, out_size), interpolation=cv2.INTER_NEAREST).astype(bool)\n        bone_mask = morph_clean(bone_mask.astype(np.uint8), Config.CT_BONE_MORPH_K).astype(bool)\n\n        if Config.HIGHLIGHT_ENABLE:\n            for i in range(len(chans)):\n                hi = highlight_stretch(chans[i])\n                if Config.CT_HIGHLIGHT_SKIP_BONE:\n                    chans[i] = np.where(~bone_mask, hi, chans[i]).astype(np.float32)\n                else:\n                    chans[i] = hi\n\n        imgs.append(np.stack(chans, 0))  # [3,H,W]\n    return np.stack(imgs, 0)            # [K,3,H,W]\n\ndef pick_topk_slices_cta_vessel(vol_hu: np.ndarray, k: int, out_size: int) -> np.ndarray:\n    \"\"\"\n    Vesselness-based CTA path (heavier CPU):\n      - Frangi/LoG vesselness on soft window for ranking\n      - Optional vesselness boost per channel\n      - HU bone mask + highlight\n    Returns [K,3,H,W]\n    \"\"\"\n    Z, H, W = vol_hu.shape\n    wins = []\n    for (L, Wd) in Config.CT_WINDOWS:\n        ch = np.stack([window_ct(vol_hu[z], level=L, width=Wd) for z in range(Z)], 0).astype(np.float32)\n        wins.append(ch)\n    soft = wins[1]  # (200,500)\n\n    vness = np.stack([vesselness_2d_soft(soft[z]) for z in range(Z)], 0)  # [Z,H,W]\n    # Rank by center vesselness for robustness\n    cy0, cx0, r = H//2, W//2, min(H, W)//4\n    yy, xx = np.ogrid[:H, :W]\n    circ = ((yy-cy0)**2 + (xx-cx0)**2) <= r*r\n    scores = (vness * circ).sum((1,2)) / max(1, circ.sum())\n    idx = np.sort(np.argsort(-scores)[:k])\n\n    imgs = []\n    for z in idx:\n        chans = [cv2.resize(ch[z], (out_size, out_size), interpolation=cv2.INTER_AREA) for ch in wins]\n        v = cv2.resize(vness[z], (out_size, out_size), interpolation=cv2.INTER_AREA).astype(np.float32)\n        if Config.VESSELNESS_BLEND > 0:\n            boost = (1.0 + Config.VESSELNESS_BLEND * v)\n            chans = [np.clip(c * boost, 0, 1).astype(np.float32) for c in chans]\n\n        bone_mask = (vol_hu[z] > float(Config.CT_BONE_MASK_HU)).astype(np.uint8)\n        bone_mask = cv2.resize(bone_mask, (out_size, out_size), interpolation=cv2.INTER_NEAREST).astype(bool)\n        bone_mask = morph_clean(bone_mask.astype(np.uint8), Config.CT_BONE_MORPH_K).astype(bool)\n\n        if Config.HIGHLIGHT_ENABLE:\n            for i in range(len(chans)):\n                hi = highlight_stretch(chans[i])\n                if Config.CT_HIGHLIGHT_SKIP_BONE:\n                    chans[i] = np.where(~bone_mask, hi, chans[i]).astype(np.float32)\n                else:\n                    chans[i] = hi\n        imgs.append(np.stack(chans, 0))\n    return np.stack(imgs, 0)\n\ndef pick_topk_slices_mr(vol: np.ndarray, k: int, out_size: int) -> np.ndarray:\n    \"\"\"\n    MR path:\n      - Per-slice percentile normalize; rank by 99th percentile (bright vessels)\n      - Gentle highlight; replicate into 3 channels\n    Returns [K,3,H,W]\n    \"\"\"\n    Z, H, W = vol.shape\n    norm = []\n    scores = []\n    for z in range(Z):\n        im = normalize_mr(vol[z])\n        scores.append(np.percentile(im, 99))\n        im = cv2.resize(im, (out_size, out_size), interpolation=cv2.INTER_AREA)\n        if Config.HIGHLIGHT_ENABLE:\n            im = highlight_stretch(im)\n        norm.append(im.astype(np.float32))\n    idx = np.sort(np.argsort(-np.array(scores))[:k])\n    out = [np.stack([norm[z], norm[z], norm[z]], 0) for z in idx]\n    return np.stack(out, 0)\n\ndef build_2d_mil_buffers(series_path: str, is_ct: bool, out_size: int, k_slices: int):\n    key_extra = f\"mil2d_ct{int(is_ct)}\"\n    cache = _cache_path(series_path, out_size, key_extra=key_extra)\n    cached = _load_cache(cache)\n    if cached is not None:\n        return cached\n    vol, _ = read_volume_hu(series_path)\n    if is_ct:\n        if Config.CTA_RANKING.lower() == \"vesselness\":\n            buf = pick_topk_slices_cta_vessel(vol, k_slices, out_size)\n        else:\n            buf = pick_topk_slices_cta_fast(vol, k_slices, out_size)\n    else:\n        buf = pick_topk_slices_mr(vol, k_slices, out_size)\n    _save_cache(buf, cache)\n    return buf\n\n# =============================================================================\n# 3D CROP DATASET (optional)\n# =============================================================================\ndef resample_iso(vol: np.ndarray, spacing: Tuple[float,float,float], iso=1.2) -> np.ndarray:\n    z,y,x = spacing\n    zoom = (z/iso, y/iso, x/iso)\n    return ndi.zoom(vol.astype(np.float32), zoom=zoom, order=1)\n\ndef find_cof_bbox_cta(vol_hu_iso: np.ndarray, out_edge: int) -> Tuple[int,int,int]:\n    Z,H,W = vol_hu_iso.shape\n    soft = np.stack([window_ct(vol_hu_iso[z], 200, 500) for z in range(Z)], 0)\n    v3 = np.stack([vesselness_2d_soft(soft[z]) for z in range(Z)], 0)\n    v3 = ndi.gaussian_filter(v3, sigma=1.0)\n    m = v3 / max(1e-6, v3.sum())\n    zz, yy, xx = np.indices(v3.shape)\n    cz = int(np.clip((zz*m).sum(), 0, Z-1))\n    cy = int(np.clip((yy*m).sum(), 0, H-1))\n    cx = int(np.clip((xx*m).sum(), 0, W-1))\n    return cz, cy, cx\n\ndef crop_cube(vol: np.ndarray, center: Tuple[int,int,int], edge: int) -> np.ndarray:\n    cz, cy, cx = center\n    Z,H,W = vol.shape\n    r = edge//2\n    z0, z1 = max(0, cz-r), min(Z, cz+r)\n    y0, y1 = max(0, cy-r), min(H, cy+r)\n    x0, x1 = max(0, cx-r), min(W, cx+r)\n    cube = np.zeros((edge, edge, edge), np.float32)\n    cz0 = (edge - (z1 - z0))//2\n    cy0 = (edge - (y1 - y0))//2\n    cx0 = (edge - (x1 - x0))//2\n    cube[cz0:cz0+(z1-z0), cy0:cy0+(y1-y0), cx0:cx0+(x1-x0)] = vol[z0:z1, y0:y1, x0:x1]\n    return cube\n\n# =============================================================================\n# DATASET & SAMPLER\n# =============================================================================\ndef stratified_split(df: pd.DataFrame, global_col=\"Aneurysm Present\", seed=42, n_splits=5):\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n    tr_idx, va_idx = next(skf.split(df, df[global_col]))\n    return df.iloc[tr_idx].copy(), df.iloc[va_idx].copy()\n\ndef safe_series_path(series_dir: str, uid: str) -> str:\n    p = os.path.join(series_dir, str(uid))\n    if not os.path.exists(p): raise FileNotFoundError(p)\n    return p\n\ndef _detect_modality_from_header(series_path: str) -> Optional[str]:\n    files = iter_dicom_files(series_path)\n    if not files: return None\n    try:\n        ds = pydicom.dcmread(files[0], stop_before_pixels=True, force=True)\n        return str(getattr(ds, \"Modality\", \"\")).upper() or None\n    except Exception:\n        return None\n\ndef filter_decodable_df(df: pd.DataFrame, series_dir: str) -> pd.DataFrame:\n    uids = df[\"SeriesInstanceUID\"].astype(str).tolist()\n    keep_mask = []\n    for uid in uids:\n        sp = os.path.join(series_dir, uid)\n        ok = False\n        try:\n            files = iter_dicom_files(sp)\n            if files:\n                ds = pydicom.dcmread(files[0], force=True)\n                _ = ds.pixel_array\n                ok = True\n        except Exception:\n            ok = False\n        keep_mask.append(ok)\n    kept = df[keep_mask].reset_index(drop=True)\n    print(f\"Decodable series (quick test): {len(kept)}/{len(df)} kept\")\n    return kept\n\nclass MIL2DDataset(Dataset):\n    \"\"\"Returns one study as K slices [K,3,H,W], normalized for ImageNet, and label vector [C].\"\"\"\n    def __init__(self, df: pd.DataFrame, series_dir: str, out_size: int, k_slices: int, modality: str):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.out_size = out_size\n        self.k_slices = k_slices\n        self.modality = modality  # \"CT\" or \"MR\"\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss: raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n        if self.modality == \"CT\":\n            buf = build_2d_mil_buffers(sp, is_ct=True, out_size=self.out_size, k_slices=self.k_slices)  # [K,3,H,W]\n        else:\n            buf = build_2d_mil_buffers(sp, is_ct=False, out_size=self.out_size, k_slices=self.k_slices)\n        x = torch.from_numpy(buf).float()         # [K,3,H,W] in [0,1]\n        # ImageNet normalization per-slice\n        x = (x - IMAGENET_MEAN) / IMAGENET_STD\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\nclass Vol3DDataset(Dataset):\n    \"\"\"3D crop dataset: returns [3,D,H,W] by stacking same volume into 3 channels, normalized ~ImageNet.\"\"\"\n    def __init__(self, df: pd.DataFrame, series_dir: str, crop_edge: int, iso: float, modality: str):\n        self.df = df.reset_index(drop=True)\n        self.series_dir = series_dir\n        self.edge = crop_edge\n        self.iso = iso\n        self.modality = modality\n        miss = [c for c in Config.TARGET_COLS if c not in df.columns]\n        if miss: raise ValueError(f\"Missing target cols: {miss}\")\n\n    def __len__(self): return len(self.df)\n\n    def __getitem__(self, idx: int):\n        row = self.df.iloc[idx]\n        uid = str(row[\"SeriesInstanceUID\"])\n        sp = safe_series_path(self.series_dir, uid)\n        vol_hu, spacing = read_volume_hu(sp)\n        vol_iso = resample_iso(vol_hu, spacing, iso=self.iso)  # [Z,H,W]\n        if self.modality == \"CT\":\n            cz, cy, cx = find_cof_bbox_cta(vol_iso, self.edge)\n        else:\n            # For MR, use 99th-percentile intensity COM\n            v = np.clip(vol_iso, np.percentile(vol_iso, 1), np.percentile(vol_iso, 99))\n            v = (v - v.min()) / max(1e-6, (v.max() - v.min()))\n            m = v / max(1e-6, v.sum())\n            zz, yy, xx = np.indices(v.shape)\n            cz = int(np.clip((zz*m).sum(), 0, v.shape[0]-1))\n            cy = int(np.clip((yy*m).sum(), 0, v.shape[1]-1))\n            cx = int(np.clip((xx*m).sum(), 0, v.shape[2]-1))\n        cube = crop_cube(vol_iso, (cz,cy,cx), self.edge)  # [D,H,W]\n        if self.modality == \"CT\":\n            D,H,W = cube.shape\n            ch = np.stack([window_ct(cube[d], 200, 500) for d in range(D)], 0)\n        else:\n            v = np.clip(cube, np.percentile(cube, 1), np.percentile(cube, 99))\n            ch = (v - v.min()) / max(1e-6, (v.max()-v.min()))\n        vol3 = np.stack([ch, ch, ch], 0)  # [3,D,H,W]\n        x = torch.from_numpy(vol3).float()\n        for c in range(3):\n            x[c] = (x[c] - IMAGENET_MEAN[c]) / IMAGENET_STD[c]\n        y = torch.tensor([row[c] for c in Config.TARGET_COLS], dtype=torch.float32)\n        return x, y, uid\n\ndef build_class_balanced_sampler(df: pd.DataFrame, target_cols: List[str]) -> WeightedRandomSampler:\n    pos = df[target_cols].sum(0).values\n    neg = len(df) - pos\n    cls_w = np.where(pos > 0, neg / np.maximum(1, pos), 1.0)\n    cls_w = np.clip(cls_w, 1.0, 50.0)\n    Y = df[target_cols].values.astype(np.float32)\n    w = 1.0 + (Y * cls_w).sum(1)\n    w = torch.as_tensor(w, dtype=torch.double)\n    return WeightedRandomSampler(weights=w, num_samples=len(df), replacement=True)\n\n# =============================================================================\n# MODELS\n# =============================================================================\ndef efficientnet_b2_features():\n    m = torchvision.models.efficientnet_b2(weights=torchvision.models.EfficientNet_B2_Weights.IMAGENET1K_V1)\n    feat_dim = m.classifier[1].in_features\n    backbone = nn.Sequential(m.features, nn.AdaptiveAvgPool2d(1), nn.Flatten())  # -> [B, feat_dim]\n    return backbone, feat_dim\n\nclass AttnMIL(nn.Module):\n    \"\"\"Processes K slices with a 2D backbone and attention-pools to a study embedding.\"\"\"\n    def __init__(self, feat_dim, hidden=512):\n        super().__init__()\n        self.attn = nn.Sequential(\n            nn.Linear(feat_dim, hidden), nn.ReLU(inplace=True),\n            nn.Linear(hidden, 1)\n        )\n    def forward(self, F):  # F: [B,K,D]\n        A = self.attn(F).squeeze(-1)           # [B,K]\n        A = torch.softmax(A, dim=1)            # weights sum to 1\n        M = torch.sum(F * A.unsqueeze(-1), 1)  # [B,D]\n        return M, A\n\nclass HierHead(nn.Module):\n    \"\"\"Two heads: Present (1) + Locations (13).\"\"\"\n    def __init__(self, in_dim, n_locs=13):\n        super().__init__()\n        self.present = nn.Linear(in_dim, 1)\n        self.locs    = nn.Linear(in_dim, n_locs)\n    def forward(self, z):\n        return self.present(z).squeeze(-1), self.locs(z)\n\nclass MIL2DModel(nn.Module):\n    def __init__(self, n_out=14):\n        super().__init__()\n        self.backbone, feat_dim = efficientnet_b2_features()\n        self.mil = AttnMIL(feat_dim)\n        self.head = HierHead(feat_dim, n_locs=n_out-1)\n    def forward(self, x):  # x: [B,K,3,H,W]\n        B,K,C,H,W = x.shape\n        x = x.view(B*K, C, H, W)\n        f = self.backbone(x)                 # [B*K, D]\n        f = f.view(B, K, -1)                 # [B,K,D]\n        z, att = self.mil(f)                 # [B,D], [B,K]\n        present, locs = self.head(z)         # [B], [B,13]\n        logits = torch.cat([locs, present.unsqueeze(-1)], dim=1)  # [B,14] (locations first)\n        return logits, att\n\nclass Res3DModel(nn.Module):\n    def __init__(self, n_out=14):\n        super().__init__()\n        m = r3d_18(weights=None)\n        m.fc = nn.Linear(m.fc.in_features, 512)\n        self.backbone = m\n        self.head = HierHead(512, n_locs=n_out-1)\n    def forward(self, x):  # [B,3,D,H,W]\n        z = self.backbone(x)                 # [B,512]\n        present, locs = self.head(z)\n        logits = torch.cat([locs, present.unsqueeze(-1)], dim=1)\n        return logits, None\n\n# =============================================================================\n# LOSSES\n# =============================================================================\nclass AsymmetricLoss(nn.Module):\n    \"\"\"\n    ASL for multi-label classification.\n    Default: gamma_neg=4, gamma_pos=0, clip=0.05\n    \"\"\"\n    def __init__(self, gamma_pos=0, gamma_neg=4, clip=0.05, eps=1e-8):\n        super().__init__()\n        self.gp = gamma_pos\n        self.gn = gamma_neg\n        self.clip = clip\n        self.eps = eps\n\n    def forward(self, logits, targets):\n        x_sigmoid = torch.sigmoid(logits)\n        xs_pos = x_sigmoid\n        xs_neg = 1.0 - x_sigmoid\n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg + self.clip).clamp(max=1)\n        loss_pos = targets * torch.log(xs_pos.clamp(min=self.eps))\n        loss_neg = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps))\n        loss = loss_pos + loss_neg\n        if self.gp > 0 or self.gn > 0:\n            pt = x_sigmoid * targets + (1 - x_sigmoid) * (1 - targets)\n            one_sided_gamma = self.gp * targets + self.gn * (1 - targets)\n            focal_weight = (1 - pt) ** one_sided_gamma\n            loss *= focal_weight\n        return -loss.mean()\n\nclass BCEWithLogitsFocal(nn.Module):\n    def __init__(self, pos_weight=None, gamma=2.0):\n        super().__init__()\n        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction=\"none\")\n        self.gamma = gamma\n    def forward(self, logits, targets):\n        bce = self.bce(logits, targets)\n        p = torch.sigmoid(logits)\n        pt = p*targets + (1-p)*(1-targets)\n        focal = (1.0 - pt).clamp_min(1e-6).pow(self.gamma)\n        return (focal * bce).mean()\n\n# =============================================================================\n# METRICS & THRESHOLDS\n# =============================================================================\ndef compute_auc_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_auc, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_auc[c] = np.nan\n                continue\n            auc = roc_auc_score(y_true[:, i], y_prob[:, i])\n            col_auc[c] = float(auc); macro_vals.append(float(auc))\n        except Exception:\n            col_auc[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_auc, macro\n\ndef compute_ap_per_column(y_true: np.ndarray, y_prob: np.ndarray, cols: List[str]):\n    col_ap, macro_vals = {}, []\n    for i, c in enumerate(cols):\n        try:\n            if len(np.unique(y_true[:, i])) < 2:\n                col_ap[c] = np.nan\n                continue\n            ap = average_precision_score(y_true[:, i], y_prob[:, i])\n            col_ap[c] = float(ap); macro_vals.append(float(ap))\n        except Exception:\n            col_ap[c] = np.nan\n    macro = float(np.mean(macro_vals)) if macro_vals else np.nan\n    return col_ap, macro\n\ndef compute_micro_ap(y_true: np.ndarray, y_prob: np.ndarray):\n    mask = (y_true.sum(0) > 0) & ((1 - y_true).sum(0) > 0)\n    if mask.sum() == 0: return np.nan\n    return average_precision_score(y_true[:, mask].ravel(), y_prob[:, mask].ravel())\n\ndef tune_thresholds_best_f1(y_true: np.ndarray, y_prob: np.ndarray) -> np.ndarray:\n    n_labels = y_true.shape[1]\n    thrs = np.zeros(n_labels, dtype=np.float32)\n    grid = np.linspace(0.0, 1.0, 1001)\n    for i in range(n_labels):\n        yi = y_true[:, i].astype(np.int32)\n        pi = y_prob[:, i]\n        if len(np.unique(yi)) < 2: thrs[i] = 0.5; continue\n        best_f1, best_t = -1.0, 0.5\n        for t in grid:\n            pred = (pi >= t).astype(np.int32)\n            tp = int((pred & (yi == 1)).sum()); fp = int((pred & (yi == 0)).sum())\n            fn = int(((1 - pred) & (yi == 1)).sum())\n            precision = tp / max(1, (tp + fp)); recall = tp / max(1, (tp + fn))\n            f1 = 2*precision*recall / max(1e-8, (precision + recall))\n            if f1 > best_f1: best_f1, best_t = f1, t\n        thrs[i] = best_t\n    return thrs\n\ndef smallest_t_for_precision(y_true: np.ndarray, y_prob: np.ndarray, target_p=0.8) -> float:\n    if len(y_true) == 0: return 0.5\n    order = np.argsort(-y_prob)\n    y = y_true[order]; p = y_prob[order]\n    tp=0; fp=0; best_t = 1.0\n    for i in range(len(y)):\n        if y[i] == 1: tp += 1\n        else: fp += 1\n        prec = tp / max(1, tp+fp)\n        if prec >= target_p:\n            best_t = p[i]; break\n    # If never reach target precision, return a conservative high threshold\n    return float(best_t)\n\ndef confusion_stats(y_true: np.ndarray, y_prob: np.ndarray, thrs: np.ndarray,\n                    cols: List[str], top_k: int = 6) -> pd.DataFrame:\n    rows = []\n    for i, c in enumerate(cols):\n        yi = y_true[:, i].astype(np.int32)\n        pi = (y_prob[:, i] >= thrs[i]).astype(np.int32)\n        tp = int((pi & (yi == 1)).sum())\n        fp = int((pi & (yi == 0)).sum())\n        tn = int(((1 - pi) & (yi == 0)).sum())\n        fn = int(((1 - pi) & (yi == 1)).sum())\n        prec = tp / max(1, (tp + fp))\n        rec  = tp / max(1, (tp + fn))\n        f1   = 2*prec*rec / max(1e-8, (prec + rec))\n        rows.append([c, thrs[i], tp, fp, tn, fn, prec, rec, f1])\n    df = pd.DataFrame(rows, columns=[\"label\",\"thr\",\"TP\",\"FP\",\"TN\",\"FN\",\"precision\",\"recall\",\"F1\"])\n    priority = [\"Aneurysm Present\", \"Left Middle Cerebral Artery\", \"Right Middle Cerebral Artery\",\n                \"Basilar Tip\", \"Anterior Communicating Artery\"]\n    order = priority + [c for c in cols if c not in priority]\n    df = df.set_index(\"label\").loc[order].reset_index()\n    return df.head(top_k)\n\n# =============================================================================\n# TEMPERATURE SCALING (per label)\n# =============================================================================\n@torch.no_grad()\ndef collect_logits(model, loader, dev):\n    model.eval()\n    logits_list, targets_list, uids = [], [], []\n    for x, y, idlist in loader:\n        x = x.to(dev, non_blocking=True)\n        y = y.to(dev, non_blocking=True)\n        out, _ = model(x)              # [B,14]\n        logits_list.append(out.detach().cpu())\n        targets_list.append(y.detach().cpu())\n        uids.extend(list(idlist))\n    L = torch.cat(logits_list, 0).numpy()\n    T = torch.cat(targets_list, 0).numpy()\n    return L, T, uids\n\ndef fit_temperature_per_label(logits: np.ndarray, targets: np.ndarray, max_iter=200, lr=0.05) -> np.ndarray:\n    \"\"\"\n    Fit a temperature per column minimizing BCEWithLogits on val.\n    Returns temperatures shape [C], >= 1e-3.\n    \"\"\"\n    if logits.size == 0:\n        return np.ones((len(Config.TARGET_COLS),), dtype=np.float32)\n    L = torch.tensor(logits, dtype=torch.float32)\n    Y = torch.tensor(targets, dtype=torch.float32)\n    C = L.shape[1]\n    temps = torch.ones(C, dtype=torch.float32, requires_grad=True)\n    optim_t = torch.optim.Adam([temps], lr=lr)\n    for _ in range(max_iter):\n        optim_t.zero_grad()\n        scaled = L / temps.clamp_min(1e-3)\n        loss = nn.BCEWithLogitsLoss()(scaled, Y)\n        loss.backward()\n        optim_t.step()\n    return temps.detach().clamp_min(1e-3).cpu().numpy()\n\n# =============================================================================\n# TRAIN / EVAL LOOP (one modality)\n# =============================================================================\ndef run_one_modality(modality_name: str, full_df: pd.DataFrame, series_dir: str, dev: str):\n    \"\"\"\n    modality_name: \"CT\" -> CT/CTA subset, \"MR\" -> MR/MRA subset\n    \"\"\"\n    is_ct = (modality_name == \"CT\")\n    print(f\"\\n================= TRAINING MODALITY: {modality_name} =================\")\n    print(f\"Config: NUM_WORKERS={Config.NUM_WORKERS} | K_SLICES={Config.K_SLICES} | CTA_RANKING={Config.CTA_RANKING} | VBLEND={Config.VESSELNESS_BLEND}\")\n\n    # Subset df by modality (prefer CSV, fallback to header)\n    df = full_df.copy()\n    df[\"Modality\"] = df.get(\"Modality\", \"\").fillna(\"\")\n    modes = []\n    for _, r in df.iterrows():\n        m = str(r.get(\"Modality\", \"\")).upper()\n        if not m:\n            try:\n                m = _detect_modality_from_header(os.path.join(series_dir, str(r[\"SeriesInstanceUID\"]))) or \"\"\n            except Exception:\n                m = \"\"\n        modes.append(m)\n    df[\"__mod\"] = modes\n    if is_ct:\n        sub = df[df[\"__mod\"].isin([\"CT\",\"CTA\"])].reset_index(drop=True)\n    else:\n        sub = df[df[\"__mod\"].isin([\"MR\",\"MRA\"])].reset_index(drop=True)\n\n    if len(sub) == 0:\n        print(f\"No {modality_name} studies found. Skipping.\")\n        return None\n\n    # Split stratified by \"Aneurysm Present\"\n    train_df, val_df = stratified_split(sub, seed=Config.SEED)\n\n    # Optional smoke limits\n    if Config.SMOKE_TRAIN_LIMIT is not None:\n        train_df = train_df.head(Config.SMOKE_TRAIN_LIMIT).copy()\n    if Config.SMOKE_VAL_LIMIT is not None:\n        val_df   = val_df.head(Config.SMOKE_VAL_LIMIT).copy()\n\n    # Filter decodable\n    print(\"Scanning decodability (quick test)...\")\n    train_keep = filter_decodable_df(train_df, series_dir)\n    val_keep   = filter_decodable_df(val_df, series_dir)\n    print(f\"{modality_name} Train: {len(train_keep)} | Val: {len(val_keep)}\")\n\n    # Build datasets/loaders\n    if Config.MODE_3D:\n        train_ds = Vol3DDataset(train_keep, series_dir, Config.VOL_CROP_SIZE, Config.VOL_ISO_SPACING_MM, modality_name)\n        val_ds   = Vol3DDataset(val_keep,   series_dir, Config.VOL_CROP_SIZE, Config.VOL_ISO_SPACING_MM, modality_name)\n    else:\n        train_ds = MIL2DDataset(train_keep, series_dir, Config.IMG_SIZE, Config.K_SLICES, modality_name)\n        val_ds   = MIL2DDataset(val_keep,   series_dir, Config.IMG_SIZE, Config.K_SLICES, modality_name)\n\n    train_sampler = build_class_balanced_sampler(train_keep, Config.TARGET_COLS)\n    tkw = dict(batch_size=Config.BATCH_SIZE, sampler=train_sampler, num_workers=Config.NUM_WORKERS, drop_last=True)\n    vkw = dict(batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=Config.NUM_WORKERS, drop_last=False)\n    if dev == \"cuda\":\n        tkw[\"pin_memory\"] = True; vkw[\"pin_memory\"] = True\n    train_loader = DataLoader(train_ds, **tkw)\n    val_loader   = DataLoader(val_ds, **vkw)\n\n    # Model\n    if Config.MODE_3D:\n        model = Res3DModel(n_out=len(Config.TARGET_COLS)).to(dev)\n    else:\n        model = MIL2DModel(n_out=len(Config.TARGET_COLS)).to(dev)\n    print(f\"Model params: {count_params(model):,}\")\n\n    # Loss\n    present_idx = Config.TARGET_COLS.index(\"Aneurysm Present\")\n    if Config.LOSS_NAME.upper() == \"ASL\":\n        criterion = AsymmetricLoss(gamma_pos=0, gamma_neg=4, clip=0.05)\n    else:\n        # compute pos_weight per label from training subset\n        posw = []\n        for c in Config.TARGET_COLS:\n            pos = train_keep[c].sum(); neg = len(train_keep) - pos\n            w = (neg / max(1.0, pos)) if pos > 0 else 1.0\n            posw.append(float(np.clip(w, 1.0, 50.0)))\n        criterion = BCEWithLogitsFocal(pos_weight=torch.tensor(posw, device=dev), gamma=Config.FOCAL_GAMMA)\n\n    opt = optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-4)\n    sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=Config.EPOCHS)\n    scaler = torch.cuda.amp.GradScaler(enabled=(dev==\"cuda\" and Config.USE_AMP))\n\n    best_macro_auc = -1.0\n    best_ckpt = f\"/kaggle/working/{modality_name.lower()}_best.pt\"\n\n    # ------------- Train -------------\n    for epoch in range(Config.EPOCHS):\n        model.train()\n        run_loss = 0.0; t0 = time.time()\n        for b, (x, y, _) in enumerate(train_loader, 1):\n            x, y = x.to(dev, non_blocking=True), y.to(dev, non_blocking=True)\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=(dev==\"cuda\" and Config.USE_AMP)):\n                logits, _att = model(x)                # [B,14]\n                loss = criterion(logits, y)\n                # consistency: locations <= present\n                if Config.CONSISTENCY_W > 0:\n                    probs = torch.sigmoid(logits)\n                    present = probs[:, present_idx:present_idx+1]\n                    locs   = probs[:, :present_idx]   # [B,13]\n                    consist = torch.clamp(locs - present, min=0.0).pow(2).mean()\n                    loss = loss + Config.CONSISTENCY_W * consist\n            scaler.scale(loss).backward()\n            scaler.step(opt); scaler.update()\n            run_loss += loss.item()\n            if b % Config.LOG_EVERY_N == 0 or b == 1:\n                print(f\"[{modality_name} E{epoch+1} {b}/{len(train_loader)}] loss={run_loss/b:.4f} lr={sch.get_last_lr()[0]:.2e}\")\n        sch.step()\n\n        # ------------- Val -------------\n        model.eval()\n        val_loss = 0.0\n        logits_all, probs_all, targs_all, uids_all = [], [], [], []\n        with torch.no_grad():\n            for x, y, uids in val_loader:\n                x, y = x.to(dev, non_blocking=True), y.to(dev, non_blocking=True)\n                with torch.cuda.amp.autocast(enabled=(dev==\"cuda\" and Config.USE_AMP)):\n                    out, _att = model(x)\n                    ls = nn.BCEWithLogitsLoss(reduction=\"mean\")(out, y)\n                val_loss += ls.item()\n                logits_all.append(out.detach().cpu().numpy())\n                probs_all.append(torch.sigmoid(out).detach().cpu().numpy())\n                targs_all.append(y.detach().cpu().numpy())\n                uids_all.extend(list(uids))\n\n        L = np.vstack(logits_all) if logits_all else np.zeros((0, len(Config.TARGET_COLS)))\n        P = np.vstack(probs_all)  if probs_all  else np.zeros((0, len(Config.TARGET_COLS)))\n        T = np.vstack(targs_all)  if targs_all  else np.zeros((0, len(Config.TARGET_COLS)))\n        col_aucs, macro_auc = compute_auc_per_column(T, P, Config.TARGET_COLS)\n        col_aps , macro_ap  = compute_ap_per_column(T, P, Config.TARGET_COLS)\n        micro_ap = compute_micro_ap(T, P)\n        dt = time.time() - t0\n        print(f\"{modality_name} Epoch {epoch+1}/{Config.EPOCHS} | {dt:.1f}s  val_loss={val_loss/max(1,len(val_loader)):.4f}  \"\n              f\"macro_auc={macro_auc:.4f} macro_ap={macro_ap:.4f} micro_ap={micro_ap:.4f}\")\n\n        if macro_auc > best_macro_auc:\n            best_macro_auc = macro_auc\n            torch.save({\n                \"epoch\": epoch+1,\n                \"model_state_dict\": model.state_dict(),\n                \"auc_macro\": macro_auc,\n                \"target_cols\": Config.TARGET_COLS,\n            }, best_ckpt)\n            print(f\"Saved new best for {modality_name}: {best_ckpt} (macro_auc={macro_auc:.4f})\")\n\n    # -------- Post-hoc calibration (temperature scaling) on final val --------\n    L, T, uids_all = collect_logits(model, val_loader, dev)\n    if Config.DO_TEMP_SCALING:\n        temps = fit_temperature_per_label(L, T, max_iter=200, lr=0.05)  # [C]\n    else:\n        temps = np.ones(L.shape[1] if L.size else len(Config.TARGET_COLS), dtype=np.float32)\n    Ls = L / np.clip(temps, 1e-3, None)\n    P_cal = 1.0 / (1.0 + np.exp(-Ls))\n\n    # Gating: locations *= present^alpha\n    present_idx = Config.TARGET_COLS.index(\"Aneurysm Present\")\n    loc_idx = [i for i in range(len(Config.TARGET_COLS)) if i != present_idx]\n    if Config.GATE_ALPHA > 0 and P_cal.size:\n        pr = np.clip(P_cal[:, present_idx:present_idx+1], 0, 1) ** Config.GATE_ALPHA\n        P_cal[:, loc_idx] = P_cal[:, loc_idx] * pr\n\n    # Thresholds:\n    thrs = np.zeros(len(Config.TARGET_COLS), dtype=np.float32)\n    if P_cal.size:\n        # 1) Present: smallest t with precision >= target\n        thrs[present_idx] = smallest_t_for_precision(T[:, present_idx], P_cal[:, present_idx], target_p=Config.TARGET_PRECISION_PRESENT)\n        # 2) Locations: F1-tuned\n        thrs[loc_idx] = tune_thresholds_best_f1(T[:, loc_idx], P_cal[:, loc_idx])\n    else:\n        thrs[:] = 0.5\n\n    # Confusion summary\n    if P_cal.size:\n        conf_df = confusion_stats(T, P_cal, thrs, Config.TARGET_COLS, top_k=6)\n        print(f\"\\n{modality_name} (Calibrated) confusion summary @ thresholds:\")\n        for _, r in conf_df.iterrows():\n            print(f\"  {r['label'][:28]:28s} thr={r['thr']:.2f}  TP={r['TP']:3d} FP={r['FP']:3d} \"\n                  f\"TN={r['TN']:3d} FN={r['FN']:3d}  P={r['precision']:.2f} R={r['recall']:.2f} F1={r['F1']:.2f}\")\n\n        # Metrics (calibrated)\n        col_aucs, macro_auc = compute_auc_per_column(T, P_cal, Config.TARGET_COLS)\n        col_aps , macro_ap  = compute_ap_per_column(T, P_cal, Config.TARGET_COLS)\n        micro_ap = compute_micro_ap(T, P_cal)\n        print(f\"\\n{modality_name} (Calibrated) macro_auc={macro_auc:.4f} macro_ap={macro_ap:.4f} micro_ap={micro_ap:.4f}\")\n\n    # Save per-modality val preds CSV\n    out_csv = f\"/kaggle/working/{modality_name.lower()}_val_preds.csv\"\n    df_out = pd.DataFrame({\"SeriesInstanceUID\": uids_all})\n    if P_cal.size:\n        for i, c in enumerate(Config.TARGET_COLS):\n            df_out[c + \"_prob\"] = P_cal[:, i]\n            df_out[c + \"_true\"] = T[:, i]\n            df_out[c + \"_thr\"]  = thrs[i]\n    df_out.to_csv(out_csv, index=False)\n    print(f\"Saved {modality_name} validation predictions to {out_csv} (shape={df_out.shape})\")\n\n    # Save final checkpoint with temps + thresholds\n    torch.save({\n        \"epoch\": Config.EPOCHS,\n        \"model_state_dict\": model.state_dict(),\n        \"target_cols\": Config.TARGET_COLS,\n        \"temps\": temps.astype(np.float32),\n        \"thresholds\": thrs.astype(np.float32),\n        \"modality\": modality_name,\n        \"config_snapshot\": {\n            \"IMG_SIZE\": Config.IMG_SIZE,\n            \"K_SLICES\": Config.K_SLICES,\n            \"CTA_RANKING\": Config.CTA_RANKING,\n            \"VESSELNESS_BLEND\": Config.VESSELNESS_BLEND,\n            \"LOSS_NAME\": Config.LOSS_NAME,\n            \"GATE_ALPHA\": Config.GATE_ALPHA,\n            \"CONSISTENCY_W\": Config.CONSISTENCY_W,\n        }\n    }, f\"/kaggle/working/{modality_name.lower()}_best.pt\")\n    print(f\"Saved {modality_name} calibrated model with temps+thresholds: /kaggle/working/{modality_name.lower()}_best.pt\")\n\n    return True\n\n# =============================================================================\n# MAIN\n# =============================================================================\ndef main():\n    print(\"== RSNA IA Detection: Modality-Split MIL (ASL, TempScaling, Gated Heads) ==\")\n    set_seed(Config.SEED, benchmark_mode=True if device()==\"cuda\" else False)\n    dev = device()\n    print(f\"Device: {dev} | AMP: {Config.USE_AMP} | 3D Mode: {Config.MODE_3D}\")\n    print(f\"CPU cores: {os.cpu_count()} | DataLoader workers: {Config.NUM_WORKERS}\")\n\n    csv_path = os.path.join(Config.DATA_DIR, \"train.csv\")\n    if not os.path.exists(csv_path): raise FileNotFoundError(csv_path)\n    df = pd.read_csv(csv_path)\n    series_dir = os.path.join(Config.DATA_DIR, \"series\")\n    print(f\"Rows in CSV: {len(df):,}\")\n\n    # Train per-modality\n    run_one_modality(\"CT\", df, series_dir, dev)\n    run_one_modality(\"MR\", df, series_dir, dev)\n    print(\"All done.\")\n\n# Jupyter helper\ndef train_model_jupyter(**kwargs):\n    # Allow quick overrides\n    for k,v in kwargs.items():\n        if hasattr(Config, k):\n            setattr(Config, k, v)\n    main()\n\nif __name__ == \"__main__\":\n    main()\n\nprint(\"Loaded script. Example:\")\nprint('train_model_jupyter(DATA_DIR=\"/kaggle/input/rsna-intracranial-aneurysm-detection\", IMG_SIZE=320, K_SLICES=8, EPOCHS=4)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:53:17.300042Z","iopub.status.idle":"2025-09-23T22:53:17.300308Z","shell.execute_reply.started":"2025-09-23T22:53:17.300191Z","shell.execute_reply":"2025-09-23T22:53:17.300203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}