{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc757d8-3a42-410d-be90-81c2567a4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced class counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Barbari     90\n",
      "Goat        90\n",
      "Harri       90\n",
      "Najdi       90\n",
      "Roman       90\n",
      "Sawakni     90\n",
      "Name: count, dtype: int64\n",
      "Found 744 validated image filenames belonging to 7 classes.\n",
      "Found 137 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 0.1624 - loss: 2.4790 - val_accuracy: 0.1022 - val_loss: 1.9881\n",
      "Epoch 2/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.2025 - loss: 2.0503 - val_accuracy: 0.4088 - val_loss: 1.8533\n",
      "Epoch 3/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3s/step - accuracy: 0.2084 - loss: 1.9868 - val_accuracy: 0.3723 - val_loss: 1.8492\n",
      "Epoch 4/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 3s/step - accuracy: 0.2667 - loss: 1.8984 - val_accuracy: 0.3723 - val_loss: 1.8982\n",
      "Epoch 5/6\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 3s/step - accuracy: 0.2567 - loss: 1.9103 - val_accuracy: 0.3723 - val_loss: 1.9141\n",
      "Epoch 1/30\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 5s/step - accuracy: 0.1967 - loss: 1.6163 - val_accuracy: 0.3723 - val_loss: 1.3841 - learning_rate: 2.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 5s/step - accuracy: 0.2202 - loss: 1.5108 - val_accuracy: 0.3723 - val_loss: 1.3899 - learning_rate: 2.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2386 - loss: 1.4300  \n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 5s/step - accuracy: 0.2390 - loss: 1.4293 - val_accuracy: 0.3796 - val_loss: 1.3965 - learning_rate: 2.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 5s/step - accuracy: 0.2858 - loss: 1.3908 - val_accuracy: 0.3796 - val_loss: 1.3924 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2991 - loss: 1.3502  \n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 5s/step - accuracy: 0.2998 - loss: 1.3501 - val_accuracy: 0.3869 - val_loss: 1.3953 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 5s/step - accuracy: 0.3447 - loss: 1.3198 - val_accuracy: 0.3942 - val_loss: 1.3878 - learning_rate: 5.0000e-06\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Barbari       0.00      0.00      0.00         7\n",
      "        Goat       0.00      0.00      0.00        22\n",
      "       Harri       0.00      0.00      0.00        12\n",
      "      Naeimi       0.37      1.00      0.54        51\n",
      "       Najdi       0.00      0.00      0.00        14\n",
      "       Roman       0.00      0.00      0.00        15\n",
      "     Sawakni       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.37       137\n",
      "   macro avg       0.05      0.14      0.08       137\n",
      "weighted avg       0.14      0.37      0.20       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------- 0. Imports & paths ----------------\n",
    "import pandas as pd, numpy as np, tensorflow as tf, matplotlib.pyplot as plt, seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "\n",
    "# ---------------- 1. dataframe ----------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "labels = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "NUM_CLASSES = len(labels)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df[\"label_idx\"], random_state=42\n",
    ")\n",
    "\n",
    "# --------- 2. uniform oversample  -------------------\n",
    "# ► EVERY breed gets at least 90 samples ◄\n",
    "TARGET = 90\n",
    "oversampled = []\n",
    "for lbl, grp in train_df.groupby(\"label\"):\n",
    "    if len(grp) < TARGET:\n",
    "        grp = resample(grp, replace=True, n_samples=TARGET, random_state=42)\n",
    "    oversampled.append(grp)\n",
    "\n",
    "train_df_bal = pd.concat(oversampled).reset_index(drop=True)\n",
    "print(\"Balanced class counts:\\n\", train_df_bal[\"label\"].value_counts())\n",
    "\n",
    "# ---------------- 3. generators ---------------------\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=20, width_shift_range=0.12, height_shift_range=0.12,\n",
    "    zoom_range=0.15, horizontal_flip=True\n",
    ")\n",
    "val_aug = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_gen = train_aug.flow_from_dataframe(\n",
    "    train_df_bal, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=(224, 224), batch_size=32, class_mode=\"categorical\", shuffle=True\n",
    ")\n",
    "val_gen = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=(224, 224), batch_size=32, class_mode=\"categorical\", shuffle=False\n",
    ")\n",
    "\n",
    "# ------------- 4. focal loss with softer α ---------- \n",
    "# order must follow `labels`\n",
    "alpha_vec = tf.constant([1.6, 0.9, 1.2, 0.8, 1.1, 1.3, 1.0], dtype=tf.float32)\n",
    "LABEL_SMOOTH = 0.05\n",
    "def focal_loss_pc(gamma=2.):\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = y_true * (1 - LABEL_SMOOTH) + LABEL_SMOOTH / NUM_CLASSES\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        ce  = -y_true * tf.math.log(y_pred)\n",
    "        fl  = tf.pow(1 - y_pred, gamma) * ce * alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "    return _loss\n",
    "\n",
    "# ---------------- 5. model --------------------------\n",
    "base = ResNet50(include_top=False, weights=\"imagenet\",\n",
    "                input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "base.trainable = False\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = Model(base.input, out)\n",
    "\n",
    "model.compile(Adam(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# ---------------- 6. train head ---------------------\n",
    "model.fit(\n",
    "    train_gen, validation_data=val_gen,\n",
    "    epochs=6,\n",
    "    callbacks=[EarlyStopping(patience=2, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# ---- unfreeze last 50 & switch loss / LR -----------\n",
    "for layer in base.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "for layer in base.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    Adam(2e-5),              # fine-tune learning-rate\n",
    "    loss=focal_loss_pc(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_gen, validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(patience=2, factor=0.5, verbose=1)\n",
    "])\n",
    "\n",
    "# ---------------- 7. evaluation ---------------------\n",
    "val_gen.reset()\n",
    "probs = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(probs, 1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99324843-e9bf-469b-badb-dfdf1d8d4d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced class counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Barbari    200\n",
      "Roman      120\n",
      "Goat        85\n",
      "Sawakni     64\n",
      "Najdi       57\n",
      "Harri       50\n",
      "Name: count, dtype: int64\n",
      "Found 780 validated image filenames belonging to 7 classes.\n",
      "Found 137 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.1733 - loss: 2.3871 - val_accuracy: 0.3723 - val_loss: 1.8433\n",
      "Epoch 2/6\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.2152 - loss: 1.9355 - val_accuracy: 0.2701 - val_loss: 1.8967\n",
      "Epoch 3/6\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 4s/step - accuracy: 0.2764 - loss: 1.8607 - val_accuracy: 0.3723 - val_loss: 1.8705\n",
      "Epoch 1/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 6s/step - accuracy: 0.2113 - loss: 1.4370 - val_accuracy: 0.3723 - val_loss: 1.2914 - learning_rate: 5.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 5s/step - accuracy: 0.2902 - loss: 1.2614 - val_accuracy: 0.3723 - val_loss: 1.2667 - learning_rate: 5.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 5s/step - accuracy: 0.2978 - loss: 1.2775 - val_accuracy: 0.3723 - val_loss: 1.2289 - learning_rate: 5.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.3271 - loss: 1.1685 - val_accuracy: 0.3577 - val_loss: 1.1942 - learning_rate: 5.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 5s/step - accuracy: 0.3538 - loss: 1.0959 - val_accuracy: 0.1314 - val_loss: 1.1692 - learning_rate: 5.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.3521 - loss: 1.1490 - val_accuracy: 0.1241 - val_loss: 1.1497 - learning_rate: 5.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - accuracy: 0.3385 - loss: 1.1557 - val_accuracy: 0.1314 - val_loss: 1.1223 - learning_rate: 5.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 6s/step - accuracy: 0.3412 - loss: 1.0914 - val_accuracy: 0.1168 - val_loss: 1.1079 - learning_rate: 5.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - accuracy: 0.3693 - loss: 1.0722 - val_accuracy: 0.0949 - val_loss: 1.3971 - learning_rate: 5.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3825 - loss: 1.0444  \n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - accuracy: 0.3823 - loss: 1.0440 - val_accuracy: 0.0949 - val_loss: 1.4991 - learning_rate: 5.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - accuracy: 0.3837 - loss: 1.0298 - val_accuracy: 0.1095 - val_loss: 1.3842 - learning_rate: 2.5000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4040 - loss: 0.9121  \n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - accuracy: 0.4045 - loss: 0.9121 - val_accuracy: 0.1460 - val_loss: 1.1296 - learning_rate: 2.5000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - accuracy: 0.3979 - loss: 0.9560 - val_accuracy: 0.1533 - val_loss: 1.1552 - learning_rate: 1.2500e-05\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Barbari       0.07      1.00      0.12         7\n",
      "        Goat       0.00      0.00      0.00        22\n",
      "       Harri       0.00      0.00      0.00        12\n",
      "      Naeimi       0.00      0.00      0.00        51\n",
      "       Najdi       0.00      0.00      0.00        14\n",
      "       Roman       0.26      0.47      0.33        15\n",
      "     Sawakni       0.40      0.12      0.19        16\n",
      "\n",
      "    accuracy                           0.12       137\n",
      "   macro avg       0.10      0.23      0.09       137\n",
      "weighted avg       0.08      0.12      0.07       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------- 0. Imports & paths ----------------\n",
    "import pandas as pd, numpy as np, tensorflow as tf, matplotlib.pyplot as plt, seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "\n",
    "# ---------------- 1. dataframe ----------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "labels = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "NUM_CLASSES = len(labels)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df[\"label_idx\"], random_state=42\n",
    ")\n",
    "\n",
    "# --------- 2. **targeted** oversample ----------------\n",
    "TARGET = {\"Barbari\": 200, \"Roman\": 120}          # ↩ only these two get boosted\n",
    "os_parts = []\n",
    "for lbl, grp in train_df.groupby(\"label\"):\n",
    "    need = TARGET.get(lbl, len(grp))             # keep original count for others\n",
    "    if len(grp) < need:\n",
    "        grp = resample(grp, replace=True, n_samples=need, random_state=42)\n",
    "    os_parts.append(grp)\n",
    "train_df_bal = pd.concat(os_parts).reset_index(drop=True)\n",
    "print(\"Balanced class counts:\\n\", train_df_bal[\"label\"].value_counts())\n",
    "\n",
    "# ---------------- 3. generators ---------------------\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15, height_shift_range=0.15,\n",
    "    zoom_range=0.20, brightness_range=[0.8,1.2],\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_aug = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_gen = train_aug.flow_from_dataframe(\n",
    "    train_df_bal, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=(224,224), batch_size=32,\n",
    "    class_mode=\"categorical\", shuffle=True\n",
    ")\n",
    "val_gen = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=(224,224), batch_size=32,\n",
    "    class_mode=\"categorical\", shuffle=False\n",
    ")\n",
    "\n",
    "# ------------- 4. focal loss with tuned α ------------\n",
    "alpha_vec = tf.constant([2.0, 0.6, 1.2, 0.3, 1.2, 1.5, 1.0], tf.float32)  # order = labels\n",
    "LABEL_SMOOTH = 0.05\n",
    "def focal_loss_pc(gamma=2.):\n",
    "    def _loss(y_true, y_pred):\n",
    "        # label-smoothing\n",
    "        y_true = y_true * (1 - LABEL_SMOOTH) + LABEL_SMOOTH / NUM_CLASSES\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        ce  = -y_true * tf.math.log(y_pred)\n",
    "        fl  = tf.pow(1 - y_pred, gamma) * ce * alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "    return _loss\n",
    "\n",
    "# ---------------- 5. model --------------------------\n",
    "base = ResNet50(include_top=False, weights=\"imagenet\",\n",
    "                input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "# ---- phase-1: train only the new head --------------\n",
    "base.trainable = False\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = Model(base.input, out)\n",
    "\n",
    "model.compile(Adam(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    train_gen, validation_data=val_gen,\n",
    "    epochs=6,\n",
    "    callbacks=[EarlyStopping(patience=2, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# ---- phase-2: unfreeze last 70 layers & fine-tune ---\n",
    "for layer in base.layers[:-70]:\n",
    "    layer.trainable = False\n",
    "for layer in base.layers[-70:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    Adam(5e-5),                    # slightly higher LR than before\n",
    "    loss=focal_loss_pc(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_gen, validation_data=val_gen,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
    "        ReduceLROnPlateau(patience=2, factor=0.5, verbose=1)\n",
    "])\n",
    "\n",
    "# ---------------- 6. evaluation ---------------------\n",
    "val_gen.reset()\n",
    "probs = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(probs, 1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e97ea2-e6f8-43b5-ae7e-65a3e85c6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Barbari    200\n",
      "Goat       200\n",
      "Harri      200\n",
      "Najdi      200\n",
      "Roman      200\n",
      "Sawakni    200\n",
      "Name: count, dtype: int64\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n",
      "Found 137 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3s/step - accuracy: 0.1471 - loss: 2.3113 - val_accuracy: 0.1606 - val_loss: 1.9548\n",
      "Epoch 2/6\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3s/step - accuracy: 0.1492 - loss: 1.9999 - val_accuracy: 0.1095 - val_loss: 1.9417\n",
      "Epoch 3/6\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 3s/step - accuracy: 0.1485 - loss: 1.9631 - val_accuracy: 0.2482 - val_loss: 1.9443\n",
      "Epoch 4/6\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.1531 - loss: 1.9482 - val_accuracy: 0.1314 - val_loss: 1.9322\n",
      "Epoch 5/6\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.1397 - loss: 1.9626 - val_accuracy: 0.3650 - val_loss: 1.9266\n",
      "Epoch 6/6\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.1524 - loss: 1.9479 - val_accuracy: 0.1533 - val_loss: 1.9448\n",
      "Epoch 1/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 5s/step - accuracy: 0.1624 - loss: 1.5670 - val_accuracy: 0.1022 - val_loss: 1.4355 - learning_rate: 3.0000e-05\n",
      "Epoch 2/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 5s/step - accuracy: 0.1963 - loss: 1.3909 - val_accuracy: 0.1168 - val_loss: 1.4443 - learning_rate: 3.0000e-05\n",
      "Epoch 3/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 5s/step - accuracy: 0.2516 - loss: 1.3518 - val_accuracy: 0.1168 - val_loss: 1.4320 - learning_rate: 3.0000e-05\n",
      "Epoch 4/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 5s/step - accuracy: 0.2480 - loss: 1.3125 - val_accuracy: 0.1679 - val_loss: 1.3645 - learning_rate: 3.0000e-05\n",
      "Epoch 5/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 5s/step - accuracy: 0.2834 - loss: 1.2417 - val_accuracy: 0.2993 - val_loss: 1.2753 - learning_rate: 3.0000e-05\n",
      "Epoch 6/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3054s\u001b[0m 71s/step - accuracy: 0.3157 - loss: 1.1799 - val_accuracy: 0.2701 - val_loss: 1.2047 - learning_rate: 3.0000e-05\n",
      "Epoch 7/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 5s/step - accuracy: 0.3619 - loss: 1.1237 - val_accuracy: 0.2409 - val_loss: 1.2987 - learning_rate: 3.0000e-05\n",
      "Epoch 8/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 6s/step - accuracy: 0.3921 - loss: 1.0957 - val_accuracy: 0.4161 - val_loss: 1.0382 - learning_rate: 3.0000e-05\n",
      "Epoch 9/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 6s/step - accuracy: 0.4457 - loss: 1.0160 - val_accuracy: 0.3650 - val_loss: 1.1717 - learning_rate: 3.0000e-05\n",
      "Epoch 10/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4405 - loss: 1.0175  \n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 6s/step - accuracy: 0.4407 - loss: 1.0171 - val_accuracy: 0.4161 - val_loss: 1.2819 - learning_rate: 3.0000e-05\n",
      "Epoch 11/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 6s/step - accuracy: 0.4783 - loss: 0.9775 - val_accuracy: 0.4599 - val_loss: 0.8936 - learning_rate: 1.5000e-05\n",
      "Epoch 12/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 6s/step - accuracy: 0.5205 - loss: 0.8895 - val_accuracy: 0.4891 - val_loss: 0.8800 - learning_rate: 1.5000e-05\n",
      "Epoch 13/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 6s/step - accuracy: 0.5251 - loss: 0.9031 - val_accuracy: 0.5620 - val_loss: 0.7858 - learning_rate: 1.5000e-05\n",
      "Epoch 14/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 6s/step - accuracy: 0.5243 - loss: 0.8561 - val_accuracy: 0.5474 - val_loss: 0.8194 - learning_rate: 1.5000e-05\n",
      "Epoch 15/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5491 - loss: 0.8268  \n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-06.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 6s/step - accuracy: 0.5498 - loss: 0.8262 - val_accuracy: 0.4307 - val_loss: 0.9360 - learning_rate: 1.5000e-05\n",
      "Epoch 16/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 6s/step - accuracy: 0.5800 - loss: 0.7792 - val_accuracy: 0.5036 - val_loss: 0.8720 - learning_rate: 7.5000e-06\n",
      "Epoch 17/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.6198 - loss: 0.7442  \n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.749999905267032e-06.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 6s/step - accuracy: 0.6194 - loss: 0.7441 - val_accuracy: 0.4599 - val_loss: 0.8990 - learning_rate: 7.5000e-06\n",
      "Epoch 18/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 6s/step - accuracy: 0.6095 - loss: 0.7232 - val_accuracy: 0.5401 - val_loss: 0.7783 - learning_rate: 3.7500e-06\n",
      "Epoch 19/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 6s/step - accuracy: 0.6035 - loss: 0.7555 - val_accuracy: 0.5109 - val_loss: 0.8414 - learning_rate: 3.7500e-06\n",
      "Epoch 20/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 6s/step - accuracy: 0.6156 - loss: 0.7100 - val_accuracy: 0.5474 - val_loss: 0.7499 - learning_rate: 3.7500e-06\n",
      "Epoch 21/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 6s/step - accuracy: 0.6383 - loss: 0.6805 - val_accuracy: 0.5182 - val_loss: 0.8087 - learning_rate: 3.7500e-06\n",
      "Epoch 22/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6176 - loss: 0.6967  \n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.874999952633516e-06.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 6s/step - accuracy: 0.6178 - loss: 0.6970 - val_accuracy: 0.5036 - val_loss: 0.7853 - learning_rate: 3.7500e-06\n",
      "Epoch 23/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 6s/step - accuracy: 0.6389 - loss: 0.6857 - val_accuracy: 0.6204 - val_loss: 0.6783 - learning_rate: 1.8750e-06\n",
      "Epoch 24/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 7s/step - accuracy: 0.6585 - loss: 0.6541 - val_accuracy: 0.6496 - val_loss: 0.6550 - learning_rate: 1.8750e-06\n",
      "Epoch 25/25\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 6s/step - accuracy: 0.6359 - loss: 0.6851 - val_accuracy: 0.5985 - val_loss: 0.6523 - learning_rate: 1.8750e-06\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x36335dc60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x36335dc60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Barbari       0.42      0.71      0.53         7\n",
      "        Goat       0.76      0.59      0.67        22\n",
      "       Harri       0.64      0.75      0.69        12\n",
      "      Naeimi       0.67      0.59      0.62        51\n",
      "       Najdi       0.85      0.79      0.81        14\n",
      "       Roman       0.21      0.33      0.26        15\n",
      "     Sawakni       0.75      0.56      0.64        16\n",
      "\n",
      "    accuracy                           0.60       137\n",
      "   macro avg       0.61      0.62      0.60       137\n",
      "weighted avg       0.65      0.60      0.61       137\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------- 0. Imports & paths ----------------\n",
    "import pandas as pd, numpy as np, tensorflow as tf, matplotlib.pyplot as plt, seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "\n",
    "# ---------------- 1. dataframe ----------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"]  = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"]  = df[\"label\"].astype(\"category\").cat.codes\n",
    "labels           = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "NUM_CLASSES      = len(labels)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df[\"label_idx\"], random_state=42\n",
    ")\n",
    "\n",
    "# --------- 2. uniform oversample --------------------\n",
    "TARGET = 200                               # every class ≥ 200 imgs\n",
    "upsampled = []\n",
    "for lbl, grp in train_df.groupby(\"label\"):\n",
    "    if len(grp) < TARGET:\n",
    "        grp = resample(grp, replace=True, n_samples=TARGET, random_state=42)\n",
    "    upsampled.append(grp)\n",
    "train_df_bal = pd.concat(upsampled).reset_index(drop=True)\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts())\n",
    "\n",
    "# ---------------- 3. generators ---------------------\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15, height_shift_range=0.15,\n",
    "    zoom_range=0.20, brightness_range=[0.8,1.2],\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_aug = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_gen = train_aug.flow_from_dataframe(\n",
    "    train_df_bal, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=(224,224), batch_size=32,\n",
    "    class_mode=\"categorical\", shuffle=True\n",
    ")\n",
    "val_gen = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=(224,224), batch_size=32,\n",
    "    class_mode=\"categorical\", shuffle=False\n",
    ")\n",
    "\n",
    "# ------------- 4. focal loss (auto-α) ----------------\n",
    "# αᵢ  =  median(freq) / freqᵢ   (rare ⇒ big α, common ⇒ small α)\n",
    "freqs = train_df_bal[\"label\"].value_counts().loc[labels]  # order = labels list\n",
    "alpha_vec = tf.constant(np.median(freqs) / freqs, dtype=tf.float32)\n",
    "'''the way the alphs is calculated is done by dividing the median of the entire classes \n",
    "divided by the number of images in that classes for example lets take a look at our case where the median is 85 and then lets say for \n",
    "Naeimi the count = 204 so we divide the median/count and we get the value of the alpha for the class '''\n",
    "LABEL_SMOOTH = 0.05\n",
    "def focal_loss_auto(gamma=2.):\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = y_true * (1 - LABEL_SMOOTH) + LABEL_SMOOTH / NUM_CLASSES\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
    "        ce  = -y_true * tf.math.log(y_pred)\n",
    "        fl  = tf.pow(1 - y_pred, gamma) * ce * alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "    return _loss\n",
    "\n",
    "# ---------------- 5. model --------------------------\n",
    "base = ResNet50(include_top=False, weights=\"imagenet\",\n",
    "                input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "# ---- phase-1: train new head -----------------------\n",
    "base.trainable = False\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = Model(base.input, out)\n",
    "\n",
    "model.compile(Adam(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_gen, validation_data=val_gen,\n",
    "          epochs=6,\n",
    "          callbacks=[EarlyStopping(patience=2, restore_best_weights=True)])\n",
    "\n",
    "# ---- phase-2: unfreeze last 70 & fine-tune ----------\n",
    "for layer in base.layers[:-70]:\n",
    "    layer.trainable = False\n",
    "for layer in base.layers[-70:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(Adam(3e-5), loss=focal_loss_auto(), metrics=[\"accuracy\"])\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=25,\n",
    "          callbacks=[EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
    "                     ReduceLROnPlateau(patience=2, factor=0.5, verbose=1)])\n",
    "\n",
    "# ---------------- 6. evaluation ---------------------\n",
    "val_gen.reset()\n",
    "probs  = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(probs, 1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17794505-9658-440b-a7e8-0d8f73421931",
   "metadata": {},
   "source": [
    "most sucefful run ever is above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9262b1-c738-4c70-81d4-bf97d080a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Barbari    200\n",
      "Goat       200\n",
      "Harri      200\n",
      "Najdi      200\n",
      "Roman      200\n",
      "Sawakni    200\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Found 137 validated image filenames belonging to 7 classes.\n",
      "\n",
      "================ γ = 1 =================\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 01:45:37.177684: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0. IMPORTS & GLOBALS\n",
    "# ---------------------------------------------------------\n",
    "import os, random, math, gc, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 1. LOAD  &  SPLIT  DATA\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "LABELS   = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "N_CLASS  = len(LABELS)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df[\"label_idx\"], random_state=SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 2. TARGETED *RARE-BREED* UPSAMPLING\n",
    "#    ► if a breed has ≤ THRESH imgs → up-sample to TARGET_CT\n",
    "# ---------------------------------------------------------\n",
    "THRESH, TARGET_CT = 120, 200\n",
    "upsampled = []\n",
    "for lbl, grp in train_df.groupby(\"label\"):\n",
    "    if len(grp) <= THRESH:\n",
    "        grp = resample(grp, replace=True, n_samples=TARGET_CT, random_state=SEED)\n",
    "    upsampled.append(grp)\n",
    "\n",
    "train_df_bal = pd.concat(upsampled).reset_index(drop=True)\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 3. AUGMENTATION   — base transforms  +  MixUp\n",
    "# ---------------------------------------------------------\n",
    "BATCH = 32\n",
    "IMG_SZ = (224, 224)\n",
    "\n",
    "base_aug = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15, height_shift_range=0.15,\n",
    "    zoom_range=0.20, brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_aug  = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "def mixup_gen(df, datagen, alpha=0.4):\n",
    "    \"\"\"Infinite MixUp generator.\"\"\"\n",
    "    base_gen = datagen.flow_from_dataframe(\n",
    "        df, x_col=\"file_path\", y_col=\"label\",\n",
    "        class_mode=\"categorical\", target_size=IMG_SZ,\n",
    "        batch_size=BATCH, shuffle=True, seed=SEED)\n",
    "\n",
    "    while True:\n",
    "        x1, y1 = next(base_gen)\n",
    "        if x1.shape[0] < BATCH:                       # pad short final batch\n",
    "            x1, y1 = next(base_gen)\n",
    "        x2, y2 = next(base_gen)\n",
    "        if x2.shape[0] < BATCH:\n",
    "            x2, y2 = next(base_gen)\n",
    "\n",
    "        lam = np.random.beta(alpha, alpha, size=BATCH)\n",
    "        lam_x = lam.reshape(BATCH, 1, 1, 1)\n",
    "        lam_y = lam.reshape(BATCH, 1)\n",
    "\n",
    "        yield x1 * lam_x + x2 * (1 - lam_x), y1 * lam_y + y2 * (1 - lam_y)\n",
    "\n",
    "# generators (fresh ones will be recreated inside γ-loop)\n",
    "val_gen  = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    class_mode=\"categorical\", target_size=IMG_SZ,\n",
    "    batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# steps/epoch helpers\n",
    "VAL_STEPS  = math.ceil(len(val_df)       / BATCH)\n",
    "STEPS_FULL = math.ceil(len(train_df_bal) / BATCH)\n",
    "\n",
    "# =========================================================\n",
    "# 4. FOCAL-LOSS  with *auto α*  &  γ-SWEEP\n",
    "# ---------------------------------------------------------\n",
    "freq        = train_df_bal[\"label\"].value_counts().loc[LABELS]\n",
    "alpha_vec   = tf.constant(np.median(freq) / freq, dtype=tf.float32)\n",
    "SMOOTH      = 0.05\n",
    "\n",
    "def focal_auto(gamma):\n",
    "    \"\"\"Focal loss with label-smoothing and per-class α.\"\"\"\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = y_true * (1 - SMOOTH) + SMOOTH / N_CLASS\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "        ce  = -y_true * tf.math.log(y_pred)\n",
    "        fl  = tf.pow(1 - y_pred, gamma) * ce * alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "    return _loss\n",
    "\n",
    "GAMMA_LIST = [1, 2, 3]\n",
    "\n",
    "# =========================================================\n",
    "# 5. BUILD MODEL HEAD (re-usable)\n",
    "# ---------------------------------------------------------\n",
    "def build_head(base):\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    return Dense(N_CLASS, activation='softmax')(x)\n",
    "\n",
    "# quick macro-F1 for sweep\n",
    "def quick_macro_f1(model):\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen, steps=VAL_STEPS, verbose=0)\n",
    "    y_hat = np.argmax(preds, 1)\n",
    "    y     = val_gen.classes\n",
    "    cm    = confusion_matrix(y, y_hat, labels=np.arange(N_CLASS))\n",
    "    prec  = np.diag(cm) / (cm.sum(0)+1e-7)\n",
    "    rec   = np.diag(cm) / (cm.sum(1)+1e-7)\n",
    "    f1    = 2*prec*rec / (prec+rec+1e-7)\n",
    "    return np.nanmean(f1)\n",
    "\n",
    "# =========================================================\n",
    "# 6. γ-SWEEP  +  PROGRESSIVE UNFREEZE\n",
    "# ---------------------------------------------------------\n",
    "best_f1, best_gamma, best_model = -np.inf, None, None\n",
    "\n",
    "for γ in GAMMA_LIST:\n",
    "    print(f\"\\n================ γ = {γ} =================\")\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "    # fresh MixUp generator **each sweep** to avoid exhaustion\n",
    "    train_gen = mixup_gen(train_df_bal, base_aug, alpha=0.4)\n",
    "\n",
    "    base = ResNet50(include_top=False, weights=\"imagenet\",\n",
    "                    input_tensor=Input(shape=IMG_SZ + (3,)))\n",
    "\n",
    "    # ---- Phase-1: head only --------------------------------\n",
    "    base.trainable = False\n",
    "    model = Model(base.input, build_head(base))\n",
    "    model.compile(Adam(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(train_gen, steps_per_epoch=STEPS_FULL,\n",
    "              validation_data=val_gen, validation_steps=VAL_STEPS,\n",
    "              epochs=6, callbacks=[EarlyStopping(patience=2, restore_best_weights=True)],\n",
    "              verbose=0)\n",
    "\n",
    "    # ---- Phase-2: unfreeze last 70 --------------------------\n",
    "    for l in base.layers[-70:]: l.trainable = True\n",
    "    model.compile(Adam(3e-5), loss=focal_auto(γ), metrics=[\"accuracy\"])\n",
    "    model.fit(train_gen, steps_per_epoch=STEPS_FULL,\n",
    "              validation_data=val_gen, validation_steps=VAL_STEPS,\n",
    "              epochs=10,\n",
    "              callbacks=[EarlyStopping(patience=3, restore_best_weights=True),\n",
    "                         ReduceLROnPlateau(patience=2, factor=0.5)],\n",
    "              verbose=0)\n",
    "\n",
    "    # ---- Phase-3: unfreeze last 140 -------------------------\n",
    "    for l in base.layers[-140:]: l.trainable = True\n",
    "    model.compile(Adam(1e-5), loss=focal_auto(γ), metrics=[\"accuracy\"])\n",
    "    model.fit(train_gen, steps_per_epoch=STEPS_FULL,\n",
    "              validation_data=val_gen, validation_steps=VAL_STEPS,\n",
    "              epochs=10,\n",
    "              callbacks=[EarlyStopping(patience=3, restore_best_weights=True),\n",
    "                         ReduceLROnPlateau(patience=2, factor=0.5)],\n",
    "              verbose=0)\n",
    "\n",
    "    f1 = quick_macro_f1(model)\n",
    "    print(f\"→ macro-F1 = {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_model, best_gamma = f1, model, γ\n",
    "\n",
    "print(f\"\\nBest γ = {best_gamma}   macro-F1 = {best_f1:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 7. SAVE BEST WEIGHTS\n",
    "# ---------------------------------------------------------\n",
    "best_model.save(\"best_sheep_model.h5\")\n",
    "\n",
    "# =========================================================\n",
    "# 8. EVALUATION  ( TTA  = 8 random augmentations )\n",
    "# ---------------------------------------------------------\n",
    "def tta_predict(model, df, n_aug=8):\n",
    "    \"\"\"Average logits across n_aug random transforms.\"\"\"\n",
    "    logits = np.zeros((len(df), N_CLASS))\n",
    "    for _ in range(n_aug):\n",
    "        tta_gen = base_aug.flow_from_dataframe(\n",
    "            df, x_col=\"file_path\", y_col=None, shuffle=False,\n",
    "            target_size=IMG_SZ, batch_size=BATCH, class_mode=None,\n",
    "            seed=random.randint(0, 9999))  # new randomness each pass\n",
    "        logits += model.predict(tta_gen, verbose=0)\n",
    "    return logits / n_aug\n",
    "\n",
    "val_logits = tta_predict(best_model, val_df)\n",
    "y_pred = np.argmax(val_logits, 1)\n",
    "y_true = val_df[\"label_idx\"].values\n",
    "\n",
    "print(\"\\n=== FINAL REPORT (TTA) ===\")\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS, digits=2))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Confusion matrix (TTA)\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39b15d26-a176-4e8b-9175-f30287797413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Barbari    200\n",
      "Goat       200\n",
      "Harri      200\n",
      "Najdi      200\n",
      "Roman      200\n",
      "Sawakni    200\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Found 137 validated image filenames belonging to 7 classes.\n",
      "\n",
      "================ γ = 1 =================\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 3s/step - accuracy: 0.1411 - loss: 2.3509 - val_accuracy: 0.0876 - val_loss: 1.9456\n",
      "Epoch 2/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3s/step - accuracy: 0.1348 - loss: 2.0658 \n",
      "Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 15:07:39.265884: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 3s/step - accuracy: 0.1365 - loss: 1.9878 - val_accuracy: 0.0876 - val_loss: 1.9788\n",
      "Epoch 4/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.1401 - loss: 1.9544 \n",
      "Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 15:10:11.524339: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 4s/step - accuracy: 0.1482 - loss: 1.9604 - val_accuracy: 0.0657 - val_loss: 1.9470\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 7s/step - accuracy: 0.1652 - loss: 1.7486 - val_accuracy: 0.0876 - val_loss: 1.6986 - learning_rate: 3.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 5s/step - accuracy: 0.1478 - loss: 1.7310 - learning_rate: 3.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - accuracy: 0.1785 - loss: 1.6734 - val_accuracy: 0.0584 - val_loss: 1.7112 - learning_rate: 3.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 5s/step - accuracy: 0.1975 - loss: 1.6365 - learning_rate: 3.0000e-05\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 15:20:18.331408: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 6s/step - accuracy: 0.2008 - loss: 1.6301 - val_accuracy: 0.0803 - val_loss: 1.6842 - learning_rate: 3.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 6s/step - accuracy: 0.2296 - loss: 1.5939 - learning_rate: 3.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 5s/step - accuracy: 0.2598 - loss: 1.6010 - val_accuracy: 0.1241 - val_loss: 1.6346 - learning_rate: 3.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 5s/step - accuracy: 0.2494 - loss: 1.5785 - learning_rate: 3.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 5s/step - accuracy: 0.2552 - loss: 1.5578 - val_accuracy: 0.2701 - val_loss: 1.5799 - learning_rate: 3.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 23s/step - accuracy: 0.2607 - loss: 1.5515 - learning_rate: 3.0000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 9s/step - accuracy: 0.1558 - loss: 1.8389 - val_accuracy: 0.1533 - val_loss: 1.6429 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 10s/step - accuracy: 0.1776 - loss: 1.7915 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 15:45:27.690490: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 11s/step - accuracy: 0.1788 - loss: 1.7238 - val_accuracy: 0.1314 - val_loss: 1.6631 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 10s/step - accuracy: 0.1956 - loss: 1.6744 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 10s/step - accuracy: 0.2150 - loss: 1.6377 - val_accuracy: 0.1752 - val_loss: 1.8643 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 9s/step - accuracy: 0.2466 - loss: 1.6089 - learning_rate: 5.0000e-06\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 11s/step - accuracy: 0.2562 - loss: 1.6020 - val_accuracy: 0.1168 - val_loss: 1.9709 - learning_rate: 5.0000e-06\n",
      "→ macro-F1 = 0.0727\n",
      "\n",
      "================ γ = 2 =================\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.1601 - loss: 2.4803 - val_accuracy: 0.1387 - val_loss: 1.9497\n",
      "Epoch 2/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 0.1579 - loss: 2.1053 \n",
      "Epoch 3/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.1210 - loss: 2.0263 - val_accuracy: 0.3869 - val_loss: 1.9422\n",
      "Epoch 4/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.1700 - loss: 1.9623\n",
      "Epoch 5/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.1223 - loss: 1.9885 - val_accuracy: 0.3723 - val_loss: 1.9437\n",
      "Epoch 6/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.1214 - loss: 1.9599 \n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 6s/step - accuracy: 0.1778 - loss: 1.4633 - val_accuracy: 0.0511 - val_loss: 1.4231 - learning_rate: 3.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 6s/step - accuracy: 0.1572 - loss: 1.4414 - learning_rate: 3.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - accuracy: 0.1860 - loss: 1.4184 - val_accuracy: 0.0657 - val_loss: 1.4380 - learning_rate: 3.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 6s/step - accuracy: 0.1871 - loss: 1.4085 - learning_rate: 3.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 0.2008 - loss: 1.3925 - val_accuracy: 0.0584 - val_loss: 1.4333 - learning_rate: 3.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - accuracy: 0.1880 - loss: 1.4248 - learning_rate: 1.5000e-05\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 16:24:30.088405: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 7s/step - accuracy: 0.1836 - loss: 1.3830 - val_accuracy: 0.0657 - val_loss: 1.4085 - learning_rate: 1.5000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 0.2309 - loss: 1.3756 - learning_rate: 1.5000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 7s/step - accuracy: 0.2693 - loss: 1.3418 - val_accuracy: 0.0949 - val_loss: 1.3958 - learning_rate: 1.5000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 6s/step - accuracy: 0.2665 - loss: 1.3091 - learning_rate: 1.5000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 12s/step - accuracy: 0.1659 - loss: 1.5567 - val_accuracy: 0.2044 - val_loss: 1.3868 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 10s/step - accuracy: 0.1644 - loss: 1.4803 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 11s/step - accuracy: 0.1666 - loss: 1.4591 - val_accuracy: 0.1095 - val_loss: 1.4345 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 11s/step - accuracy: 0.1831 - loss: 1.4558 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 10s/step - accuracy: 0.1678 - loss: 1.4187 - val_accuracy: 0.1241 - val_loss: 1.4929 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 10s/step - accuracy: 0.2268 - loss: 1.3815 - learning_rate: 5.0000e-06\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 10s/step - accuracy: 0.2581 - loss: 1.3845 - val_accuracy: 0.1168 - val_loss: 1.4970 - learning_rate: 5.0000e-06\n",
      "→ macro-F1 = 0.1496\n",
      "\n",
      "================ γ = 3 =================\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n",
      "Epoch 1/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 4s/step - accuracy: 0.1425 - loss: 2.3615 - val_accuracy: 0.0876 - val_loss: 1.9630\n",
      "Epoch 2/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 3s/step - accuracy: 0.1642 - loss: 2.0663\n",
      "Epoch 3/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 4s/step - accuracy: 0.1219 - loss: 2.0016 - val_accuracy: 0.0511 - val_loss: 1.9478\n",
      "Epoch 4/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step - accuracy: 0.1107 - loss: 1.9838\n",
      "Epoch 5/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.1664 - loss: 1.9545 - val_accuracy: 0.1533 - val_loss: 1.9443\n",
      "Epoch 6/6\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 3s/step - accuracy: 0.1342 - loss: 1.9525 \n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 6s/step - accuracy: 0.1513 - loss: 1.2804 - val_accuracy: 0.1533 - val_loss: 1.2156 - learning_rate: 3.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 6s/step - accuracy: 0.1550 - loss: 1.2380 - learning_rate: 3.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 6s/step - accuracy: 0.2049 - loss: 1.1984 - val_accuracy: 0.1387 - val_loss: 1.2169 - learning_rate: 3.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 5s/step - accuracy: 0.1488 - loss: 1.2156 - learning_rate: 3.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 5s/step - accuracy: 0.2070 - loss: 1.2097 - val_accuracy: 0.1168 - val_loss: 1.2173 - learning_rate: 3.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 5s/step - accuracy: 0.1811 - loss: 1.2088 - learning_rate: 1.5000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - accuracy: 0.2302 - loss: 1.1788 - val_accuracy: 0.1314 - val_loss: 1.2093 - learning_rate: 1.5000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 6s/step - accuracy: 0.2209 - loss: 1.1594 - learning_rate: 1.5000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 6s/step - accuracy: 0.2163 - loss: 1.1697 - val_accuracy: 0.1095 - val_loss: 1.2053 - learning_rate: 1.5000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 6s/step - accuracy: 0.2600 - loss: 1.1300 - learning_rate: 1.5000e-05\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 9s/step - accuracy: 0.1335 - loss: 1.3442 - val_accuracy: 0.1387 - val_loss: 1.2821 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 9s/step - accuracy: 0.1393 - loss: 1.2703 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 9s/step - accuracy: 0.1456 - loss: 1.2469 - val_accuracy: 0.0949 - val_loss: 1.2471 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 14s/step - accuracy: 0.1828 - loss: 1.2144 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 11s/step - accuracy: 0.1741 - loss: 1.2477 - val_accuracy: 0.1314 - val_loss: 1.2396 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 10s/step - accuracy: 0.1960 - loss: 1.2060 - learning_rate: 1.0000e-05\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 17:52:33.902043: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 11s/step - accuracy: 0.1741 - loss: 1.2058 - val_accuracy: 0.1314 - val_loss: 1.1881 - learning_rate: 1.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 9s/step - accuracy: 0.1991 - loss: 1.1946 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 8s/step - accuracy: 0.2350 - loss: 1.1658 - val_accuracy: 0.1387 - val_loss: 1.1847 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 8s/step - accuracy: 0.2470 - loss: 1.1626 - learning_rate: 1.0000e-05\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x31aa6c0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x31aa6c0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ macro-F1 = 0.0999\n",
      "\n",
      "Best γ = 2   macro-F1 = 0.1496\n",
      "Found 137 validated image filenames.\n",
      "Found 137 validated image filenames.\n",
      "Found 137 validated image filenames.\n",
      "Found 137 validated image filenames.\n",
      "Found 137 validated image filenames.\n",
      "Found 137 validated image filenames.\n",
      "Found 137 validated image filenames.\n",
      "Found 137 validated image filenames.\n",
      "\n",
      "=== FINAL REPORT (TTA)  —  macro-F1 0.075 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Barbari       0.00      0.00      0.00         7\n",
      "        Goat       0.18      0.36      0.24        22\n",
      "       Harri       0.00      0.00      0.00        12\n",
      "      Naeimi       0.00      0.00      0.00        51\n",
      "       Najdi       0.00      0.00      0.00        14\n",
      "       Roman       0.10      0.60      0.17        15\n",
      "     Sawakni       0.50      0.06      0.11        16\n",
      "\n",
      "    accuracy                           0.13       137\n",
      "   macro avg       0.11      0.15      0.07       137\n",
      "weighted avg       0.10      0.13      0.07       137\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0. IMPORTS & GLOBALS\n",
    "# ---------------------------------------------------------\n",
    "import os, random, math, gc, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "\n",
    "# reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 1. LOAD & STRATIFY\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "LABELS  = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "N_CLASS = len(LABELS)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df[\"label_idx\"], random_state=SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 2. TARGETED UPSAMPLING  (only “rare” ≤120 → 200 imgs)\n",
    "# ---------------------------------------------------------\n",
    "THRESH, TARGET_CT = 120, 200\n",
    "upsampled = []\n",
    "for lbl, g in train_df.groupby(\"label\"):\n",
    "    if len(g) <= THRESH:\n",
    "        g = resample(g, replace=True, n_samples=TARGET_CT, random_state=SEED)\n",
    "    upsampled.append(g)\n",
    "\n",
    "train_df_bal = pd.concat(upsampled).reset_index(drop=True)\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 3. AUGMENTATION + robust MixUp  (FIXED)\n",
    "# ---------------------------------------------------------\n",
    "BATCH  = 32\n",
    "IMG_SZ = (224, 224)\n",
    "\n",
    "base_aug = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15, height_shift_range=0.15,\n",
    "    zoom_range=0.20, brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_aug  = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "def mixup_gen(df, datagen, alpha=0.4):\n",
    "    \"\"\"\n",
    "    Infinite MixUp generator.\n",
    "\n",
    "    * Always returns **full** batches (len == BATCH), otherwise it retries.\n",
    "    * Re-creates the underlying ImageDataGenerator iterator whenever it is\n",
    "      exhausted, so we never hit StopIteration.\n",
    "    \"\"\"\n",
    "    def fresh_iter():\n",
    "        return datagen.flow_from_dataframe(\n",
    "            df, x_col=\"file_path\", y_col=\"label\",\n",
    "            class_mode=\"categorical\", target_size=IMG_SZ,\n",
    "            batch_size=BATCH, shuffle=True,\n",
    "            seed=random.randint(0, 9999))\n",
    "\n",
    "    g = fresh_iter()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            x1, y1 = next(g)\n",
    "        except StopIteration:\n",
    "            g = fresh_iter()\n",
    "            continue                          # start over\n",
    "\n",
    "        if x1.shape[0] != BATCH:              # short final batch → skip\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            x2, y2 = next(g)\n",
    "        except StopIteration:\n",
    "            g = fresh_iter()\n",
    "            continue\n",
    "\n",
    "        if x2.shape[0] != BATCH:\n",
    "            continue\n",
    "\n",
    "        lam     = np.random.beta(alpha, alpha, size=BATCH)\n",
    "        lam_x   = lam.reshape(BATCH, 1, 1, 1)\n",
    "        lam_y   = lam.reshape(BATCH, 1)\n",
    "\n",
    "        yield x1 * lam_x + x2 * (1 - lam_x), y1 * lam_y + y2 * (1 - lam_y)\n",
    "\n",
    "# ----- validation generator (unchanged) -----\n",
    "val_gen = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    class_mode=\"categorical\", target_size=IMG_SZ,\n",
    "    batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# 1 MixUp step consumes 2 physical batches, so we divide by 2\n",
    "PHYSICAL_STEPS = math.ceil(len(train_df_bal) / BATCH)\n",
    "STEPS_FULL     = math.ceil(PHYSICAL_STEPS / 2)      # logical “epochs”\n",
    "VAL_STEPS      = math.ceil(len(val_df) / BATCH)\n",
    "\n",
    "# =========================================================\n",
    "# 4. FOCAL-LOSS (auto α)  +  γ-SWEEP\n",
    "# ---------------------------------------------------------\n",
    "freq       = train_df_bal[\"label\"].value_counts().loc[LABELS]\n",
    "alpha_vec  = tf.constant(np.median(freq) / freq, dtype=tf.float32)\n",
    "SMOOTH     = 0.05\n",
    "\n",
    "def focal_auto(gamma):\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = y_true * (1 - SMOOTH) + SMOOTH / N_CLASS       # label-smoothing\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "        ce  = -y_true * tf.math.log(y_pred)\n",
    "        fl  = tf.pow(1 - y_pred, gamma) * ce * alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "    return _loss\n",
    "\n",
    "# =========================================================\n",
    "# 5. MODEL UTILITIES\n",
    "# ---------------------------------------------------------\n",
    "def build_head(base):\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    return Dense(N_CLASS, activation='softmax')(x)\n",
    "\n",
    "def macro_f1_from_logits(logits, y_true):\n",
    "    y_hat = np.argmax(logits, 1)\n",
    "    cm = confusion_matrix(y_true, y_hat, labels=np.arange(N_CLASS))\n",
    "    prec = np.diag(cm) / (cm.sum(0)+1e-7)\n",
    "    rec  = np.diag(cm) / (cm.sum(1)+1e-7)\n",
    "    f1   = 2*prec*rec / (prec+rec+1e-7)\n",
    "    return np.nanmean(f1)\n",
    "\n",
    "# =========================================================\n",
    "# 6. γ-SWEEP +  PROGRESSIVE UNFREEZE\n",
    "# ---------------------------------------------------------\n",
    "GAMMA_LIST = [1, 2, 3]\n",
    "best_f1, best_gamma, best_model = -np.inf, None, None\n",
    "\n",
    "for γ in GAMMA_LIST:\n",
    "    print(f\"\\n================ γ = {γ} =================\")\n",
    "    tf.keras.backend.clear_session(); gc.collect()\n",
    "\n",
    "    # fresh MixUp iterator each sweep\n",
    "    train_gen = mixup_gen(train_df_bal, base_aug, alpha=0.4)\n",
    "\n",
    "    base = ResNet50(include_top=False, weights=\"imagenet\",\n",
    "                    input_tensor=Input(shape=IMG_SZ + (3,)))\n",
    "\n",
    "    # ---------- Phase-1 : train new head ----------\n",
    "    base.trainable = False\n",
    "    model = Model(base.input, build_head(base))\n",
    "    model.compile(Adam(1e-3), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(train_gen, steps_per_epoch=STEPS_FULL,\n",
    "              validation_data=val_gen, validation_steps=VAL_STEPS,\n",
    "              epochs=6, verbose=1,\n",
    "              callbacks=[EarlyStopping(patience=2, restore_best_weights=True)])\n",
    "\n",
    "    # ---------- Phase-2 : unfreeze last 70 ----------\n",
    "    for l in base.layers[-70:]: l.trainable = True\n",
    "    model.compile(Adam(3e-5), loss=focal_auto(γ), metrics=[\"accuracy\"])\n",
    "    model.fit(train_gen, steps_per_epoch=STEPS_FULL,\n",
    "              validation_data=val_gen, validation_steps=VAL_STEPS,\n",
    "              epochs=10, verbose=1,\n",
    "              callbacks=[EarlyStopping(patience=3, restore_best_weights=True),\n",
    "                         ReduceLROnPlateau(patience=2, factor=0.5)])\n",
    "\n",
    "    # ---------- Phase-3 : unfreeze last 140 ----------\n",
    "    for l in base.layers[-140:]: l.trainable = True\n",
    "    model.compile(Adam(1e-5), loss=focal_auto(γ), metrics=[\"accuracy\"])\n",
    "    model.fit(train_gen, steps_per_epoch=STEPS_FULL,\n",
    "              validation_data=val_gen, validation_steps=VAL_STEPS,\n",
    "              epochs=10, verbose=1,\n",
    "              callbacks=[EarlyStopping(patience=3, restore_best_weights=True),\n",
    "                         ReduceLROnPlateau(patience=2, factor=0.5)])\n",
    "\n",
    "    # quick F1 on raw validation logits\n",
    "    val_logits = model.predict(val_gen, steps=VAL_STEPS, verbose=0)\n",
    "    f1 = macro_f1_from_logits(val_logits, val_gen.classes)\n",
    "    print(f\"→ macro-F1 = {f1:.4f}\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_model, best_gamma = f1, model, γ\n",
    "\n",
    "print(f\"\\nBest γ = {best_gamma}   macro-F1 = {best_f1:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 7. SAVE BEST CHECKPOINT\n",
    "# ---------------------------------------------------------\n",
    "best_model.save(\"best_sheep_model.h5\")\n",
    "\n",
    "# =========================================================\n",
    "# 8. FINAL EVALUATION  ( TTA = 8 )\n",
    "# ---------------------------------------------------------\n",
    "def tta_logits(model, df, n_aug=8):\n",
    "    out = np.zeros((len(df), N_CLASS))\n",
    "    for _ in range(n_aug):\n",
    "        tta_gen = base_aug.flow_from_dataframe(\n",
    "            df, x_col=\"file_path\", y_col=None, shuffle=False,\n",
    "            target_size=IMG_SZ, batch_size=BATCH, class_mode=None,\n",
    "            seed=random.randint(0, 9999))\n",
    "        out += model.predict(tta_gen, verbose=0)\n",
    "    return out / n_aug\n",
    "\n",
    "val_logits = tta_logits(best_model, val_df)\n",
    "macro_f1   = macro_f1_from_logits(val_logits, val_df[\"label_idx\"].values)\n",
    "\n",
    "print(\"\\n=== FINAL REPORT (TTA)  —  macro-F1 {:.3f} ===\".format(macro_f1))\n",
    "print(classification_report(val_df[\"label_idx\"], np.argmax(val_logits,1),\n",
    "                            target_names=LABELS, digits=2))\n",
    "\n",
    "cm = confusion_matrix(val_df[\"label_idx\"], np.argmax(val_logits,1))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Confusion matrix (TTA)\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed741341-1164-481c-957d-27cb2b2135f3",
   "metadata": {},
   "source": [
    "# Advance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cab66b0-2f59-4a96-9dba-f233cfd4d558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.17.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (EarlyStopping, ReduceLROnPlateau,\n\u001b[1;32m     15\u001b[0m                                         LearningRateScheduler)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m         \u001b[38;5;66;03m# ← ArcFace & MultiOptimizer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m _check_tf_version()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/activations/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgelu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhardshrink\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlisht\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lisht\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/activations/gelu.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow_addons/utils/types.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# importing internal symbols.\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0.  IMPORTS  &  GLOBALS\n",
    "# ---------------------------------------------------------\n",
    "import os, random, math, gc, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dropout,\n",
    "                                     Dense, BatchNormalization, Lambda)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                        LearningRateScheduler)\n",
    "import tensorflow_addons as tfa         # ← ArcFace & MultiOptimizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "SEED = 42\n",
    "BATCH = 32\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 1.  LOAD  &  BALANCE  DATA   (down-sample, not over-sample)\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "LABELS  = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "N_CLASS = len(LABELS)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "        df, test_size=0.20, stratify=df[\"label_idx\"], random_state=SEED)\n",
    "\n",
    "TARGET = 180                        # keep **max** 180 per class\n",
    "balanced = (train_df.groupby(\"label\", group_keys=False)\n",
    "                      .apply(lambda g: g.sample(min(len(g), TARGET),\n",
    "                                                 random_state=SEED)))\n",
    "train_df_bal = balanced.sample(frac=1, random_state=SEED)   # shuffle\n",
    "\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 2.  AUGMENTERS  &  GENERATOR FACTORIES\n",
    "# ---------------------------------------------------------\n",
    "def make_aug(img_size):\n",
    "    return ImageDataGenerator(\n",
    "        rescale=1/255.,\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.15, height_shift_range=0.15,\n",
    "        zoom_range=0.20, brightness_range=[0.8,1.2],\n",
    "        horizontal_flip=True)\n",
    "\n",
    "val_aug = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "def make_gen(df, aug, img_size, shuffle):\n",
    "    return aug.flow_from_dataframe(\n",
    "            df, x_col=\"file_path\", y_col=\"label\",\n",
    "            target_size=img_size, batch_size=BATCH,\n",
    "            class_mode=\"categorical\", shuffle=shuffle, seed=SEED)\n",
    "\n",
    "# ---------- Late, **small** MixUp (α = 0.15) -------------\n",
    "def mixup_gen(base_gen, alpha=0.15):\n",
    "    while True:\n",
    "        x1, y1 = next(base_gen)\n",
    "        x2, y2 = next(base_gen)\n",
    "        lam = np.random.beta(alpha, alpha, size=BATCH)\n",
    "        lam_x = lam.reshape(BATCH,1,1,1); lam_y = lam.reshape(BATCH,1)\n",
    "        yield x1*lam_x + x2*(1-lam_x), y1*lam_y + y2*(1-lam_y)\n",
    "\n",
    "# =========================================================\n",
    "# 3.  FOCAL-LOSS  (auto-α)  +  ARC-FACE HEAD\n",
    "# ---------------------------------------------------------\n",
    "freq      = train_df_bal[\"label\"].value_counts().loc[LABELS]\n",
    "alpha_vec = tf.constant(np.median(freq)/freq, dtype=tf.float32)\n",
    "SMOOTH    = 0.05\n",
    "\n",
    "def focal_auto(gamma=2.):\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = y_true*(1-SMOOTH) + SMOOTH/N_CLASS\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "        ce  = -y_true * tf.math.log(y_pred)\n",
    "        fl  = tf.pow(1-y_pred, gamma) * ce * alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "    return _loss\n",
    "\n",
    "def build_model(img_size):\n",
    "    inp  = Input(shape=img_size+(3,))\n",
    "    base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inp)\n",
    "    x    = GlobalAveragePooling2D()(base.output)\n",
    "    x    = BatchNormalization()(x)\n",
    "    x    = Dropout(0.5)(x)\n",
    "\n",
    "    # -------- ArcMargin head (adds angular margin) --------\n",
    "    logits = tfa.layers.ArcMarginProduct(num_classes=N_CLASS,\n",
    "                                         s=30, m=0.3,\n",
    "                                         regularizer=None)(x)\n",
    "\n",
    "    model = Model(inp, logits)     # logits; will use CE/Focal on them\n",
    "    return model, base\n",
    "\n",
    "# =========================================================\n",
    "# 4.  TRAINING  PIPELINE\n",
    "# ---------------------------------------------------------\n",
    "IMG1 = (224,224)\n",
    "IMG2 = (288,288)\n",
    "\n",
    "# ---------- Phase-A : CE warm-up (224 px) ---------------\n",
    "train_gen = make_gen(train_df_bal, make_aug(IMG1), IMG1, shuffle=True)\n",
    "val_gen   = make_gen(val_df,         val_aug,    IMG1, shuffle=False)\n",
    "\n",
    "model, base = build_model(IMG1)\n",
    "base.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_gen, epochs=10, validation_data=val_gen,\n",
    "          callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n",
    "          verbose=2)\n",
    "\n",
    "# ---------- Phase-B : unfreeze last 70  + focal-loss -----\n",
    "for l in base.layers[-70:]: l.trainable = True\n",
    "\n",
    "steps_per_epoch = math.ceil(len(train_df_bal)/BATCH)\n",
    "cosine = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "            initial_learning_rate=3e-5,\n",
    "            first_decay_steps=8*steps_per_epoch)\n",
    "\n",
    "# Discriminative LR  (head 3× faster)\n",
    "head_vars = model.layers[-1].trainable_variables\n",
    "back_vars = [v for v in model.trainable_variables if v not in head_vars]\n",
    "\n",
    "opt_head = Adam(cosine)             # LR schedule applied here\n",
    "opt_back = Adam(lambda step: cosine(step)/3)   # 3× smaller\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tfa.optimizers.MultiOptimizer(\n",
    "        [(opt_head, head_vars), (opt_back, back_vars)]),\n",
    "    loss=focal_auto(gamma=2),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_gen, epochs=12, validation_data=val_gen,\n",
    "          callbacks=[EarlyStopping(patience=4, restore_best_weights=True)],\n",
    "          verbose=2)\n",
    "\n",
    "# ---------- Phase-C : upscale images to 288 px ----------\n",
    "train_gen_big = make_gen(train_df_bal, make_aug(IMG2), IMG2, shuffle=True)\n",
    "val_gen_big   = make_gen(val_df,         val_aug,    IMG2, shuffle=False)\n",
    "\n",
    "model.fit(train_gen_big, epochs=8, validation_data=val_gen_big,\n",
    "          callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],\n",
    "          verbose=2)\n",
    "\n",
    "# ---------- Phase-D : 3 epochs **tiny** MixUp -----------\n",
    "mix_base = make_gen(train_df_bal, make_aug(IMG2), IMG2, shuffle=True)\n",
    "mix_gen  = mixup_gen(mix_base, alpha=0.15)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tfa.optimizers.MultiOptimizer(\n",
    "        [(opt_head, head_vars), (opt_back, back_vars)]),\n",
    "    loss=\"categorical_crossentropy\",      # back to CE for MixUp\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(mix_gen, steps_per_epoch=steps_per_epoch,\n",
    "          epochs=3, validation_data=val_gen_big, verbose=2)\n",
    "\n",
    "# =========================================================\n",
    "# 5.  FINAL  EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "val_logits = model.predict(val_gen_big, verbose=0)\n",
    "y_true = val_df[\"label_idx\"].values\n",
    "y_pred = np.argmax(val_logits,1)\n",
    "\n",
    "print(\"\\n=== FINAL REPORT ===\")\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS, digits=2))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Confusion matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed34eed8-bafd-4dbe-b1c7-722038e2dbe8",
   "metadata": {},
   "source": [
    "\n",
    "2\n",
    "down-sample instead of oversample\n",
    "removes near-duplicate sheep shots → cleaner gradients\n",
    "3\n",
    "progressive 224 → 288 px\n",
    "lets network first see coarse shapes, later wool texture\n",
    "4-A\n",
    "10-epoch CE warm-up\n",
    "stabilises features before focal-loss\n",
    "4-B\n",
    "cosine LR + discriminative LR\n",
    "smoother convergence; head learns 3× faster\n",
    "4-B\n",
    "ArcMargin (angular margin) head\n",
    "enforces larger class separation in embedding space\n",
    "4-D\n",
    "tiny MixUp after good features\n",
    "widens decision boundaries without washing them out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6475bc20-ec5b-41c2-89c4-59813e35a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c5b900-0cb6-4bed-8675-32ff412c30b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Barbari    200\n",
      "Goat       200\n",
      "Harri      200\n",
      "Najdi      200\n",
      "Roman      200\n",
      "Sawakni    200\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Found 137 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Layer.add_weight() got multiple values for argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 164\u001b[0m\n\u001b[1;32m    161\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model([inp,lbl],[out])\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base, model\n\u001b[0;32m--> 164\u001b[0m base, model \u001b[38;5;241m=\u001b[39m build_model(IMG_S)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# 7. TRAIN\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# two optims (head/backbone) with discriminative LR\u001b[39;00m\n\u001b[1;32m    170\u001b[0m opt_head \u001b[38;5;241m=\u001b[39m Adam(lr_fn(\u001b[38;5;241m0\u001b[39m))\n",
      "Cell \u001b[0;32mIn[4], line 158\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(img_size)\u001b[0m\n\u001b[1;32m    156\u001b[0m feat  \u001b[38;5;241m=\u001b[39m Lambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39ml2_normalize(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))(feat)\n\u001b[1;32m    157\u001b[0m lbl   \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(N_CLASS,))                         \u001b[38;5;66;03m# labels one-hot\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m feat_c\u001b[38;5;241m=\u001b[39m CenterLossLayer(N_CLASS,\u001b[38;5;241m256\u001b[39m)(feat,lbl)\n\u001b[1;32m    159\u001b[0m logits\u001b[38;5;241m=\u001b[39m ArcMarginProduct(N_CLASS)(feat_c,lbl,training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m out   \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(logits)                           \u001b[38;5;66;03m# probs for metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[4], line 107\u001b[0m, in \u001b[0;36mCenterLossLayer.build\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, _):\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m                                    shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat_dim),\n\u001b[1;32m    109\u001b[0m                                    initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Layer.add_weight() got multiple values for argument 'shape'"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0. IMPORTS  (pure-TF 2.17)\n",
    "# ---------------------------------------------------------\n",
    "import os, random, math, gc, warnings, numpy as np, pandas as pd\n",
    "import tensorflow as tf, matplotlib.pyplot as plt, seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense,\n",
    "                                     Dropout, Layer, Lambda)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 1. DATA  – load, stratify, balance\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "LABELS  = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "N_CLASS = len(LABELS)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=.2,\n",
    "                                    stratify=df[\"label_idx\"],\n",
    "                                    random_state=SEED)\n",
    "\n",
    "TARGET = 200\n",
    "train_df_bal = (train_df.groupby(\"label\", group_keys=False)\n",
    "                         .apply(lambda g: resample(g, replace=True,\n",
    "                                                   n_samples=max(TARGET,len(g)),\n",
    "                                                   random_state=SEED))\n",
    "                         .reset_index(drop=True))\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. AUGMENTATION – progressive size + late/small MixUp\n",
    "# ---------------------------------------------------------\n",
    "BATCH          = 32\n",
    "IMG_S          = (224,224)\n",
    "IMG_L          = (256,256)\n",
    "MIXUP_ALPHA    = .2\n",
    "MIXUP_DELAY_EP = 3\n",
    "\n",
    "base_aug = ImageDataGenerator(\n",
    "        rescale=1/255., rotation_range=25,\n",
    "        width_shift_range=.15, height_shift_range=.15,\n",
    "        zoom_range=.2, brightness_range=[.8,1.2],\n",
    "        horizontal_flip=True)\n",
    "val_aug  = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "def mixup_iter(df, img_size):\n",
    "    g = base_aug.flow_from_dataframe(\n",
    "            df, x_col=\"file_path\", y_col=\"label\",\n",
    "            class_mode=\"categorical\", target_size=img_size,\n",
    "            batch_size=BATCH, shuffle=True, seed=SEED)\n",
    "    ep = 0\n",
    "    while True:\n",
    "        x1,y1 = next(g)\n",
    "        if ep < MIXUP_DELAY_EP:\n",
    "            yield x1,y1\n",
    "        else:\n",
    "            x2,y2 = next(g)\n",
    "            lam = np.random.beta(MIXUP_ALPHA,MIXUP_ALPHA, size=BATCH)\n",
    "            lam_x = lam.reshape(BATCH,1,1,1); lam_y = lam.reshape(BATCH,1)\n",
    "            yield x1*lam_x + x2*(1-lam_x), y1*lam_y + y2*(1-lam_y)\n",
    "        ep += 1\n",
    "\n",
    "val_gen = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    class_mode=\"categorical\", target_size=IMG_L,\n",
    "    batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# =========================================================\n",
    "# 3. CUSTOM  ArcMarginProduct  +  Center-loss layer\n",
    "# ---------------------------------------------------------\n",
    "class ArcMarginProduct(Layer):\n",
    "    \"\"\"Implements the ArcFace / CosFace style margin in logits.\"\"\"\n",
    "    def __init__(self, n_classes, s=30., m=.5, **kw):\n",
    "        super().__init__(**kw); self.n_classes, self.s, self.m = n_classes,s,m\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\"W\", shape=(input_shape[-1], self.n_classes),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "    def call(self, inputs, labels, training=False):\n",
    "        x = tf.nn.l2_normalize(inputs, axis=1)\n",
    "        W = tf.nn.l2_normalize(self.W,      axis=0)\n",
    "        cos  = tf.matmul(x, W)                                # [B,C]\n",
    "        if training:\n",
    "            theta = tf.acos(tf.clip_by_value(cos,-1+1e-5,1-1e-5))\n",
    "            target_logits = tf.cos(theta + self.m)\n",
    "            cos = cos*(1-labels) + target_logits*labels       # replace only GT class\n",
    "        return self.s * cos\n",
    "\n",
    "class CenterLossLayer(Layer):\n",
    "    def __init__(self, n_classes, feat_dim, alpha=0.5, **kw):\n",
    "        super().__init__(**kw); self.n_classes,self.feat_dim,self.alpha= n_classes, feat_dim, alpha\n",
    "    def build(self, _):\n",
    "        self.centers = self.add_weight(\"centers\",\n",
    "                                       shape=(self.n_classes, self.feat_dim),\n",
    "                                       initializer=\"zeros\", trainable=False)\n",
    "    def call(self, features, labels):\n",
    "        # update centres\n",
    "        labels_idx = tf.argmax(labels,1)\n",
    "        centers_batch = tf.gather(self.centers, labels_idx)\n",
    "        diff = centers_batch - features\n",
    "        self.add_update(tf.scatter_sub(self.centers, labels_idx,\n",
    "                                       self.alpha*diff))\n",
    "        # add centre-loss term\n",
    "        self.add_loss(tf.reduce_mean(tf.square(diff))*0.003)  # centre-loss λ=0.003\n",
    "        return features\n",
    "\n",
    "# =========================================================\n",
    "# 4. Focal-loss  (auto-α + label-smooth)  same as before\n",
    "# ---------------------------------------------------------\n",
    "freq       = train_df_bal[\"label\"].value_counts().loc[LABELS]\n",
    "alpha_vec  = tf.constant(np.median(freq)/freq, dtype=tf.float32)\n",
    "SMOOTH=.05\n",
    "def focal_loss(gamma=2.):\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = y_true*(1-SMOOTH)+SMOOTH/N_CLASS\n",
    "        y_pred = tf.clip_by_value(y_pred,1e-7,1-1e-7)\n",
    "        ce=-y_true*tf.math.log(y_pred)\n",
    "        fl=tf.pow(1-y_pred,gamma)*ce*alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl,axis=1))\n",
    "    return _loss\n",
    "\n",
    "# =========================================================\n",
    "# 5. Cosine-decay LR with warm-up\n",
    "# ---------------------------------------------------------\n",
    "INIT_LR=3e-4; WARM_E=2; TOTAL_E=20\n",
    "def lr_fn(epoch):\n",
    "    if epoch < WARM_E: return INIT_LR*(epoch+1)/WARM_E\n",
    "    cos=0.5*(1+math.cos(math.pi*(epoch-WARM_E)/(TOTAL_E-WARM_E)))\n",
    "    return 1e-6 + (INIT_LR-1e-6)*cos\n",
    "lr_cb=LearningRateScheduler(lr_fn,verbose=0)\n",
    "\n",
    "# =========================================================\n",
    "# 6. BUILD MODEL  (224 → 256 progressive size)\n",
    "# ---------------------------------------------------------\n",
    "def build_model(img_size):\n",
    "    inp   = Input(shape=img_size+(3,))\n",
    "    base  = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inp)\n",
    "    base.trainable=False\n",
    "    feat  = GlobalAveragePooling2D()(base.output)           # 2048-D\n",
    "    feat  = Dropout(.4)(feat)\n",
    "    feat  = Dense(256, activation='relu')(feat)             # embedding\n",
    "    feat  = Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))(feat)\n",
    "    lbl   = Input(shape=(N_CLASS,))                         # labels one-hot\n",
    "    feat_c= CenterLossLayer(N_CLASS,256)(feat,lbl)\n",
    "    logits= ArcMarginProduct(N_CLASS)(feat_c,lbl,training=True)\n",
    "    out   = tf.nn.softmax(logits)                           # probs for metrics\n",
    "    model = Model([inp,lbl],[out])\n",
    "    return base, model\n",
    "\n",
    "base, model = build_model(IMG_S)\n",
    "\n",
    "# =========================================================\n",
    "# 7. TRAIN\n",
    "# ---------------------------------------------------------\n",
    "# two optims (head/backbone) with discriminative LR\n",
    "opt_head = Adam(lr_fn(0))\n",
    "opt_back = Adam(lr_fn(0)*0.1)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model([images,labels], training=True)[0]\n",
    "        loss  = focal_loss()(labels, preds) + sum(model.losses)  # focal+centre\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    head_vars = [v for v in model.trainable_weights if 'dense' in v.name]  # embedding + Arc weights\n",
    "    base_vars = [v for v in model.trainable_weights if v not in head_vars]\n",
    "    opt_head.apply_gradients(zip([g for g,v in zip(grads,model.trainable_weights) if v in head_vars], head_vars))\n",
    "    opt_back.apply_gradients(zip([g for g,v in zip(grads,model.trainable_weights) if v in base_vars], base_vars))\n",
    "    return loss\n",
    "\n",
    "# ---- Stage-1: head only, no MixUp, 224 ----------\n",
    "steps_small = math.ceil(len(train_df_bal)/BATCH)\n",
    "plain_gen   = mixup_iter(train_df_bal, IMG_S)  # MixUp α>0 but delay > epoch count\n",
    "for epoch in range(3):\n",
    "    for _ in range(steps_small):\n",
    "        imgs,lbls = next(plain_gen)\n",
    "        train_step(imgs,lbls)\n",
    "    print(f\"head-train Epoch {epoch+1}/3 done\")\n",
    "\n",
    "# ---- Stage-2: unfreeze last 70, 256, MixUp ----------\n",
    "for l in base.layers[-70:]: l.trainable=True\n",
    "\n",
    "steps_large = math.ceil(len(train_df_bal)/BATCH//2)\n",
    "mix_gen     = mixup_iter(train_df_bal, IMG_L)\n",
    "for epoch in range(TOTAL_E):\n",
    "    # update LR\n",
    "    lr = lr_fn(epoch)\n",
    "    opt_head.lr.assign(lr); opt_back.lr.assign(lr*0.1)\n",
    "\n",
    "    for _ in range(steps_large):\n",
    "        imgs,lbls = next(mix_gen)\n",
    "        train_step(imgs,lbls)\n",
    "\n",
    "    # quick val acc\n",
    "    preds = model.predict([val_gen.x, val_gen.y], verbose=0)[0]\n",
    "    acc = (preds.argmax(1)==val_gen.classes).mean()\n",
    "    print(f\"fine-tune {epoch+1}/{TOTAL_E} – val-acc {acc:.3f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 8. FINAL REPORT\n",
    "# ---------------------------------------------------------\n",
    "preds = model.predict([val_gen.x, val_gen.y], verbose=0)[0]\n",
    "print(classification_report(val_gen.classes, preds.argmax(1),\n",
    "                            target_names=LABELS, digits=2))\n",
    "cm = confusion_matrix(val_gen.classes, preds.argmax(1))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554526e3-e015-4529-b441-2e57765870ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.11/site-packages (3.5.0)\n",
      "Collecting keras\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.5.0\n",
      "    Uninstalling keras-3.5.0:\n",
      "      Successfully uninstalled keras-3.5.0\n",
      "Successfully installed keras-3.10.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09a377b-16dc-4927-bdc3-52a1c0099f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Barbari    200\n",
      "Goat       200\n",
      "Harri      200\n",
      "Najdi      200\n",
      "Roman      200\n",
      "Sawakni    200\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n",
      "Found 137 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling CenterLossLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'centerloss' (of type CenterLossLayer). Either the `CenterLossLayer.call()` method is incorrect, or you need to implement the `CenterLossLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\n'CenterLossLayer' object has no attribute 'add_update'\u001b[0m\n\nArguments received by CenterLossLayer.call():\n  • args=('<KerasTensor shape=(None, 256), dtype=float32, sparse=False, name=keras_tensor_178>', '<KerasTensor shape=(None, 7), dtype=float32, sparse=False, name=keras_tensor_1>')\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 156\u001b[0m\n\u001b[1;32m    153\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model([inp, lbl], out)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base, model\n\u001b[0;32m--> 156\u001b[0m base, model \u001b[38;5;241m=\u001b[39m build_model(IMG_SZ)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# 5. COSINE LR  (with 5-epoch warm-up)\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    161\u001b[0m EPOCHS_PHASE2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 149\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(img_size)\u001b[0m\n\u001b[1;32m    146\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m)(x)\n\u001b[1;32m    147\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m--> 149\u001b[0m x  \u001b[38;5;241m=\u001b[39m CenterLossLayer(N_CLASS, \u001b[38;5;241m256\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenterloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x, lbl)\n\u001b[1;32m    150\u001b[0m logits \u001b[38;5;241m=\u001b[39m ArcMarginProduct(N_CLASS, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marcface\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x, lbl)\n\u001b[1;32m    151\u001b[0m out    \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(logits)          \u001b[38;5;66;03m# for accuracy / metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[6], line 107\u001b[0m, in \u001b[0;36mCenterLossLayer.call\u001b[0;34m(self, feats, labels)\u001b[0m\n\u001b[1;32m    105\u001b[0m batch_centers \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenters)\n\u001b[1;32m    106\u001b[0m diff \u001b[38;5;241m=\u001b[39m feats \u001b[38;5;241m-\u001b[39m batch_centers\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_update(\n\u001b[1;32m    108\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39massign_sub(\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenters,\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(tf\u001b[38;5;241m.\u001b[39mtranspose(labels),\n\u001b[1;32m    111\u001b[0m                                diff) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mtf\u001b[38;5;241m.\u001b[39mreduce_sum(labels,\u001b[38;5;241m0\u001b[39m,keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))))\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feats\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling CenterLossLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'centerloss' (of type CenterLossLayer). Either the `CenterLossLayer.call()` method is incorrect, or you need to implement the `CenterLossLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\n'CenterLossLayer' object has no attribute 'add_update'\u001b[0m\n\nArguments received by CenterLossLayer.call():\n  • args=('<KerasTensor shape=(None, 256), dtype=float32, sparse=False, name=keras_tensor_178>', '<KerasTensor shape=(None, 7), dtype=float32, sparse=False, name=keras_tensor_1>')\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0. IMPORTS & GLOBALS\n",
    "# ---------------------------------------------------------\n",
    "import os, random, math, gc, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense,\n",
    "                                     Dropout, Layer, Lambda)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "SEED = 42\n",
    "IMG_SZ = (224, 224)\n",
    "BATCH = 32\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# =========================================================\n",
    "# 1. DATA (uniform up-sample to 200 each)\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "LABELS  = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "N_CLASS = len(LABELS)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2,\n",
    "                                    stratify=df[\"label_idx\"], random_state=SEED)\n",
    "\n",
    "TARGET = 200\n",
    "train_df_bal = pd.concat([\n",
    "    resample(g, replace=True, n_samples=TARGET, random_state=SEED)\n",
    "    if len(g) < TARGET else g\n",
    "    for _, g in train_df.groupby(\"label\")]).reset_index(drop=True)\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. AUGMENTATION (no MixUp by default)\n",
    "# ---------------------------------------------------------\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1/255., rotation_range=25,\n",
    "    width_shift_range=0.15, height_shift_range=0.15,\n",
    "    zoom_range=0.20, brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_aug   = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_gen = train_aug.flow_from_dataframe(\n",
    "    train_df_bal, x_col=\"file_path\", y_col=\"label\",\n",
    "    class_mode=\"categorical\", target_size=IMG_SZ,\n",
    "    batch_size=BATCH, shuffle=True, seed=SEED)\n",
    "\n",
    "val_gen   = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    class_mode=\"categorical\", target_size=IMG_SZ,\n",
    "    batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# steps\n",
    "STEPS = math.ceil(len(train_df_bal)/BATCH)\n",
    "VAL_STEPS = math.ceil(len(val_df)/BATCH)\n",
    "\n",
    "# =========================================================\n",
    "# 3. LOSSES\n",
    "# ---------------------------------------------------------\n",
    "# focal-loss with automatic per-class α\n",
    "freq        = train_df_bal[\"label\"].value_counts().loc[LABELS]\n",
    "alpha_vec   = tf.constant(np.median(freq)/freq, dtype=tf.float32)\n",
    "SMOOTH      = 0.05\n",
    "def focal_auto(gamma=2.):\n",
    "    def _loss(y_true, y_pred):\n",
    "        y_true = y_true*(1-SMOOTH) + SMOOTH/N_CLASS\n",
    "        y_pred = tf.clip_by_value(y_pred,1e-7,1-1e-7)\n",
    "        ce = -y_true*tf.math.log(y_pred)\n",
    "        fl = tf.pow(1-y_pred,gamma)*ce*alpha_vec\n",
    "        return tf.reduce_mean(tf.reduce_sum(fl,axis=-1))\n",
    "    return _loss\n",
    "\n",
    "# -------- Center‐loss layer (fixed add_weight) ------------\n",
    "class CenterLossLayer(Layer):\n",
    "    def __init__(self, n_classes, feat_dim, alpha=0.5, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.n_classes, self.feat_dim, self.alpha = n_classes, feat_dim, alpha\n",
    "    def build(self, _):\n",
    "        self.centers = self.add_weight(\n",
    "            shape=(self.n_classes, self.feat_dim),\n",
    "            name=\"centers\",\n",
    "            initializer=\"zeros\",\n",
    "            trainable=False)\n",
    "    def call(self, feats, labels):\n",
    "        # feats L2-norm\n",
    "        feats = tf.nn.l2_normalize(feats, axis=1)\n",
    "        batch_centers = tf.matmul(labels, self.centers)\n",
    "        diff = feats - batch_centers\n",
    "        self.add_update(\n",
    "            tf.compat.v1.assign_sub(\n",
    "                self.centers,\n",
    "                self.alpha * tf.matmul(tf.transpose(labels),\n",
    "                                       diff) / (1+tf.reduce_sum(labels,0,keepdims=True))))\n",
    "        return feats  # pass through for ArcFace\n",
    "\n",
    "# -------- ArcMargin (ArcFace) -----------------------------\n",
    "class ArcMarginProduct(Layer):\n",
    "    def __init__(self, n_classes, s=30.0, m=0.50, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.n_classes, self.s, self.m = n_classes, s, m\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            shape=(input_shape[-1], self.n_classes),\n",
    "            name=\"arcface_W\",\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=True)\n",
    "    def call(self, feats, labels, training=True):\n",
    "        # feats already L2-norm\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        cos = tf.matmul(feats, W)\n",
    "        if training:\n",
    "            theta = tf.acos(tf.clip_by_value(cos, -1+1e-7, 1-1e-7))\n",
    "            cos_m = tf.cos(theta + self.m)\n",
    "            cos = cos*(1-labels) + cos_m*labels\n",
    "        return self.s * cos\n",
    "\n",
    "# =========================================================\n",
    "# 4. MODEL\n",
    "# ---------------------------------------------------------\n",
    "def build_model(img_size):\n",
    "    inp = Input((*img_size,3))\n",
    "    lbl = Input((N_CLASS,))                 # one-hot labels (only used in training)\n",
    "\n",
    "    base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inp)\n",
    "    for layer in base.layers: layer.trainable = False   # freeze first\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    x  = CenterLossLayer(N_CLASS, 256, name=\"centerloss\")(x, lbl)\n",
    "    logits = ArcMarginProduct(N_CLASS, name=\"arcface\")(x, lbl)\n",
    "    out    = tf.nn.softmax(logits)          # for accuracy / metrics\n",
    "\n",
    "    model = Model([inp, lbl], out)\n",
    "    return base, model\n",
    "\n",
    "base, model = build_model(IMG_SZ)\n",
    "\n",
    "# =========================================================\n",
    "# 5. COSINE LR  (with 5-epoch warm-up)\n",
    "# ---------------------------------------------------------\n",
    "EPOCHS_PHASE2 = 20\n",
    "def lr_fn(epoch):\n",
    "    warm = 5\n",
    "    base_lr = 3e-5\n",
    "    if epoch < warm:\n",
    "        return base_lr * (epoch+1)/warm\n",
    "    # cosine decay\n",
    "    cosine = 0.5*(1 + tf.math.cos(math.pi*(epoch-warm)/(EPOCHS_PHASE2-warm)))\n",
    "    return base_lr*cosine\n",
    "\n",
    "# =========================================================\n",
    "# 6. OPTIMIZERS  (discriminative LR)\n",
    "# ---------------------------------------------------------\n",
    "opt_head  = Adam( lr_fn(0) )          # higher LR for new layers\n",
    "opt_back  = Adam( lr_fn(0)/10 )       # 10× smaller for backbone\n",
    "\n",
    "# Keras’ built-in MultiOptimizer (TF-2.15+) — fallback if unavailable\n",
    "try:\n",
    "    from keras.optimizers import MultiOptimizer\n",
    "    optim = MultiOptimizer([\n",
    "        (opt_back , base.trainable_variables),\n",
    "        (opt_head , [v for v in model.trainable_variables\n",
    "                     if v not in base.trainable_variables])])\n",
    "except Exception:\n",
    "    # simple manual grouping\n",
    "    optim = Adam( lr_fn(0) )\n",
    "\n",
    "# compile with joint loss: focal + λ*center-loss\n",
    "LAMBDA_CENTER = 0.5\n",
    "def total_loss(y_true,y_pred):\n",
    "    fl = focal_auto()(y_true, y_pred)\n",
    "    # grab centerloss added to model.losses[0]\n",
    "    return fl + LAMBDA_CENTER * tf.add_n(model.losses)\n",
    "\n",
    "model.compile(optimizer=optim, loss=total_loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# =========================================================\n",
    "# 7. TRAIN  (head-only first, then progressive unfreeze)\n",
    "# ---------------------------------------------------------\n",
    "# Phase-1 : train head only (freeze backbone)\n",
    "model.fit([train_gen.x, train_gen.y], train_gen.y,\n",
    "          steps_per_epoch=STEPS, epochs=3, verbose=2)\n",
    "\n",
    "# unfreeze last 70\n",
    "for l in base.layers[-70:]: l.trainable = True\n",
    "\n",
    "model.compile(optimizer=optim, loss=total_loss, metrics=[\"accuracy\"])\n",
    "model.fit([train_gen.x, train_gen.y], train_gen.y,\n",
    "          steps_per_epoch=STEPS, validation_data=val_gen,\n",
    "          epochs=EPOCHS_PHASE2, verbose=2,\n",
    "          callbacks=[LearningRateScheduler(lr_fn),\n",
    "                     EarlyStopping(patience=4, restore_best_weights=True)])\n",
    "\n",
    "# =========================================================\n",
    "# 8. EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "val_logits = model.predict([val_gen.x, val_gen.y], verbose=0)\n",
    "y_pred = np.argmax(val_logits,1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS, digits=2))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Confusion matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b6fdcb-2a38-4a61-bbd4-38f5c954c8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Roman      200\n",
      "Harri      200\n",
      "Najdi      200\n",
      "Goat       200\n",
      "Barbari    200\n",
      "Sawakni    200\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n",
      "Found 137 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling CenterLossLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'centerloss' (of type CenterLossLayer). Either the `CenterLossLayer.call()` method is incorrect, or you need to implement the `CenterLossLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimensions must be equal, but are 256 and 7 for '{{node truediv}} = RealDiv[T=DT_FLOAT](MatMul_1, add)' with input shapes: [7,256], [1,7].\u001b[0m\n\nArguments received by CenterLossLayer.call():\n  • args=('<KerasTensor shape=(None, 256), dtype=float32, sparse=False, name=keras_tensor_178>', '<KerasTensor shape=(None, 7), dtype=float32, sparse=False, name=keras_tensor_1>')\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 167\u001b[0m\n\u001b[1;32m    164\u001b[0m     model  \u001b[38;5;241m=\u001b[39m Model([inp, lbl], out, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSheepID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base, model\n\u001b[0;32m--> 167\u001b[0m base, model \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# 6. DISCRIMINATIVE LR + COSINE DECAY\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    172\u001b[0m EPOCHS_H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 160\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m Dropout(\u001b[38;5;241m0.5\u001b[39m)(x)\n\u001b[1;32m    158\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m--> 160\u001b[0m x  \u001b[38;5;241m=\u001b[39m CenterLossLayer(N_CLASS, \u001b[38;5;241m256\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenterloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x, lbl)\n\u001b[1;32m    161\u001b[0m logits \u001b[38;5;241m=\u001b[39m ArcMarginProduct(N_CLASS, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marcface\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x, lbl, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    162\u001b[0m out    \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(logits)          \u001b[38;5;66;03m# for metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[7], line 97\u001b[0m, in \u001b[0;36mCenterLossLayer.call\u001b[0;34m(self, feats, labels)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# -------- update centers --------\u001b[39;00m\n\u001b[1;32m     96\u001b[0m label_cnt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m---> 97\u001b[0m centers_delta \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmatmul(tf\u001b[38;5;241m.\u001b[39mtranspose(labels), diff) \u001b[38;5;241m/\u001b[39m label_cnt\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenters\u001b[38;5;241m.\u001b[39massign_sub(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m centers_delta)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# -------- add center loss --------\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling CenterLossLayer.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'centerloss' (of type CenterLossLayer). Either the `CenterLossLayer.call()` method is incorrect, or you need to implement the `CenterLossLayer.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimensions must be equal, but are 256 and 7 for '{{node truediv}} = RealDiv[T=DT_FLOAT](MatMul_1, add)' with input shapes: [7,256], [1,7].\u001b[0m\n\nArguments received by CenterLossLayer.call():\n  • args=('<KerasTensor shape=(None, 256), dtype=float32, sparse=False, name=keras_tensor_178>', '<KerasTensor shape=(None, 7), dtype=float32, sparse=False, name=keras_tensor_1>')\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0. IMPORTS & GLOBALS\n",
    "# ---------------------------------------------------------\n",
    "import os, random, math, gc, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dropout,\n",
    "                                     Dense, Lambda, Layer)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                        LearningRateScheduler)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# ---------- reproducibility ----------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "\n",
    "# =========================================================\n",
    "# 1. DATAFRAME & BALANCING\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "LABELS  = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "N_CLASS = len(LABELS)\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.20, stratify=df[\"label_idx\"], random_state=SEED)\n",
    "\n",
    "TARGET = 200\n",
    "train_df_bal = (\n",
    "    train_df.groupby(\"label\", group_keys=False)\n",
    "            .apply(lambda g: g if len(g) >= TARGET\n",
    "                              else resample(g, replace=True,\n",
    "                                            n_samples=TARGET, random_state=SEED))\n",
    "            .sample(frac=1, random_state=SEED)           # shuffle\n",
    "            .reset_index(drop=True)\n",
    ")\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. AUGMENTATION\n",
    "# ---------------------------------------------------------\n",
    "BATCH  = 32\n",
    "IMG_SZ = (224, 224)\n",
    "\n",
    "train_aug = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15, height_shift_range=0.15,\n",
    "    zoom_range=0.20, brightness_range=[0.8,1.2],\n",
    "    horizontal_flip=True)\n",
    "val_aug = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_gen = train_aug.flow_from_dataframe(\n",
    "    train_df_bal, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=IMG_SZ, batch_size=BATCH,\n",
    "    class_mode=\"categorical\", shuffle=True, seed=SEED)\n",
    "val_gen = val_aug.flow_from_dataframe(\n",
    "    val_df, x_col=\"file_path\", y_col=\"label\",\n",
    "    target_size=IMG_SZ, batch_size=BATCH,\n",
    "    class_mode=\"categorical\", shuffle=False)\n",
    "\n",
    "# =========================================================\n",
    "# 3. CUSTOM LOSSES / LAYERS  (Keras-3 compatible)\n",
    "# ---------------------------------------------------------\n",
    "class CenterLossLayer(Layer):\n",
    "    def __init__(self, n_classes, feat_dim, alpha=0.5, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.n_classes, self.feat_dim, self.alpha = n_classes, feat_dim, alpha\n",
    "\n",
    "    def build(self, _):\n",
    "        self.centers = self.add_weight(\n",
    "            name=\"centers\",\n",
    "            shape=(self.n_classes, self.feat_dim),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=False)\n",
    "\n",
    "    def call(self, feats, labels):\n",
    "        # labels are one-hot\n",
    "        batch_centers = tf.matmul(labels, self.centers)\n",
    "        diff          = feats - batch_centers\n",
    "\n",
    "        # -------- update centers --------\n",
    "        label_cnt = tf.reduce_sum(labels, axis=0, keepdims=True) + 1e-6\n",
    "        centers_delta = tf.matmul(tf.transpose(labels), diff) / label_cnt\n",
    "        self.centers.assign_sub(self.alpha * centers_delta)\n",
    "\n",
    "        # -------- add center loss --------\n",
    "        self.add_loss(tf.reduce_mean(tf.square(diff)))\n",
    "        return feats                                   # passthrough\n",
    "\n",
    "class ArcMarginProduct(Layer):\n",
    "    \"\"\"ArcFace head.\"\"\"\n",
    "    def __init__(self, n_classes, s=30.0, m=0.50, easy_margin=False, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.n_classes, self.s, self.m, self.easy_margin = n_classes, s, m, easy_margin\n",
    "        self.cos_m = tf.constant(np.cos(m), dtype=tf.float32)\n",
    "        self.sin_m = tf.constant(np.sin(m), dtype=tf.float32)\n",
    "        self.th    = tf.constant(np.cos(np.pi - m), dtype=tf.float32)\n",
    "        self.mm    = tf.constant(np.sin(np.pi - m) * m, dtype=tf.float32)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[-1], self.n_classes),\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, feats, labels, training=False):\n",
    "        x_norm = tf.nn.l2_normalize(feats, axis=1)\n",
    "        W_norm = tf.nn.l2_normalize(self.W,    axis=0)\n",
    "        cos_t  = tf.matmul(x_norm, W_norm)\n",
    "\n",
    "        if not training:\n",
    "            return self.s * cos_t                     # plain logits\n",
    "\n",
    "        sin_t = tf.sqrt(1. - tf.square(cos_t) + 1e-7)\n",
    "        cos_mt = cos_t * self.cos_m - sin_t * self.sin_m\n",
    "        cond   = tf.where(cos_t > self.th, cos_mt, cos_t - self.mm) \\\n",
    "                 if not self.easy_margin else cos_mt\n",
    "        logits = tf.where(labels==1, cond, cos_t) * self.s\n",
    "        return logits\n",
    "\n",
    "# =========================================================\n",
    "# 4. FOCAL-LOSS  (auto-α, γ=2)\n",
    "# ---------------------------------------------------------\n",
    "freq        = train_df_bal[\"label\"].value_counts().loc[LABELS]\n",
    "alpha_vec   = tf.constant(np.median(freq) / freq, dtype=tf.float32)\n",
    "SMOOTH      = 0.05\n",
    "def focal_auto(y_true, y_pred, gamma=2.):\n",
    "    y_true = y_true * (1 - SMOOTH) + SMOOTH / N_CLASS\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "    ce  = -y_true * tf.math.log(y_pred)\n",
    "    fl  = tf.pow(1 - y_pred, gamma) * ce * alpha_vec\n",
    "    return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "\n",
    "# =========================================================\n",
    "# 5. MODEL  (ResNet-50 + ArcFace + Center-Loss)\n",
    "# ---------------------------------------------------------\n",
    "def build_model():\n",
    "    inp  = Input(shape=IMG_SZ + (3,))\n",
    "    lbl  = Input(shape=(N_CLASS,))          # ground-truth one-hot\n",
    "\n",
    "    base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inp)\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    x  = CenterLossLayer(N_CLASS, 256, name=\"centerloss\")(x, lbl)\n",
    "    logits = ArcMarginProduct(N_CLASS, name=\"arcface\")(x, lbl, training=True)\n",
    "    out    = tf.nn.softmax(logits)          # for metrics\n",
    "\n",
    "    model  = Model([inp, lbl], out, name=\"SheepID\")\n",
    "    return base, model\n",
    "\n",
    "base, model = build_model()\n",
    "\n",
    "# =========================================================\n",
    "# 6. DISCRIMINATIVE LR + COSINE DECAY\n",
    "# ---------------------------------------------------------\n",
    "EPOCHS_H = 5\n",
    "EPOCHS_FT = 20\n",
    "TOTAL_STEPS = (EPOCHS_H + EPOCHS_FT) * math.ceil(len(train_df_bal)/BATCH)\n",
    "\n",
    "def lr_schedule(step):\n",
    "    warmup_steps = 5 * math.ceil(len(train_df_bal)/BATCH)\n",
    "    if step < warmup_steps:\n",
    "        return 1e-3 * (step+1) / warmup_steps\n",
    "    prog = (step-warmup_steps) / (TOTAL_STEPS-warmup_steps)\n",
    "    return 3e-5 * 0.5 * (1 + math.cos(math.pi * prog))\n",
    "\n",
    "lr_fn = tf.keras.optimizers.schedules.LearningRateSchedule(lr_schedule)\n",
    "\n",
    "# two optimizers: tiny LR for backbone, bigger for new head\n",
    "opt_head = Adam(learning_rate=lambda: lr_fn(tf.keras.backend.get_value(step_var)))\n",
    "opt_back = Adam(learning_rate=lambda: lr_fn(tf.keras.backend.get_value(step_var))*0.1)\n",
    "\n",
    "# wrap them into MultiOptimizer\n",
    "opt = tf.keras.optimizers.legacy.Adam(1e-3)    # fallback if MultiOpt absent\n",
    "try:\n",
    "    from keras.optimizers import MultiOptimizer\n",
    "    opt = MultiOptimizer((model.get_layer(\"centerloss\"), opt_head),\n",
    "                         (model.get_layer(\"arcface\"),    opt_head),\n",
    "                         (base,                          opt_back))\n",
    "except Exception:\n",
    "    warnings.warn(\"MultiOptimizer unavailable → using single Adam\")\n",
    "    opt = Adam(1e-3)\n",
    "\n",
    "model.compile(optimizer=opt, loss=focal_auto, metrics=[\"accuracy\"])\n",
    "\n",
    "# helper generator to feed [img, label] twice\n",
    "def dual_gen(gen):\n",
    "    for x,y in gen:\n",
    "        yield [x, y], y\n",
    "\n",
    "# =========================================================\n",
    "# 7. TRAIN\n",
    "# ---------------------------------------------------------\n",
    "callback_list = [EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                 ReduceLROnPlateau(patience=2, factor=0.5, verbose=1)]\n",
    "\n",
    "model.fit(dual_gen(train_gen),\n",
    "          validation_data=dual_gen(val_gen),\n",
    "          steps_per_epoch=len(train_gen),\n",
    "          validation_steps=len(val_gen),\n",
    "          epochs=EPOCHS_H+EPOCHS_FT,\n",
    "          callbacks=callback_list)\n",
    "\n",
    "# =========================================================\n",
    "# 8. EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "val_logits = model.predict(dual_gen(val_gen), steps=len(val_gen), verbose=0)\n",
    "y_pred = np.argmax(val_logits,1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS, digits=2))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Confusion matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b8ed203-caef-4950-ac40-7192b087163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced counts:\n",
      " label\n",
      "Naeimi     204\n",
      "Roman      200\n",
      "Harri      200\n",
      "Najdi      200\n",
      "Goat       200\n",
      "Barbari    200\n",
      "Sawakni    200\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Found 1404 validated image filenames belonging to 7 classes.\n",
      "Found 137 validated image filenames belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Layer.add_weight() got multiple values for argument 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 172\u001b[0m\n\u001b[1;32m    168\u001b[0m     out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(logits)\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base, Model([inp, lbl], out)\n\u001b[0;32m--> 172\u001b[0m base, model \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# phase-1: head only\u001b[39;00m\n\u001b[1;32m    175\u001b[0m base\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 167\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(x)\n\u001b[1;32m    166\u001b[0m x \u001b[38;5;241m=\u001b[39m CenterLossLayer(N_CLASS, \u001b[38;5;241m256\u001b[39m)([x, lbl])\n\u001b[0;32m--> 167\u001b[0m logits \u001b[38;5;241m=\u001b[39m ArcMarginProduct(N_CLASS)([x, lbl], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    168\u001b[0m out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(logits)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m base, Model([inp, lbl], out)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[8], line 112\u001b[0m, in \u001b[0;36mArcMarginProduct.build\u001b[0;34m(self, in_shape)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_shape):\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m, shape\u001b[38;5;241m=\u001b[39m(in_shape[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes),\n\u001b[1;32m    113\u001b[0m                              initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglorot_uniform\u001b[39m\u001b[38;5;124m\"\u001b[39m, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Layer.add_weight() got multiple values for argument 'shape'"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 0. IMPORTS & GLOBALS\n",
    "# ---------------------------------------------------------\n",
    "import os, random, math, gc, warnings, numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D,\n",
    "                                     Dropout, Dense, Layer)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau,\n",
    "                                        LearningRateScheduler)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "CSV  = \"/Users/nabin/python/projects/Sheep Classification Images/train_labels.csv\"\n",
    "ROOT = \"/Users/nabin/python/projects/Sheep Classification Images/train/\"\n",
    "\n",
    "# =========================================================\n",
    "# 1. DATA  —————————————————————————————————————————————\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_csv(CSV)\n",
    "df[\"file_path\"] = ROOT + df[\"filename\"]\n",
    "df[\"label_idx\"] = df[\"label\"].astype(\"category\").cat.codes\n",
    "LABELS  = list(df[\"label\"].astype(\"category\").cat.categories)\n",
    "N_CLASS = len(LABELS)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=.2,\n",
    "                                    stratify=df[\"label_idx\"],\n",
    "                                    random_state=SEED)\n",
    "\n",
    "# balance ≤200 per class\n",
    "TARGET = 200\n",
    "train_df_bal = (train_df.groupby(\"label\", group_keys=False)\n",
    "                        .apply(lambda g: g if len(g) >= TARGET else\n",
    "                               resample(g, replace=True, n_samples=TARGET,\n",
    "                                        random_state=SEED))\n",
    "                        .sample(frac=1, random_state=SEED)\n",
    "                        .reset_index(drop=True))\n",
    "print(\"Balanced counts:\\n\", train_df_bal[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. GENERATORS\n",
    "# ---------------------------------------------------------\n",
    "BATCH  = 32\n",
    "IMG_SZ = (224, 224)\n",
    "\n",
    "tgen = ImageDataGenerator(rescale=1/255., rotation_range=25,\n",
    "                          width_shift_range=.15, height_shift_range=.15,\n",
    "                          zoom_range=.2, brightness_range=[.8,1.2],\n",
    "                          horizontal_flip=True)\n",
    "vgen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_gen = tgen.flow_from_dataframe(train_df_bal, x_col=\"file_path\",\n",
    "                                     y_col=\"label\", class_mode=\"categorical\",\n",
    "                                     target_size=IMG_SZ, batch_size=BATCH,\n",
    "                                     shuffle=True, seed=SEED)\n",
    "val_gen   = vgen.flow_from_dataframe(val_df, x_col=\"file_path\",\n",
    "                                     y_col=\"label\", class_mode=\"categorical\",\n",
    "                                     target_size=IMG_SZ, batch_size=BATCH,\n",
    "                                     shuffle=False)\n",
    "\n",
    "# =========================================================\n",
    "# 3. CUSTOM LAYERS  —————————————————————————————\n",
    "# ---------------------------------------------------------\n",
    "class CenterLossLayer(Layer):\n",
    "    def __init__(self, n_classes, feat_dim, alpha=0.5, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.n_classes, self.feat_dim, self.alpha = n_classes, feat_dim, alpha\n",
    "\n",
    "    def build(self, _):\n",
    "        self.centers = self.add_weight(name=\"centers\",\n",
    "                                       shape=(self.n_classes, self.feat_dim),\n",
    "                                       initializer=\"zeros\", trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        feats, labels = inputs            # labels one-hot\n",
    "        ctrs_batch   = tf.matmul(labels, self.centers)     # (bs,feat)\n",
    "        diff         = feats - ctrs_batch\n",
    "\n",
    "        # centre update\n",
    "        label_sum = tf.reduce_sum(labels, axis=0) + 1e-6   # (n_classes,)\n",
    "        delta     = tf.matmul(labels, diff, transpose_a=True)\n",
    "        delta    /= tf.expand_dims(label_sum, 1)\n",
    "        self.centers.assign_sub(self.alpha * delta)\n",
    "\n",
    "        self.add_loss(tf.reduce_mean(tf.square(diff)))     # centre loss\n",
    "        return feats                                       # passthrough\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "class ArcMarginProduct(Layer):\n",
    "    def __init__(self, n_classes, s=30., m=.5, easy_margin=False, **kw):\n",
    "        super().__init__(**kw)\n",
    "        self.n_classes, self.s, self.m, self.easy_margin = n_classes, s, m, easy_margin\n",
    "        self.cos_m = tf.constant(np.cos(m), dtype=tf.float32)\n",
    "        self.sin_m = tf.constant(np.sin(m), dtype=tf.float32)\n",
    "        self.th    = tf.constant(np.cos(np.pi - m), dtype=tf.float32)\n",
    "        self.mm    = tf.constant(np.sin(np.pi - m) * m, dtype=tf.float32)\n",
    "\n",
    "    def build(self, in_shape):\n",
    "        self.W = self.add_weight(\"W\", shape=(in_shape[0][-1], self.n_classes),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        feats, labels = inputs\n",
    "        x_norm = tf.nn.l2_normalize(feats, axis=1)\n",
    "        W_norm = tf.nn.l2_normalize(self.W,   axis=0)\n",
    "        cos_t  = tf.matmul(x_norm, W_norm)\n",
    "\n",
    "        if not training:\n",
    "            return self.s * cos_t\n",
    "\n",
    "        sin_t  = tf.sqrt(1. - tf.square(cos_t) + 1e-7)\n",
    "        cos_mt = cos_t * self.cos_m - sin_t * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            cos_mt = tf.where(cos_t > 0, cos_mt, cos_t)\n",
    "        else:\n",
    "            cos_mt = tf.where(cos_t > self.th, cos_mt, cos_t - self.mm)\n",
    "\n",
    "        logits = tf.where(labels==1, cos_mt, cos_t) * self.s\n",
    "        return logits\n",
    "\n",
    "# =========================================================\n",
    "# 4. LOSSES & LR SCHEDULE\n",
    "# ---------------------------------------------------------\n",
    "freq         = train_df_bal[\"label\"].value_counts().loc[LABELS]\n",
    "alpha_vec    = tf.constant(np.median(freq)/freq, dtype=tf.float32)\n",
    "SMOOTH, GAMMA= .05, 2.\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    y_true = y_true * (1 - SMOOTH) + SMOOTH / N_CLASS\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
    "    ce     = -y_true * tf.math.log(y_pred)\n",
    "    fl     = tf.pow(1 - y_pred, GAMMA) * ce * alpha_vec\n",
    "    return tf.reduce_mean(tf.reduce_sum(fl, axis=-1))\n",
    "\n",
    "def cosine_lr(epoch, lr0=3e-5, warm=5, total=25):\n",
    "    if epoch < warm:\n",
    "        return lr0 * (epoch+1)/warm * 30       # warm-up from 0 → 3e-4\n",
    "    progress = (epoch-warm)/(total-warm)\n",
    "    return lr0 * 0.5 * (1 + math.cos(math.pi*progress))\n",
    "\n",
    "# =========================================================\n",
    "# 5. MODEL — ResNet50 + ArcFace + CenterLoss\n",
    "# ---------------------------------------------------------\n",
    "def build_model():\n",
    "    inp  = Input(shape=IMG_SZ + (3,))\n",
    "    lbl  = Input(shape=(N_CLASS,))\n",
    "    base = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inp)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "    x = CenterLossLayer(N_CLASS, 256)([x, lbl])\n",
    "    logits = ArcMarginProduct(N_CLASS)([x, lbl], training=True)\n",
    "    out = tf.nn.softmax(logits)\n",
    "\n",
    "    return base, Model([inp, lbl], out)\n",
    "\n",
    "base, model = build_model()\n",
    "\n",
    "# phase-1: head only\n",
    "base.trainable = False\n",
    "model.compile(Adam(1e-3), loss=focal_loss, metrics=[\"accuracy\"])\n",
    "model.fit([train_gen.x, train_gen.y], train_gen.y,\n",
    "          validation_data=([val_gen.x, val_gen.y], val_gen.y),\n",
    "          epochs=5, batch_size=BATCH,\n",
    "          callbacks=[EarlyStopping(patience=2, restore_best_weights=True)],\n",
    "          verbose=1)\n",
    "\n",
    "# phase-2: fine-tune last 70 layers with cosine LR\n",
    "for l in base.layers[-70:]: l.trainable = True\n",
    "model.compile(Adam(learning_rate=3e-5), loss=focal_loss, metrics=[\"accuracy\"])\n",
    "model.fit([train_gen.x, train_gen.y], train_gen.y,\n",
    "          validation_data=([val_gen.x, val_gen.y], val_gen.y),\n",
    "          epochs=25, batch_size=BATCH,\n",
    "          callbacks=[LearningRateScheduler(cosine_lr),\n",
    "                     EarlyStopping(patience=5, restore_best_weights=True),\n",
    "                     ReduceLROnPlateau(patience=3, factor=.5)],\n",
    "          verbose=1)\n",
    "\n",
    "# =========================================================\n",
    "# 6. EVALUATION\n",
    "# ---------------------------------------------------------\n",
    "val_logits = model.predict([val_gen.x, val_gen.y], verbose=0)\n",
    "print(classification_report(val_gen.classes,\n",
    "                            np.argmax(val_logits,1),\n",
    "                            target_names=LABELS,\n",
    "                            digits=2))\n",
    "\n",
    "cm = confusion_matrix(val_gen.classes, np.argmax(val_logits,1))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Confusion matrix\"); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe647cef-843c-4ff3-8f50-b43284183421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
